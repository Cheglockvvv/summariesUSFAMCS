\documentclass[a4paper, 12pt]{report}
\usepackage{cmap}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[normalem]{ulem}
\usepackage[left=2cm,right=2cm, top=2cm,bottom=2cm,bindingoffset=0cm]{geometry}
\usepackage[english,russian]{babel}
\usepackage[unicode]{hyperref}

\title{\textbf{\Huge{Линейная алгебра}}\par\bigskipКонспект по 2-му семестру
	специальностей «экономическая кибернетика», «компьютерная безопасноть», «актуарная математика»\par(лектор: Б. Б. Комраков)}


\date{}
\begin{document}
	\maketitle
	\tableofcontents{}
	\chapter{Векторное пространство}
	\section{Определение и простейшие свойства вектороного пространства.}
	$\quad\; \bullet$ \textit{Пусть $V$ $\ne$ $\varnothing$, $P$ --- некоторое поле. Непустое множество $V$ называют \textbf{векторным пространством} над полем $P$, если на $V$ задана бинарная операция $V\times V \to V$, называемая сложением, и операция $P\times V \to V$, называемая умножением элемента на элемент поля $P$, для которых выполняются следующие условия:}
	\begin{enumerate} 
		\item ($V$, +) - абелева группа, т.е. выполняются свойства:
		\begin{itemize} 
			\item $a + b = b + a$
			\item $(a + b) + c = a + (b + c)$
			\item $\exists$ нейтралный элемент $a + 0 = a$
			\item $\exists$ противоположный элемент $a + (-a) = 0$
		\end{itemize}
		\item $\forall$ $\alpha$, $\beta$ $\in$ $P$, $\forall$ $a$, $b$ $\in$ $V$:
		\begin{itemize} 
			\item ($\alpha$ + $\beta$) $\cdot$ $a$ = $\alpha$ $\cdot$ $a$ + $\beta$ $\cdot$ $a$
			\item $\alpha$ $\cdot$ $(a + b)$ = $\alpha$ $\cdot$ $a$ + $\alpha$ $\cdot$ $b$
			\item $\alpha$ $\cdot$ ($\beta$ $\cdot$ $a$) = ($\alpha$ $\cdot$ $\beta$)  $\cdot$ $a$
			\item $a$ $\cdot$ 1 = $a$
		\end{itemize}
	\end{enumerate}
	\par\bigskip
	Если $a$ $\in$ $V$, то $a$ --- \textbf{вектор}, $\alpha$ $\in$ $P$ --- \textbf{скаляр}. Векторы --- элементы векторного пространства и обозначаются латинскими буквами: $a, b, c$ и т.д. Скаляры обозначаются греческими буквами $\alpha$, $\beta$, $\gamma$ и т.д. Если P = $\mathbb{C}$, то $V$ --- \textbf{комплексное векторное пространство}, а если $\mathbb{R}$, то \textbf{действительное}.
	\par\bigskip
	$0_v$ $\in$ $V$ - \textbf{нулевой вектор}, $0_p$ $\in$ $P$ - \textbf{нулевой скаляр}.
	\par\bigskip
	\textbf{Примеры векторных пространств:}
	\begin{itemize}
		\item ($V_2$, $\mathbb{R}$, +, $\cdot$ ) --- двумерное действительное ВП;
		\item ($V_3$, $\mathbb{R}$, +, $\cdot$ ) --- трёхмерное действительное ВП;
		\item ($P_m,n$, $P$, +, $\cdot$ ) --- ВП матриц размерности m$\times$n;
		\item ($R[x]$, $P$, +, $\cdot$ ) --- ВП многочленов над полем P;
		\item f: $\mathbb{R}$ $\to$ $\mathbb{R}$, $(f + g)(x) = f(x) + g(x)$, $\alpha$ $\cdot$ $f(x)$ = ($\alpha$ $\cdot$ $f$)$(x)$ - векторное пространство функций;
		\item $V$ = {$0_v$} --- нулевое ВП;
		\item ($P_n$, $P$, +, $\cdot$ ) --- ВП строк/столбцов элементов поля P.
	\end{itemize}
	\par\bigskip
	\textit{\textbf{Простейшие свойства векторных пространств:}}
	\begin{enumerate}
		\item $0_p$ $\cdot$ $a$ = $0_v$, $\forall$ $a$ $\in$ $V$, 
		\\$\alpha$ $\cdot$ $0_v$ = $0_v$, $\forall$ $\alpha$ $\in$ $P$
		\item $\alpha$ $\cdot$ $a$ = $0_v$ $\Leftrightarrow$ 
		$\left[ 
		\begin{gathered} 
			a = 0_v\\
			\alpha = 0_p\\
		\end{gathered} 
		\right.$
		\\\\
		$\blacklozenge$ Пусть $\alpha$ $\ne$ $0_p$ $\Rightarrow$ $\exists$ $\alpha^{-1}$ $\in$ $P:$ $\alpha$ $\cdot$ $\alpha^{-1}$ = 1
		\\ $a$ $\cdot$ 1 = ($\alpha^{-1}$ $\cdot$ $\alpha$) $\cdot$ $a$ = $\alpha^{-1}$ $\cdot$ ($\alpha$ $\cdot$ $a$) = $\alpha^{-1}$ $\cdot$ $0_v$ = $0_v \quad \boxtimes$
		\item Если $\alpha$ $\cdot$ $a$ = $\beta$ $\cdot$ $a$, $a$ $\ne$ $0_v$ $\Rightarrow$ $\alpha$ = $\beta$
		\\ Если $\alpha$ $\cdot$ $a$ = $\alpha$ $\cdot$ $b$, $\alpha$ $\ne$ $0_v$ $\Rightarrow$ $a = b$
	\end{enumerate}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Линейная зависимость и независимость векторов.}
	$\quad \; \ $Пусть $V$ $\ne$ $\varnothing$, $P$ --- некоторое поле. $A(a_1, ..., a_n), a_i \in V$ --- некоторая система векторов. $\alpha_1, ..., \alpha_n, \alpha_i \in P$ --- некоторые элементы поля $P$ (скаляры).
	$\alpha_1a_1 + ... + \alpha_n a_n = \sum\limits_{i=1}^n \alpha_i a_i$ --- \textbf{линейная комбинация} веткоров системы $A$ с коэффициентами $\alpha_1, ..., \alpha_n$
	\par\bigskip
	$\quad\; \bullet$ \textit{\textbf{Линейной оболочкой системы $A$} называется множество всевозможных комбинаций векторов системы $A$. Обозначение: $L(A) = L(a_1, ..., a_n)$}
	\par\bigskip
	$\quad\; \bullet$ \textit{Пусть $b \in A$ - некоторый вектор и $b = \sum\limits_{i=1}^n \alpha_i a_i \Rightarrow b \in L(A)$. Тогда говорят, что \textbf{вектор $b$ линейно выражается через систему A}.}
	\par\bigskip
	Пусть $B = (b_1, ..., b_k), b_i \in L(A), \forall i \in \overline{1,n}$. Тогда говорят, что \textbf{вся система $B$ линейно выражается через систему $A$}.
	\par\bigskip
	Если система $A$ линейно выражается через систему $B$ и система $B$ линейно выражается через систему $A$, то эти системы являются \textbf{эквивалентными}: $A \sim B$.
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Если система векторов $B$ линейно выражается через систему $A$, то $L(B) \subset L(A)$.}
	\par\bigskip
	$\blacklozenge$ Пусть $b \in L(B) \Rightarrow b$ представим в виде линейной комбинации векторов из $B$: 
	\begin{center}$b = \sum\limits_{i=1}^n \beta_i b_i$.\end{center}
	
	$\quad$Т.к. по условию теоремы система $B$ линейно выражается через систему $A$, то каждый 
	
	$\quad$вектор из системы $B$ представим в виде линейной комбинации векторов из $A$:
	\begin{center}
		\begin{equation*}
			\begin{cases}
				b_1 = \alpha_{11}a_1 + ... + \alpha_{1n}a_n
				\\
				b_2 = \alpha_{21}a_1 + ... + \alpha_{2n}a_n
				\\
				...
				\\
				b_n = \alpha_{n1}a_1 + ... + \alpha_{nn}a_n
				\\
			\end{cases}
		\end{equation*}
	\end{center}
	\par\bigskip
	$\quad$А, значит, $b \in L(A) \Rightarrow L(B) \subset L(A)$ $\quad\boxtimes$
	\par\bigskip
	\textbf{\textit{Следствие}}
	
	\textit{Если системы эквивалентны, то их линейные оболочки равны, т.е. $A \sim B \Rightarrow L(A) = L(B)$}.
	\par\bigskip
	$\quad\; \bullet$ \textit{Линейная комбинация системы векторов называется $\textbf{тривиальной}$, если $\alpha_i$ = 0, $\forall i \in \overline{1, n}$, и $\textbf{нетривиальной}$, если $\exists \alpha_i \ne$ 0.}
	\par\bigskip
	Если $\alpha_1a_1 + ... + \alpha_n a_n = 0_v$ и $\exists \alpha_i \ne 0$, то такая система векторов будет называется \textbf{линейно зависимой} (ЛЗ). В противном случае (если все $\alpha_i = 0$) она называется \textbf{линейно не зависимой} (ЛНЗ).
	\par\bigskip
	\textbf{Примеры:}
	\begin{itemize}
		\item Орты координатных осей $(i, j)$ --- ЛНЗ система;
		\item $(i, j, i + j)$ --- ЛЗ система, т.к. $i + j - (i + j) = 0_v$
		\item $(cost, sint)$ --- ЛНЗ, т.к. $\alpha cost + \beta sint = 0 \Rightarrow$ или $t = \dfrac{\pi}{2}, \beta = 0$, или $t = 0, \alpha = 0$
		\item $(cos^2t, sin^2t, 1)$ --- ЛЗ, т.е. $cos^2t + sin^t - 1 = 0$
		\item $P_n = (e_1(1, 0, ..., 0), e_2(0, 1, 0, ..., 0), ..., e_n(0, ..., 0, 1))$ --- ЛНЗ
		\item $P[x] = (1, x, x^2, ..., x^n)$ --- ЛНЗ
	\end{itemize}
	
	\textit{\textbf{Свойства линейной зависимости и независимости систем:}}
	\begin{enumerate}
		\item Если система $A(a_1, ..., a_n)$ --- ЛНЗ, то любая её подсистема также ЛНЗ. Если $\exists$ подсистема $A$, которая ЛЗ, то и система $A$ также ЛЗ.
		
		$\blacklozenge$ Докажем вторую часть теоремы. Пусть есть некоторая система $A(a_1, ..., a_n)$ и $B(a_1, ..., a_k) \subset A$ --- некоторая её ЛЗ подсистема. 
		\par
		$\quad$Тогда $\alpha_1 a_1 + ... + \alpha_k a_k = 0_v, \exists \alpha_i \ne 0_p \Rightarrow \alpha_1 a_1 + ... + \alpha_k a_k + 0_pa_{k+1} + ... + 0_pa_{n} = 0_v$. $\boxtimes$
		\item a) Система, состоящая из одного вектора ЛЗ $\Longleftrightarrow$ этот вектор нулевой. 
		
		б) Система, состоящая более, чем из одного вектора, ЛЗ $\Longleftrightarrow$ один из векторов линейно выражается через другие.
		\par\bigskip
		$\blacklozenge$ а) (Система состоит из 1-го вектора)
		
		\textbf{$\Rightarrow$)} А --- ЛЗ $\Rightarrow$ $\alpha a = 0_v и \alpha \ne 0 \Rightarrow a = 0_v$.
		
		\textbf{$\Leftarrow$)} A = {$0_v$} $\Rightarrow \alpha a = 0_v \forall \alpha \ne 0 \Rightarrow$ А --- ЛЗ. $\quad\boxtimes$ 
		
		$\blacklozenge$ б) (Система состоит более, чем из 1-го вектора)
		
		\textbf{$\Rightarrow$)} $A(a_1, ..., a_n)$ --- ЛЗ $\Rightarrow \alpha_1 a_1 + ... + \alpha_n a_n = 0_v и \exists \alpha_i \ne 0$. Поделим всё на $\alpha_i$: $\dfrac{\alpha_1}{\alpha_i}a_1 + ... + \dfrac{\alpha_{i-1}}{\alpha_i}a_{i-1} + a_i + \dfrac{\alpha_{i+1}}{\alpha_i}a_{i+1} + ... + \dfrac{\alpha_n}{\alpha_i}a_n = 0_v \Rightarrow a_i = - \dfrac{\alpha_1}{\alpha_i}a_1 - ... - \dfrac{\alpha_n}{\alpha_i}a_n$. $\quad\boxtimes$ 
		
		\textbf{$\Leftarrow$)} $A(a_1, ..., a_n)$ - некоторая система и $a_i = \dfrac{\alpha_1}{\alpha_i}a_1 + ... + \dfrac{\alpha_n}{\alpha_i}a_n \Rightarrow a_i - \dfrac{\alpha_1}{\alpha_i}a_1 - ... - \dfrac{\alpha_n}{\alpha_i}a_n = 0_v$
		
		\textbf{\textit{Следствие 1}}
		
		\textit{Система, содержащая $0_v$, всегда ЛЗ.}
		
		\textbf{\textit{Следствие 2}}
		
		\textit{Система, содержащая равные вектора, всегда ЛЗ.}
		
		\textbf{\textit{Следствие 3}}
		
		\textit{Если $A(a_1, ..., a_n)$ --- ЛНЗ, а $B(a_1, ..., a_n, b)$ --- ЛЗ, то $b$ линейно выражается через систему $A$.}
		
		$\blacklozenge$ $B(a_1, ..., a_n, b)$ --- ЛЗ $\Rightarrow \alpha_1a_1 + ... + \alpha_n a_n + \beta b = 0_v$.
		
		$\quad$Пусть $\beta = 0 \Rightarrow \exists \alpha_i \ne 0: \alpha_1a_1 + ... + \alpha_n a_n = 0_v$ - противоречие с тем, что система 
		
		$\quad A$ --- ЛНЗ $\Rightarrow \beta \ne 0 \Rightarrow b = \dfrac{\alpha_1}{\beta}a_1 + ... + \dfrac{\alpha_n}{\beta}a_n$. $\quad\boxtimes$ 
		\par\bigskip
		\textbf{Пример:}
		
		Пусть $A(a_1, a_2, a_3)$ - некоторая система, $a_1(1, -1, 2), a_2(1, 0, 1), a_3(2, -1, 2)$. Является ли эта система ЛЗ?
		
		Составим линейную комбинацию: $\alpha_1a_1 + \alpha_2a_2 + \alpha_3a_3 = 0_v$, или же $\alpha_1(1, -1, 2) + \alpha_2(1, 0, 1) + \alpha_3(2, -1, 2) = 0_v$.
		
		В итоге решение задачи сводится к решению системы линейных уравнений, где i-е столбцы - i-е координаты векторов.
		
		$\begin{pmatrix} 1 & 1 & 2 \\ -1 & 0 & -1 \\ 2 & 1 & 2 \end{pmatrix}\sim
		\begin{pmatrix} 1 & 1 & 2 \\ 0 & 1 & 1 \\ 0 & -1 & -2 \end{pmatrix}
		\begin{pmatrix} 1 & 1 & 2 \\  0 & 1 & 1 \\ 0 & 0 & -1 \end{pmatrix} \Rightarrow \exists только нулевое решение \Rightarrow система A$ --- ЛНЗ.
		\par\bigskip
		
		Рассмотрим теперь случай, когда $a_1(1, 1, -2), a_2(2, 0, 1), a_3(5, 1, 0)$
		
		$\begin{pmatrix} 1 & 2 & 5 \\ 1 & 0 & 1 \\ -2 & 1 & 0 \end{pmatrix}\sim
		\begin{pmatrix} 1 & 0 & 1 \\ 0 & 2 & 4 \\ 0 & 1 & 2 \end{pmatrix}
		\begin{pmatrix} 1 & 0 & 1 \\ 0 & 1 & 2 \end{pmatrix} \Rightarrow \exists ненулевое решение (-\alpha, -2\alpha, \alpha), \forall \alpha \in R \Rightarrow система A$ --- ЛЗ.
		
	\end{enumerate}
	
	
	
	
	
	
	
	
	
	
	\section{Базис и размерность векторных пространств.}
	
	\par\bigskip
	$\quad\; \bullet$ \textit{ Бесконечная система векторов ЛНЗ, если любая её конечная подсистема ЛНЗ, и ЛЗ, если существует ЛЗ конечная подсистема.}
	
	$\bullet$ \textit{Векторное пространство называется \textbf{бесконечномерным}, если в нем существует бесконечная ЛНЗ система векторов и \textbf{конечномерным}, если в нем все системы ЛЗ.}
	
	\par\bigskip
	$\bullet$ \textit{Система векторов $B$ векторного пространства $V$ называется \textbf{базисом $V$}, если:}
	
	\textit{1) $B$ --- ЛНЗ система,}
	
	\textit{2) $L$($B$) = $V$ }.
	\par\bigskip
	\textbf{Примеры}
	
	1) В пространстве $V_2 - $любые 2 некомпланарные вектора.
	
	2) В пространстве V = $\left\{ 0 \right\}$ базисов нет.
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{В конечномерном пространстве ЛНЗ система векторов либо является базисом, либо может быть дополнена до базиса.}
	
	$\blacklozenge$ $A$($a_1$, ..., $a_n$) --- ЛНЗ система.
	
	$\quad$ Пусть $A$ - не базис. Тогда $\exists$ $b$ $\in$ $V$, $b$ $\notin$ $L$($A$) 
	
	$\quad$ $B$($a_1$, ..., $a_n$, $b$). Пусть $B$ --- ЛЗ $\Rightarrow$ вектор $b$ $\in$ $L$($A$) $-$ выразим через $A \Rightarrow$  ?! (противоречие) $\Rightarrow$ $B$ --- ЛНЗ $\Rightarrow$ $A$ - базис.
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{В ненулевом конечном пространстве всегда существует конечный базис.}
	
	$\blacklozenge$ $a \neq 0, \left\{ a\right\}$ --- ЛНЗ $\Rightarrow$ по теореме это базис. $\boxtimes$
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Все базисы ненулевого конечномерного векторного пространства состоят из одного и того же числа векторов.}
	
	$\blacklozenge$  $A$($a_1$, ..., $a_k$), $B$($b_1$, ..., $b_n$), $k$ $\geqslant$  $n$, $A$ и $B$ базисы $V$,
	
	$\quad L$($B$) = $V$, $a_1$ $\in$ $L$($B$), ($a_1$, $b_1$, ..., $b_n$) --- ЛЗ.
	
	$\quad\alpha_1a_1 + \beta_1b_1$ + ... + $\beta_1b_1$ = $0_v$.
	
	\par\bigskip
	
	$\quad$Пусть $b_i$ = 0, $i = \overline{1, n}$ $\Rightarrow$ $\alpha_1a_1 = 0_v \Rightarrow \alpha_1 = 0$.
	
	$\quad\exists$ $b_i \neq 0$. Пусть $b_1 \neq 0 \Rightarrow b_1 = - \dfrac{\alpha_1}{\beta_1}a_1 - \dfrac{\beta_2}{\beta_1}b_2 - \dfrac{\beta_1}{\beta_1}b_1 \Rightarrow b_1 \in L$($a_1, b_2, ..., b_n$) $\Rightarrow$
	
	$\quad\Rightarrow$ $L$($a_1, b_2, ..., b_n$) = $L$($a_1, b_1, b_2, ..., b_n$) = $L(B)$ = $V$.
	
	\par\bigskip
	$\quad$Пусть $\beta_i$ = 0, i = $\overline{2, n}$ $\alpha_1a_1 + \alpha_2a_2 = 0_v \Rightarrow \alpha_1 + \alpha_2 = 0 \Rightarrow \exists \beta_i \neq 0, \beta_2 \neq 0,$
	
	$\quad b2 = - \dfrac{\alpha_1}{\beta_2}a_1$ - $\dfrac{\alpha_2}{\beta_2}a_2$ - $\dfrac{\beta_2}{\beta_2}b_1$ - ... - $\dfrac{\beta_n}{\beta_2}b_n \Rightarrow$
	
	$\quad\Rightarrow$ $b_2 \in L(a_1, a_2, b_3, ..., b_n)$. $L(a_1, a_2, b_3, ..., b_n)$ = $L(a_1, a_2, b_2, b_3, ..., b_n)$
	
	\par\bigskip
	$\quad$Аналогичным образом после всех действий получим $A(a_1, ..., a_n)$, где $L(A) = V$
	
	$\quad a_{n+1} \in L(a_1, ..., a_n) \Rightarrow (a_1, ..., a_n, a_{n+1})$ ---  ЛЗ $\Rightarrow n = k \Rightarrow A - $ не базис.
	
	$\quad$На первом шаге все $b_i$ будут заменены на $a_i$ и ничего не уменьшится. Значит 
	
	$\quad (a_1, ..., a_n)$ - базис. Если $k > n$, то $a_n$ линейно выражается $(a_1, ..., a_n, a_{n+1})$ --- ЛЗ.
	
	$\quad$Но базис ЛНЗ, значит $k = n.\quad \boxtimes$
	
	\par\bigskip
	{\textbf{ Размерность векторного пространства (dim)} --- количество векторов в базисе конечномерного векторного пространства.
		
		\par\bigskip
		\textbf{Пример:}
		
		1)$dim V_2$ = 2
		
		2)$dim V_3$ = 3
		
		
		
		
		
		
		
		
		
		
		\section{Координаты вектора. Изоморфизм векторных пространств.}
		
		
		\quad\; Пусть $V$ --- векторное пространство. $dim V = n$. $A(a_1, ..., a_n)$ --- базис $V$.
		
		$b = \alpha_1a_1 + ... + \alpha_na_n$, $\forall$ $b \in V$, $\alpha_i \in P$, $i=\overline{1, n}$
		
		$\alpha_1,...,\alpha_n$ --- \textbf{координаты вектора} $b$ в базисе} $A$. $X_b = \begin{pmatrix} \alpha_1 \\ ... \\ \alpha_n \end{pmatrix}$ --- \textbf{координатный столбец вектора} $b$.
	
	Исходя из определений выше, разложение вектора $b$ можно записать в следующем виде:
	
	$b = (a_1, ..., a_n)\cdot\begin{pmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{pmatrix} = AX_b$
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Координаты вектора в заданном базисе определяются однозначно}.
	\par\bigskip
	$\blacklozenge$ Пусть $b = \alpha_1a_1 + ... + \alpha_na_n - \beta_1a_1 + ... + \beta_na_n$
	
	$\quad$ $0_v = (\alpha_1 - \beta_1)a_1 + ... + (\alpha_n - \beta_n)a_n$ $\Rightarrow$ $\alpha_i - \beta_i = 0$ $\Rightarrow$ $\alpha_i = \beta_i$
	$\quad$ $\boxtimes$
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Координатный столбец суммы векторов равен сумме координатных столбцов векторов. При уможении вектора на скаляр, его координатный столбец также умножается на скаляр:}:
	
	$\quad$ $X_{a+b} = X_a + X_b$
	
	$\quad$ $X_{\alpha a} = \alpha X_a$, $\forall a, b \in V$, $\forall \alpha \in P$
	\par\bigskip
	$\blacklozenge$ 1) Рассмотрим $X_a=\begin{pmatrix} \alpha_1 \\ ... \\ \alpha_n \end{pmatrix}$, $X_b=\begin{pmatrix} \beta_1 \\ ... \\ \beta_n \end{pmatrix}$, тогда $\begin{cases} a = \alpha_1a_1 + ... + \alpha_n{a_n} \\ b = \beta_1b_1 + ... + \beta_n{b_n} \end{cases} \Rightarrow $
	
	$\quad\Rightarrow$ $a + b = (\alpha_1 + \beta_1)a_1 + ... + (\alpha_n + \beta_n)a_n$ $\Rightarrow$ $X_{a+b} = \begin{pmatrix} \alpha_1 + \beta_1 \\ ... \\ \alpha_n + \beta_n \end{pmatrix} =$ 
	
	$\quad = \begin{pmatrix} \alpha_1 \\ ... \\ \alpha_n \end{pmatrix} + \begin{pmatrix} \beta_1 \\ ... \\ \beta_n \end{pmatrix} = X_a + X_b$.
	\par\bigskip
	
	\quad2) $\alpha a = \alpha \alpha_1 a_1 + ... + \alpha \alpha_n a_n$ $\Rightarrow$ $X_{\alpha a} = \begin{pmatrix} \alpha \alpha_1 \\ ... \\ \alpha \alpha_n \end{pmatrix} = \alpha X_a$.
	$\quad\boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{Векторы ЛЗ $\Leftrightarrow$ ЛЗ их координатные столбцы.}
	\par\bigskip
	\textbf{Изоморфизм}
	\par\bigskip
	$\quad\; \bullet$ \textit{Отображение $\gamma: V \rightarrow U$ - \textbf{изоморфизм пространства $V$ в пространство $U$} при следующих условиях:}
	
	1) \textit{$U$ - биекция(взаимное однозначное соответствие)}
	
	2) $\gamma(a+b) = \gamma(a) + \gamma(b)$
	
	3) $\gamma(\alpha a) = \alpha \gamma(a)$, $\forall$ $a, b$ $\in V$, $\forall$ $\alpha$ $\in P$
	\par\bigskip
	Если существует изоморфизм между двумя пространствами, то эти пространства называются \textbf{изоморфными}.
	
	\par\bigskip
	\textbf{\textit{Свойства:} $\gamma$}
	
	1) $\gamma(0_v) = 0_v$
	\par\bigskip
	$\blacklozenge\;\; \gamma(0_v) = a$
	
	$\quad\;\gamma(0_v) = \gamma(0_p 0_v) = 0_p * \gamma(0_v) = 0_p * a = O_m$ $\Rightarrow$ $a = 0_v\quad\boxtimes$
	
	\par\bigskip
	
	2) \textit{изоморфизм ЛНЗ систем векторов переводит в ЛНЗ систему векторов:}
	
	$\quad$ $(a_1, ..., a_n)$\textit{ --- ЛНЗ} $\Rightarrow$ $(\gamma(a_1), ..., \gamma(a_n))$\textit{ --- ЛНЗ}.
	\par\bigskip
	$\blacklozenge\;$ Пусть $(a_1, ..., a_n)$ --- ЛНЗ $\Rightarrow$ $(\gamma(a_1), ..., \gamma(a_n))$ --- ЛЗ. $\Rightarrow$
	
	$\quad\;\Rightarrow$ $\alpha_1\gamma(a_1) + ... + \alpha_k \gamma(a_k) = O_u$, $\exists$ $\alpha_i \neq 0$ $\Rightarrow$
	
	$\quad$ $\Rightarrow$ $\gamma(\alpha_1a_1 + ... + \alpha_n a_n) = O_u; \gamma(O_u) = 0_v \Rightarrow$ $\alpha_1a_1 + \alpha_n a_n = 0_v$, $\exists$ $\alpha_i \neq 0$, $a_1, ..., a_n$ --- ЛЗ.
	
	$\quad\;\boxtimes$
	
	\par\bigskip
	
	3) \textit{Отношение изоморфизма на множестве векторных пространств является отношением эквивалентности.}
	\par\bigskip
	$\blacklozenge\;$ а) $V \cong V$ --- рефлексивность.
	
	$\quad$ б) $V \cong U$, $U \cong V$ --- симметричность.
	
	$\quad$ в) $V \cong U$, $U \cong W$ $\Rightarrow$ $V \cong W$ --- транзитивность.$\quad\boxtimes$
	
	\par\bigskip
	\textbf{Теорема}
	
	Если $dim V = n \geqslant 1$ $\Rightarrow$ $V \cong P_n$
	\par\bigskip
	$\blacklozenge$ Рассмотрим отображение $\gamma: V \rightarrow P_n$ и покажем, что по определению оно является изоморфизмом.
	
	$\quad\gamma(a) = X_a$, $\forall$ $a \in V$
	
	$\quad X_{a+b} = X_a + X_b$
	
	$\quad X_{\alpha a} = \alpha X_a\quad\boxtimes$
	
	\textit{Замечание: данное отображение ставит в соответствие вектору его координаты из поля $P_n$}.
	
	\par\bigskip
	\textbf{Теорема (критерий изоморфности векторных пространств)}
	
	\textit{Конечномерные векторные пространства над одним и тем же полем изоморфны $\Longleftrightarrow$ их размерности равны:}
	
	$U \cong V \Longleftrightarrow dim V = dim U$
	
	\par\bigskip
	
	$\blacklozenge$ $V \cong U$ $\Rightarrow$ $\exists$ $\gamma: V \rightarrow U$, $dim V \leqslant dim U$, $dim V = n$
	
	$\quad\gamma^{-1}: U \rightarrow V$, $dim U \leqslant dim V$ $\Rightarrow$ $dim V = dim U$ $\Rightarrow$ $dim U = dim V = n$
	
	$\quad U \cong P_n, V \cong P_n$ $\Rightarrow$ $U \cong V$
	$\quad\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	\section{Подпространства векторного пространства.}
	
	$\quad\; \bullet$ \textit{ Подмножество $U$ векторного пространства $V$ называется \textbf{подпространством}, если оно само является векторным пространством над полем $P$ относительно тех же операций, что и пространство $V$ (Обозначение: $U \subset V)$.}
	\par\bigskip
	\textbf{Примеры:}
	
	$P_n[x] \subset P[x]$(многочлены степени $\leqslant n$)
	
	$V_2 < V_3$($V_2$ - векторы плоскости, $V_3$ - векторы пространства)
	
	$V, U \neq \{\varnothing\}$
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Непустое множество $U$ векторного пространства $V$ является подпространством $\Leftrightarrow$ выполняются следующие условия:}
	
	\textit{Множество замкнуто относительно операций сложения и умножения на число: }
	
	$\begin{cases}$ 1) $a + b \in U$, $\forall$ $a, b \in U$ $\\$ 2) $\alpha a \in U$, $\forall$ $a \in U$, $\forall$ $\alpha \in P\end{cases}$
	\par\bigskip
	$\blacklozenge\Rightarrow)$ $U$ --- подпространство $\Rightarrow$ $U$ - векторное пространство $\Rightarrow$ условия 1 и 2 выполняются.
	
	$\quad\Leftarrow)$ 1), 2) выполняется: $a \in U, \alpha a \in U, 0_v \cdot a \in U$ $\Rightarrow$ $0_v \in U$ 
	
	$\quad\alpha  = (-1) a \in U$ $\Rightarrow$ $-a \in U$ $\Rightarrow$ $U$ - векторное пространство $\Rightarrow$ $U$ - подпространство. $\quad\boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие 1}}
	
	\textit{$U \subseteq V$ $\Rightarrow$ $0_v \in U$, т.е. нулевые векторы у $V$ и $U$ совпадают.}
	\par\bigskip
	$\blacklozenge$ $a \in U$ $\Rightarrow$ $0_v \cdot a  \subseteq U$ $\Rightarrow$ $0_v \in U\quad\boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие 2}}
	
	\textit{$A(a_1, ..., a_n), a_i \in U, i = \overline{1, k}$ $L(A) \subseteq V$}
	\par\bigskip
	$\blacklozenge$ $a, b \in L(A)$ $\Rightarrow$ $a = \alpha_1 a_k + .. + \alpha_k a_k$
	
	$\quad b = \beta_1 a_1 + ... + \beta_k a_k$
	
	$\quad a + b = (\alpha_1 + \beta_1)a_1 + ... + (\alpha_k + \beta_k)a_k \in L(A)$
	
	$\quad\alpha a = \alpha_1 a_1 + ... + \alpha_k a_k \in L(A)$
	
	$\quad\forall$ $a, b \in L(A)$ $\Rightarrow$ $a + b$, $\alpha a \in L(A)$ $\Rightarrow$ $L(A) \subseteq V$
	$\quad\boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие 3}}
	
	\textit{Размерность линейной оболочки системы $A$ равна максимальному числу ЛНЗ векторов в системе $A$.}
	\par\bigskip
	$\blacklozenge$ Если система $A$ ЛНЗ, то $A$ --- базис $L(A)$
	
	$\quad A(a_1, ..., a_n)$ $(a_1, ..., a_n)$ --- ЛНЗ
	
	$\quad a_{k+1}, a_n$ выражаются через $(a_1, ..., a_n)$
	
	$\quad L(A) = L(a_1, ..., a_n) = L(a_1, ..., a_k)$ $\Rightarrow$ $a_1, ..., a_n$ --- базис $L(A)$
	
	$\quad\Rightarrow$ $dim L(A) = k$
	$\quad\boxtimes$
	
	\par\bigskip
	\textbf{Теорема (о монотонности размерности векторных пространств)}
	
	\textit{$dim V = n, \forall\ U \subseteq V$ $\Rightarrow$ $dim U \leqslant n$, $dim U = n$ $\Rightarrow$ $U = V$}
	\par\bigskip
	$\blacklozenge$ $A$ --- базис $U$ $\Rightarrow A$ --- ЛНЗ $\Rightarrow$ $dim U \leqslant n$
	
	$\quad A = (a_1, ..., a_n)$ $\Rightarrow$ $A$ --- базис $V$.
	
	$\quad\begin{cases} L(A) = V \\ L(A) = U \end{cases}\Rightarrow$ $U = V$
	$\quad\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Ранг системы векторов.}
	$\quad\; \bullet$ \textit{ Пусть $A(a_{1}...a_{n}), B \subset A$, тогда
		$B$ --- \textbf{базис системы $A$}, если:}
	
	$\quad \; \ $\textit{$1)$ $B$ --- линейно независимая система}
	
	$\quad \; \ $\textit{$2)$ любой вектор системы $A$ линейно выражается через $B$}
	\par\bigskip
	\textit{\textbf{Свойства:}}
	
	\textit{$1)$ если $B$ --- базис $A$, то $B \sim A$}
	
	$\blacklozenge\ B \subseteq A \Rightarrow B$ линейно выражается через $A$.
	
	\quad$B$ --- базис $A \Rightarrow A$ линейно выражается через $B$. $\quad\boxtimes$
	
	\textit{$2)$ $B$ --- базис $A \Rightarrow L(A) = L(B)$}
	
	\textit{$3)$ $B$ --- базис $A \Rightarrow B$ --- базис $L(A)$}
	
	\textit{$4)$ Все базисы системы векторов состоят из одного и того же числа векторов}
	\par\bigskip
	
	$\bullet$ \textit{Число векторов в базисе системы векторов называется \textbf{рангом системы векторов} и обозначается $rankA$}.
	
	Если система состоит только из нулевого вектора, то ранг системы равен 0 ($rankA = 0$)
	\par\bigskip
	\textit{\textbf{Свойства ранга:}}
	
	$1)$ $\forall A$ $rankA = dimL(a)$
	
	$2)$ $\forall A, B$, \textit{если $A$ линейно выражается через $B$, то}
	$rankB \leqslant rankA$
	
	$\blacklozenge$ $A$ линейно выражается через $B \Rightarrow$ $L(B)$ $\leqslant$  $L(A) \Rightarrow$ $dimB$ $\leqslant$  $dimA \Rightarrow$ $rankB$ $\leqslant$  $rankA \boxtimes$
	\par\bigskip
	\textit{\textbf{ Элементарные преобразования векторов:}}
	
	$1)$ Домножение любого вектора системы на $\alpha \in P, \alpha \ne 0$
	
	$2)$ Сложение двух векторов системы, один из которых домножен на скаляр $\alpha \in P, \alpha \ne 0$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Элементарные преобразования не меняют ранг системы}.
	\par\bigskip
	$\blacklozenge$ Пусть $A$, $B$ и $C$ --- системы векторов, векторы $\overline{a}, \overline{a}_{1}, \overline{a}_{2}, \in A$, $\alpha \in P, \alpha \ne 0$. Пусть $A$ 
	
	\quadлинейно выражается через $B$ и для любого $\overline{a}$ существует $\overline{b}, \overline{a} = \alpha \overline{b}$ $\Rightarrow rankB \leqslant rankA$.
	
	\quad Тогда любое $\overline{b}$ можно выразить через $\overline{a}$ как: $\overline{b} = {\alpha}^{-1}\overline{a} \Rightarrow$ $B$ линейно выражается 
	
	\quad через $A \Rightarrow rankA \leqslant rankB \Rightarrow rankA = rankB$. Пусть $A$ линейно выражается через 
	
	\quad$C$ $\Rightarrow rankC \leqslant rankA$.
	
	\quad Для любого $\overline{a_{1}}$ справедливо следующее: $\overline{a_{1}} = (\overline{a_{1}} + \alpha \overline{a_{2}})$ - $\alpha \overline{a_{2}}$, где $\overline{a_{1}} \in C$ (так как $A$ 
	
	\quadлинейно выражается через $C$), $\overline{a_{1}} + \alpha \overline{a_{2}} \in A$ и $\alpha \overline{a_{2}} \in A$ $\Rightarrow$ $C$ линейно выражается 
	
	\quadчерез $A \Rightarrow rankA \leqslant rankC \Rightarrow rankA = rankC$ $\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Ранг матрицы.}
	\par\bigskip
	$\quad \; \ $Обозначим за $A$ следующую матрицу:
	
	$A=\alpha_{ij} \in P_{mn}$,
	\par\bigskip
	$A=$ $\begin{pmatrix} 
		\alpha_{11} & ... & \alpha_{1n} 
		\\ ... & ... & ...
		\\ \alpha_{m1} & ... & \alpha_{mn}
	\end{pmatrix}$.
	\par\bigskip
	Определим $A_{i}=\begin{pmatrix} 
		A_{1i} 
		\\A_{2i}
		\\...
		\\A_{mi}
	\end{pmatrix},$ $i=\overline{1,n}$.
	\par\bigskip
	$\bullet$ \textit{\textbf{Рангом матрицы} $A$ называется ранг системы её стобцов.}
	\par\bigskip
	$\bullet$ \textit{\textbf{Базисным минором матрицы} $A$ называется такой минор матрицы $M$, что: }
	
	$\quad \ $\textit{$1)$ $M \ne 0$ }
	
	$\quad \ $\textit{$2)$ все миноры, порядок которых больше порядка $M$, равны нулю }
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Столбцы матрицы $A$, в которых расположен базисный минор, образуют базис системы столбцов матриц}.
	\par\bigskip
	$\blacklozenge$ $M=\begin{vmatrix}
		\alpha_{i11} & ... & \alpha_{i1k}
		\\ ... & ... & ...
		\\ \alpha_{ik1} & ... & \alpha_{ikk}
	\end{vmatrix} \ne 0$, $(A_{1}, ..., A_{k})$ --- базис $(A_{1}, ..., A_{n})$
	\par\bigskip
	$\quad $Пусть $(A_{1}$, ..., $A_{k})$ --- линейно зависим $\Rightarrow$ $\exists \beta_{i} \ne 0$ : $(\beta_{1}A_{1}$ ... $\beta_{k}A_{k}) = 0$
	\par\bigskip
	$\quad$ $\begin{cases}
		\beta_{1}\alpha_{11} + ... + \beta_{n}\alpha_{1n} = 0
		\\ ...
		\\ \beta_{m}\alpha_{m1} + ... + \beta_{n}\alpha_{mn} = 0
	\end{cases}$
	
	\quad Обозначим за $B_{i}$ столбец вида  $B_{i} = \begin{pmatrix} \alpha_{i}
		\\ ...
		\\ \alpha_{i}
	\end{pmatrix}$ и $B_{k} = \begin{pmatrix} \alpha_{i1k}
		\\ ...
		\\ \alpha_{ikk}
	\end{pmatrix}$
	
	\quad $\beta_{1}B_{1} + ... + \beta_{k}B_{k} = 0, \beta_{i} \ne 0 \Rightarrow M = 0 \Rightarrow (A_{1} ... A_{n})$ --- линейно зависимо
	
	\quad $\forall S = \overline{1, m}, p \in \overline{k+1, n} M_{S} = \begin{vmatrix} \alpha_{i11} & ... & \alpha_{i1k} & \alpha_{i1p}
		\\ \alpha_{ik1} & ... & \alpha_{ikk} & \alpha_{ikp}
		\\ \alpha_{s1} & ... & \alpha_{sk} & \alpha_{sp}
	\end{vmatrix} = 0$
	
	\quad Распишем минор по $M_{S}$ строке: $A_{k+1} = M$
	
	\quad $0 = M_{s} = \alpha_{s1}D_{1} + ... \alpha_{sk}D_{k} + \alpha_{sp}M$
	
	\quad $A_{1}D_{1} + ... + A_{k}D_{k} + A_{p}M = 0$
	
	\quad $A_{p} = -\frac{1}{M}(A_{1}D_{1} + ... + A_{n}D_{n})$ $\boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие 1}}
	
	\textit{Ранг матрицы равен порядку базисного минора}.
	\par\bigskip
	\textit{\textbf{Следствие 2}}
	
	\textit{Ранг матрицы не меняется при транспонировании}.
	\par\bigskip
	\textit{\textbf{Следствие 3}}
	
	\textit{$detA = 0 \Longleftrightarrow$ столбцы $A_{1}, ..., A_{n}$ --- линейно зависимы}.
	\par\bigskip
	$\blacklozenge$ $\Rightarrow detA = 0, M \ne detA \Rightarrow rank(A_{1} ... A_{n})$ --- линейно зависимы
	
	$\quad\Leftarrow A_{1} ... A_{n}$ --- линейно зависимы $\Rightarrow detA = 0$ $\boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие 4}}
	
	\textit{Элементарные преобразования строк и столбцов матрицы не меняют её ранг}.
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $rank(AB) \leqslant rankA,\ rank(AB) \leqslant rankB,\ A \in P_{nn},\ detA \ne 0 \Rightarrow rank(AB) = rankB$}.
	
	$\blacklozenge$ $A = (\alpha_{ij}) \in P_{mn},\ B = (\beta{ij}) \in P_{nk},\ AB = (\gamma_{ij}) \in P_{mk},\ s = \overline{1, k}$
	\par\bigskip
	$\quad$ $\begin{pmatrix} \gamma_{11}
		\\ ...
		\\ \gamma_{m1}
	\end{pmatrix} = \begin{pmatrix} 
		\alpha_{11}\beta_{1s} + ... + \alpha_{1n}\beta_{ns}
		\\ \alpha_{21}\beta_{1s} + ... + \alpha_{2n}\beta_{ns}
		\\ \alpha_{m1}\beta_{1s} + ... + \alpha_{mn}\beta_{ns}
	\end{pmatrix} = \beta_{1s}\begin{pmatrix} \alpha_{11}
		\\ ...
		\\ \alpha_{m1}
	\end{pmatrix} + \beta_{1s}\begin{pmatrix} \alpha_{1n}
		\\ ...
		\\ \alpha_{mn}
	\end{pmatrix} \Rightarrow rank(AB) \leqslant rankA$
	\par\bigskip
	$\quad \ rank(AB) = rank(AB)^{T} = rank(B^{T}A^{T}) \leqslant rankB^{T} = rankB$
	
	$\quad \ detA \ne 0 \Rightarrow \exists A^{-1}$, 
	$B = A^{-1}(AB)$
	
	$\quad \ rankB = rank(A^{-1}(AB)) \leqslant rank(AB) \Rightarrow rank(AB) = rankB$  $\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Матрица перехода. Преобразование координат векторов.}
	
	$\quad \;$Пусть задана матрица $V$, $A=(a_{1}, ... , a_{n})$ --- базис $V, dimV = n$.
	Зададим $B=(b_{1}, ... b_{n}): b_{i} = \alpha_{1i}a_{1} + ... + \alpha_{ni}a_{n}, i = \overline{1, k}$.
	\par\bigskip
	$B_{i} = \begin{pmatrix} \alpha_{1i}
		\\ ...
		\\ \alpha_{ni}
	\end{pmatrix}$ --- координатный столбцов векторов $B$ в базисе $A$.
	
	$\bullet$ \textit{$S = (b_{1} ... b_{n} \in P_{n,n})$ --- \textbf{матрица перехода} от базиса $A$ к системе векторов $B$.}
	
	$B = A\begin{pmatrix} \alpha_{11} ... \alpha_{1n}
		\\ ...
		\\ \alpha_{n1} ... \alpha_{nn}
	\end{pmatrix} \Rightarrow B = AS$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{$rankS = rankB$}.
	\par\bigskip
	$\blacklozenge$ Если вектора линейно зависимы то их координаты линейно зависимы. Столбцы матрицы перехода $S$ --- это координаты столбцов $B$ $\boxtimes$
	\par\bigskip
	\textit{\textbf{Свойство:}}
	
	\textit{$dimV = n, B(b_{1}, ... , b_{n})$ --- базис $V$ $\Leftrightarrow$ $S \in P_{nn}, detS \ne 0$}.
	\par\bigskip
	$\blacklozenge$ $\Rightarrow B$ --- базис $\Rightarrow Bk = n, rankB = n \Rightarrow rankS = n \Rightarrow detA \ne 0$ 
	
	$\quad \Leftarrow S \in P_{nn}, detS \ne 0 \Rightarrow Bk = n \Rightarrow rankS = n, rankB = n$ $\boxtimes$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Если $A, B, C$ --- базисы $V$, $S_{A\rightarrow B}$ $S_{A\rightarrow C}$ $S_{B\rightarrow C}$ --- матрицы перехода, то выполняются следующие свойства: }
	
	$a)$ \textit{$S_{B\rightarrow A} = S_{A\rightarrow B}^{-1}$}
	
	$b)$ \textit{$S_{A\rightarrow C} = S_{A\rightarrow B}S_{B\rightarrow C}$}
	\par\bigskip
	$\blacklozenge$ $B = AS_{A\rightarrow B}, \exists (S_{A \rightarrow B})^{-1}$
	
	$\quad B(S_{A\rightarrow B})^{-1} = A(S_{A\rightarrow B})(S_{A\rightarrow B})^{-1} = A \Rightarrow A = B(S_{A\rightarrow B})^{-1} = B(S_{B\rightarrow A})$
	\par\bigskip
	$\quad C = B(S_{B\rightarrow C}), B = A(S_{A\rightarrow B}) \Rightarrow C = A(S_{A\rightarrow B})(S_{B\rightarrow C}) = A(S_{A\rightarrow C}) \Rightarrow S_{A\rightarrow C} = S_{A\rightarrow B}S_{B\rightarrow C}$ $\boxtimes$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $X \in V, A и B$ --- базис $V, X_{A}$ --- координатный столбец вектора $A$ в базисе $V, X_{B}$ --- координатный столбец вектора $B$ в базисе $V$. Тогда}
	
	\textit{$$X_{A} = S_{A \rightarrow B}X_{B}$$}
	\par\bigskip
	$\blacklozenge$ $X_{A} = \begin{pmatrix} \alpha_{1}
		\\ ...
		\\ \alpha_{n}
	\end{pmatrix}, X_{B} = \begin{pmatrix} \beta_{1}
		\\ ...
		\\ \beta_{n}
	\end{pmatrix}, X = AX_{A}, X = BX_{B}, B = AS_{A \rightarrow B}$
	
	$\quad AX_{A} = BX_{B} \Rightarrow AX_{A} = AS_{A \rightarrow B}X_{B}$
	
	$\quad A(X_{A} - S_{A \rightarrow B}X_{B}) = 0_{V} \Rightarrow X_{A} = S_{A \rightarrow B}X_{B}$ $\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Сумма и пересечение подпространств.}
	%в следующей строчке у меня немного съезжает влево из-за section. если у тебя не будет съезжать влево, то убери "\quad \; \ "
	$\quad \; \  U\subset V \Longleftrightarrow u_1 + u_2 \in U$
	
	$\qquad\qquad\quad \; \  \alpha u \in U$
	
	$\qquad\qquad\quad \; \   \forall u_1, u_2, u \in U,\  \forall \alpha \in P $
	
	Пусть $U_1 \subset V,\  U_2\subset V$. Тогда
	
	$U_1 \cap U_2 = \{u\in V \ | \  u\in U_1,\  u\in U_2\}$ - \textbf{пересечение}.
	
	$U_1 + U_2 = \{a_1 + a_2 \ |\  a_1\in U_1,\  a_2\in U_2\}$ - \textbf{сумма}.
	
	$U_1 \oplus U_2 $ - \textbf{прямая сумма} (любой вектор $V$ раскладывается единственным образом).
	
	\par\bigskip
	\textbf{\textit{Свойства суммы и пересечения подпространств:}}
	\begin{enumerate}
		\item \textit{$U_1 + U_2, U_1\cap U_2$  - подпространства пространства $V$.}
		
		$\blacklozenge$ Для пересечения: $\forall a,b\in U_1\cap U_2 \Rightarrow a,b \in U_1,\  a,b \in U_2$
		
		$\quad \; \Rightarrow a + b\in U_1,\  a+b\in U_2$
		
		$\quad\quad \; \; \alpha a \in U_1,\  \alpha a \in U_2$
		
		$\quad \; \Rightarrow a + b\in U_1\cap U_2$
		
		$\quad\quad \; \;\alpha a \in U_1\cap U_2$
		
		$\quad \; \Rightarrow U_1\cap U_2\subset V \quad \boxtimes$
		
		$\blacklozenge$ Для суммы: $\forall a,b\in U_1 + U_2 \Rightarrow a = a_1 + a_2$
		
		$\qquad \qquad \qquad \qquad \quad \; b = b_1 + b_2$
		
		$\qquad \qquad \qquad \qquad \quad \; a_1, b_1 \in U_1, \; a_2, b_2 \in U_2$
		
		$\quad \; a + b = \underset{\in U_1}{(a_1 + b_1)} + \underset{\in U_2}{(a_2 + b_2)} \Rightarrow a + b \in U_1 + U_2$
		
		$\quad \; \alpha a = \underset{\in U_2}{\alpha a_1} + \underset{\in U_2}{\alpha a_2} \Rightarrow \alpha a\in U_1 + U_2 \Rightarrow U_1 + U_2 \subset V \quad \boxtimes$
		
		\item $U_1 \oplus U_2 \Longleftrightarrow U_1\cap U_2 = \{0_v\}$ (Сумма является прямой тогда и только тогда, когда пересечение состоит только из нулевого вектора).
		
		$\blacklozenge\  \Rightarrow )\ $ Пусть $ U_1\oplus U_2,\ $ и предположим, что  $U_1\cap U_2 \ne \{0_v\}\Rightarrow \exists\  a\in U_1\cap U_2,\ a\ne 0_v$
		
		$\quad \; \Rightarrow -a\in U_1\cap U_2,\  a\ne 0_v \Rightarrow -\alpha \in U_1\cap U_2$
		
		$\quad \; 0_v = \underset{\in U_1}{0_v} + \underset{\in U_2}{0_v}, \qquad 0_v = \underset{\in U_1}{a} + \underset{\in U_1}{(-a)}$
		
		$\qquad\qquad\qquad\qquad\;\; \Downarrow$
		
		$\quad \; \nexists\  a \ne 0 \Rightarrow U_1\cap U_2 = \{0_v\}$
		
		$\quad \Leftarrow )\ U_1\cap U_2 = \{0_v\} \Rightarrow \exists \ x\in U_1 + U_2\ : \ x=a_1 + a_2, \ x = b_1 + b_2,$ где $\ a_1,b_1 \in U_1, \ a_2,b_2 \in U_2$
		
		$\quad \; \underset{\in U_1}{(a_1 - b_1)} + \underset{\in U_2}{(a_2 - b_2)} = 0_v$
		
		$\quad \; a_1 - b_1 = b_2 - a_2$
		
		$\quad \; b_2 - a_2\in U_2, \ a_1 - b_1 \in U_1$ (один и тот же вектор)
		
		$\quad \; a_1 - b_1\in U_1\cap U_2 \Rightarrow a_1 - b_1 = 0_v \Rightarrow a_1 = b_1 \Rightarrow b_2 = a_2 \Rightarrow U_1 \oplus U_2 \quad \boxtimes$
		
	\end{enumerate}\par\bigskip\textbf{Теорема}
	
	\textit{Если $U_1\subset V_1, \ U_2\subset V_2$, то $dim(U_1 + U_2) = dim U_1\  +\  dim U_2\  -\  dim (U_1 \cap U_2)$.}
	\par\bigskip
	$\blacklozenge$ Пусть $C\ (c_1,...,c_m)$ --- базис $U_1\cap U_2$, $dim(U_1\cap U_2) = m$.
	
	$\quad$И пусть $A\ (c_1,...,c_m,a_1,..., a_k)$ --- базис $U_1$, $dim U_1 = m+k$,
	a $B\ (c_1,...,c_m,b_1,..., b_s)$ --- 
	
	$\quad$базис $U_2$, $dim U_2 = m+s$.
	
	$\quad$Рассмотрим $D\ (c,...,c_m,a_1,...,a_k,b_1,...,b_s)$ и покажем, что это базис $U_1 + U_2$. А именно, 
	
	$\quad$что любой вектор $x\in U_1 + U_2$ представим в виде $x=\underset{\in U_1}{x_1} + \underset{\in U_2}{x_2}$.
	
	$\quad$Пусть $D$ --- ЛЗ. Тогда существует нетривиальная ЛК
	
	$\quad \gamma_1 c_1 +...+\gamma_m c_m +\alpha_1 a_1 + ... + \alpha_k a_k + \beta_1 b_1 + ...+\beta_s b_s = 0_v$
	
	$\quad \underbrace{\gamma_1 c_1 +...+\gamma_m c_m +\alpha_1 a_1 + ... + \alpha_k a_k}_b = -\beta_1 b_1 - ...-\beta_s b_s$
	
	$\quad b\in U_1,\  b\in U_2 \Rightarrow b\in U_1\cap U_2 \Rightarrow$ $b$ линейно выражается через систему $C$:
	
	$\quad b = \gamma_1 c_1 +...+\gamma_m c_m + 0\cdot b_1 + ... + 0\cdot  b_s$,$\  \gamma_i = 0 \; \forall\  i\in[1,m] $.
	
	$\quad$С другой стороны, $b = 0\cdot c_1+...+0\cdot c_m - \beta_1 b_1 - ... -\beta_s b_s$, $\  \beta_i = 0\; \forall i\in[1,s]$.
	
	$\quad$Следовательно, $D$ --- ЛНЗ. $D$ --- базис $U_1+U_2\Rightarrow dim(U_1 + U_2) = m + k + s$
	
	$\quad m+k+s = (m+k)+(m+s)-m$ --- размерность $U_1 + U_2$
	
	$\quad\left.
	\begin{aligned}
		m+k &= dim U_1 \\
		m+s &= dim U_2 \\
		m = di&m (U_1\cap U_2)
	\end{aligned}
	\right\}
	\Rightarrow dim(U_1 + U_2) = dim U_1 + dim U_2 - dim(U_1\cap U_2)
	$
	$\quad \boxtimes$
	\par\bigskip
	\textbf{\textit{Следствие $U_1 \oplus U_2$}}
	
	\textit{
		$(\underbrace{a_1,...,a_k}_{\text{Базис } U_1}, \underbrace{b_1,...,b_s}_{\text{Базис } U_2})$ --- базис $U_1\oplus U_2$.}
	\par\bigskip
	$\blacklozenge$ $U_1\cap U_2 = \{0_v\}$
	
	$\quad dim(U_1\cap U_2)=0$
	
	$\quad dim(U_1 + U_2) = dim U_1 + dim U_2\quad \boxtimes$
	\par\bigskip
	\textbf{Пример:}
	
	Найти базис и размерность $L_1 + L_2, L_1\cap L_2$, если
	
	$a_1\ (1,-1,2), a_2\ (2,3,-1), a_3\ (3,2,1), \quad L_1 = L\ (a_1,a_2,a_3)$
	
	$b_1\ (-2,1,2), b_2\ (1,1,1), b_3\ (-3,2,1), \quad \  L_2 = L\ (b_1,b_2,b_3)$.
	\par\bigskip
	Сначала найдём базис и размерность $L_1+L_2 = \{a+b\ |\ a\in L_1,\ b\in L_2\}$.
	\par\bigskip
	$\begin{pmatrix} 1 & 2 & 3 \\ -1 & 3 & 2 \\ 2 & -1 & 1 \end{pmatrix} \sim $
	$\begin{pmatrix} 1 & 2 & 3 \\ 0  & 5 & 5  \\   0 & 5 & 5 \end{pmatrix}$ $\Rightarrow a_1, a_2$ --- базис $L_1, dim L_1 = 2$
	
	$\begin{pmatrix} -2 & 1& -3 \\ 1 & -1 & 2 \\ 2 & 1 & 1 \end{pmatrix} \sim $
	$\begin{pmatrix} -2 & 1 & -3 \\ -1  & 0 & -1  \\   -4 & 0 & 4 \end{pmatrix}$ $\Rightarrow b_1, b_2$ --- базис $L_2, dim L_2 = 2$
	
	$\begin{pmatrix} 1 & 2 & -2 & 1 \\ -1 & 3 & 1 & -1 \\ 2 & -1 & 2 & 1 \end{pmatrix} \sim $
	$\begin{pmatrix} 1 & 2 & -2 & 1 \\ 0 & 5 & -1 & 0 \\ 0 & -5 & 6 & -1 \end{pmatrix} \sim $
	$\begin{pmatrix} 1 & 2 & -2 & 1 \\ 0 & 5 & -1 & 0 \\ 0 & 0 & 5 & -1 \end{pmatrix}$, 
	\par\bigskip
	где 3-ий столбец возьмём за независимый вектор $\Rightarrow$ 
	
	$a_1, a_2, b_2$ --- базис $L_1+L_2,\  dim(L_1 + L_2) = 3$
	
	Теперь найдем базис и размерность $L_1 \cap L_2$:
	
	$dim(L_1 + L_2) = dim L_1 + dim L_2 - dim(L_1\cap L_2)$
	
	$dim(L_1\cap L_2) = 1$
	
	$b_1 = \alpha_1 a_1 + \alpha_2 a_2 + \alpha_3 b_2$
	
	$\underbrace{b_1 - \alpha_3 b_2}_{\in L_2} = 
	\underbrace{\alpha_1 a_1 + \alpha_2 a_2}_{\in L_1}$
	\par\bigskip
	$\begin{pmatrix} 1 & 2 & 1 & \vrule & -2 \\ -1 & 3 & -1 & \vrule & 1 \\ 1 & -1 & 1 &\vrule & 2 \end{pmatrix} \sim $
	$\begin{pmatrix} 1 & 2 & 1 & \vrule & -2 \\ 0 & 5 & 0 & \vrule & -1 \\ 0 & 0 & -1 &\vrule & 5 \end{pmatrix} \sim $
	$\begin{pmatrix} 1 & 2 & 0 & \vrule & 3 \\ 0 & 1 & 0 & \vrule & \frac{-1}{5} \\ 0 & 0 & 1 &\vrule & -5 \end{pmatrix} \sim $
	$\begin{pmatrix} 1 & 0 & 0 & \vrule & \frac{17}{5} \\ 0 & 1 & 0 & \vrule & \frac{-1}{5} \\ 0 & 0 & 1 &\vrule & -5 \end{pmatrix} $
	\par\bigskip
	
	$b_1 = \dfrac{17}{5}a_1 - \dfrac{1}{5}a_2 - 5 b_2$
	
	$b_1 + 5 b_2 = \dfrac{17}{5}a_1 - \dfrac{1}{5}a_2 $
	
	$b_1 + 5 b_2 =(-2, 1, 2) + (5,-5,5)=(3,-4,7)$
	
	$\dfrac{1}{5}(17a_1 - a_2) = \dfrac{1}{5}((17,-17,34) - (2,3,-1)) = \dfrac{1}{5}(15,-20,35) = (3,-4,7)$ --- базис $L_1\cap L_2$
	
	\section{Пространство решений однородной линейной системы уравнений.}
	$\quad \; \ $Пусть
	$\begin{cases}
		\alpha_{11}x_1+...+\alpha_{1n}x_n=0 \\
		\alpha_{21}x_1+...+\alpha_{2n}x_n=0 \\
		\qquad\qquad...\\
		\alpha_{m1}x_1+...+\alpha_{mn}x_n=0
	\end{cases}$ --- однородная линейная система уравнений (ОСЛУ).
	\par\bigskip
	В матричной форме ОСЛУ записывается в форме $AX = 0$, где
	\par\bigskip
	$A = \begin{pmatrix} \alpha_{11} & ... & \alpha_{1n} \\ ... & ... & ...\\ \alpha_{m1} & ... & \alpha_{mn} \end{pmatrix} \in P_{m,n}$ --- матрица системы, 
	\par\bigskip
	$X = \begin{pmatrix} x_1 \\ ...\\ x_n \end{pmatrix}$ --- столбец неизвестных,
	\par\bigskip
	0 --- нулевой столбец.
	
	Также имеет место быть запись $A_1 x_1 + ... + A_n x_n = 0$, где $A_i = \begin{pmatrix} \alpha_{1i} \\ ...\\ \alpha_{mi}\end{pmatrix}$.
	
	Однородная система линейных уравнений всегда имеет нулевое решение, а каждое решение $x$ является элементом поля $P_n$ $\Rightarrow$ множество решений ОСЛУ  --- непустое подмножество ВП $P_n$.
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Множество решений ОСЛУ над полем $P$ с $n$ неизвестными является подпространством пространства $P_n$ размерностью $n-rankA$.}
	\par\bigskip
	$\blacklozenge$ Пусть $L$ - множество решений ОСЛУ. Тогда $L\ne \{\O\}$.
	
	$\quad$Покажем, что $L$ является подпространством $P_n$. Пусть $b,c\in L$,\  $b\ (\beta_1,...,\beta_n), c\ (\gamma_1,...\gamma_n)$ 
	
	$\quad$--- решения системы.
	
	$\quad A_1\beta_1 + ... + A_n\beta_n = 0$
	
	$\quad A_1\gamma_1 + ... + A_n\gamma_n = 0$
	
	$\quad b+c\in L \Rightarrow A_1(\beta_1 + \gamma_1)+...+A_n(\beta_n + \gamma_n) = 0 \Rightarrow (\beta_1 + \gamma_1, ..., \beta_n + \gamma_n)\in L$
	
	$\quad \alpha b \in L, \forall \alpha \in P \Rightarrow A_1(\alpha \beta_1) + ... + A_n(\alpha \beta_n) = \alpha \underbrace{( A_1 \beta_1 + ... + A_n\beta_n)}_{=0} = 0\Rightarrow$
	
	$\quad \Rightarrow (\alpha \beta_1, ..., \alpha \beta_n)\in L$ 
	
	$\quad$Из уравнений выше следует, что $L\subset P_n$
	
	$\quad$Покажем, что $dim L = n - rank A$:
	
	$\quad$Если $rankA = 0 $, то $A = 0\Rightarrow \forall \ x\in P_n \ AX = 0 \Rightarrow L = P_n,\ dimL = n \Rightarrow n=n-0$.
	
	$\quad$Если $rankA = n$, то $A_1,...,A_n$ --- ЛНЗ, $A_1 x_1 + ... + A_n x_n = 0$ $\Rightarrow x_i = 0, i = \overline{1,n} \Rightarrow $
	
	$\quad X = 0 \Rightarrow L=\{0\} \Rightarrow dimL = 0$.
	
	$\quad$Если $rankA = k$, $0<k<n$, то $A_1,...,A_k$ --- ЛНЗ $\Rightarrow A_1,...A_k$ --- базис   
	\par\bigskip
	$\quad\begin{cases}
		\beta_{11}A_1+...+\beta_{1k}A_k + A_{k+1}=0 \\
		\beta_{21}A_1+...+\beta_{2k}A_k + A_{k+2}=0 \\
		\qquad\qquad\qquad...\\
		\beta_{(n-k)1}A_1+...+\beta_{(n-k)k}A_k + A_n=0
	\end{cases} \Rightarrow
	\begin{cases}
		b_1 = (\beta_{11},...,\beta_{1k},1,0,...0) \\
		b_2 = (\beta_{21},...,\beta_{2k},0,1,...0) \\
		\qquad\qquad\qquad...\\
		b_{n-k} = (\beta_{(n-k)1},...,\beta_{(n-k)k},0,0,...1)
	\end{cases}  $ --- 
	\par\bigskip
	$\quad$решения системы. Покажем, что $b_1,b_2,...,b_{n-k}$ образуют базис пространства решений. 
	
	$\quad$Запишем эти последовательности в виде матрицы по строкам.
	\begin{center}
		$\begin{pmatrix} \beta_{11} & ... & \beta_{1n} & 1 & 0 & ... & 0 \\ \beta_{21} & ... & \beta_{2n} & 0 & 1 & ... & 0 \\... & ... & ... & ... & ... & ... & ...\\ \beta_{k1} & ... & \beta_{kn} & 0 & 0 & ... & 1 \end{pmatrix}$
	\end{center}
	$\qquad \, \ $ Крайние $n-k$ столбцов образуют единичную матрицу, они также являются базис-
	
	$\quad$ ным минором, так как матрица невырожденная. Следовательно, строки $b_1,...,b_{n-k}$ 
	
	$\quad$ образуют базис системы строк, а значит они линейно независимы.
	
	$\quad$ Покажем, что любое решение системы линейно выражается через эти последова-
	
	$\quad$ тельности. Пусть $c = (\gamma_1,...,\gamma_n)\in L, \ d = c - \gamma_{k+1}b_1 - \gamma_{k+2}b_2 - ... - \gamma_nb_{n-k}\Rightarrow d \in L$
	
	$\quad\  d = (\delta_1,...,\delta_k,0,0,...,0) \Rightarrow A_1\delta_1 + ... + A_k\delta_k = 0.$ Так как $A_1,...,A_k$ --- ЛНЗ, то $\delta_1=$
	
	$\quad\ ...=\delta_k=0 \Rightarrow d=0\Rightarrow  c=\gamma_{k+1}b_1 - \gamma_{k+2}b_2 - ... - \gamma_nb_{n-k} \Rightarrow b_1,...,b_{n-k}$ образуют базис 
	
	$\quad$ пространства решений. $\Rightarrow dimL = n-k = n - rankA. \quad \boxtimes$ 
	
	
	
	
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	$AX = 0, X \ne 0 \Longleftrightarrow dimL > 0 \Longleftrightarrow n-rankA>0 \Longleftrightarrow n > rankA$.
	\par\bigskip
	$\bullet$\textit{ Базис пространства решений ОСЛУ называется \textbf{фундаментальной системой решений}.}
	\par\bigskip
	\textbf{Пример:}
	
	Найти ФСР и общее решение системы:
	
	$\begin{cases}
		3x_1-6x_2-x_3+8x_4=0 \\
		2x_1-4x_2-3x_3+3x_4=0 \\
		x_1-2x_2-3x_3=0 \\
	\end{cases}$
	\par\bigskip
	Составляем матрицу и приводим её к частично-мономиальному виду
	\par\bigskip
	$\begin{pmatrix} 3 & -6 & -1 & 8 \\ 2 & -4 & -3 & 3\\ 1 & -2 & -1 & 0 \end{pmatrix}\sim$
	$\begin{pmatrix} 1 & -2 & -3 & 0 \\ 0 & 0 & 8 & 8\\ 0 & 0 & 3 & 3 \end{pmatrix}\sim$
	$\begin{pmatrix} 1 & -2 & -3 & 0 \\ 0 & 0 & 1 & 1 \end{pmatrix}$
	\par\bigskip
	Первый и четвёртый столбцы образуют частично-мономиальную матрицу. Возьмём их в качестве базисных. Тогда $x_2, x_3$ объявим свободными неизвестными $\alpha$ и $\beta$ соответственно. Следовательно, $x_2$ и $x_3$ можно линейно выразить через базис:
	
	$\begin{cases}
		x_1 = 2\alpha + 3\beta \\
		x_2 = \alpha \\
		x_3 = \beta \\
		x_4 = -\beta
	\end{cases}$
	
	Тогда $(x_1,x_2,x_3,x_4) = (2\alpha + 3\beta, \alpha, \beta, -\beta), \ \alpha, \beta \in R,$ является общим решением системы.
	\par\bigskip
	$\quad\left.
	\begin{aligned}
		X_1 &= (2,1,0,0) \\
		X_2 &= (3,0,-1,1) \\
	\end{aligned}
	\right\}$ --- фундаментальная система решений, $X = \alpha X_1 + \beta X_2$.
	
	\section{Критерий совместности линейных неоднородных систем уравнений.}
	$\quad \; \ $Пусть
	$\begin{cases}
		\alpha_{11}x_1+...+\alpha_{1n}x_n=b_1 \\
		\alpha_{21}x_1+...+\alpha_{2n}x_n=b_2 \\
		\qquad\qquad...\\
		\alpha_{m1}x_1+...+\alpha_{mn}x_n=b_m
	\end{cases}$ --- линейная неоднородная система.
	\par\bigskip
	Или в матричной форме $AX = B$, где
	\par\bigskip
	$A = \begin{pmatrix} \alpha_{11} & ... & \alpha_{1n} \\ ... & ... & ...\\ \alpha_{m1} & ... & \alpha_{mn} \end{pmatrix} \in P_{m,n}$, 
	$X = \begin{pmatrix} x_1 \\ ...\\ x_n \end{pmatrix}$, $B = \begin{pmatrix} b_1 \\ ...\\ b_m \end{pmatrix}$ --- столбец неоднородности.
	\par\bigskip
	Также имеет место быть запись $A_1 x_1 + ... + A_n x_n = B$, где $A_i = \begin{pmatrix} \alpha_{1i} \\ ...\\ \alpha_{mi}\end{pmatrix}$. 
	
	$\tilde{A}=(A_1,...,A_n,B) = (A|B)$ --- расширенная матрица системы.
	\par\bigskip
	\textbf{Теорема Кронекера-Капелли (Критерий совместности линейных неоднородных систем)}
	
	\textit{Линейная неоднородная система уравнений совместна $\Longleftrightarrow$ $rank A = rank\tilde{A}$.}
	\par\bigskip
	
	$\blacklozenge$ $\Rightarrow)$ Пусть $AX = B$ совместна. $\exists\  \alpha_1 A_1 + ... + \alpha_n A_n = B \Rightarrow B$ линейно выражается 
	
	$\quad$через $A_1,...,A_n \Rightarrow L(A_1,...,A_n,B) =L(A_1,...,A_n) \Rightarrow dim(A_1,...,A_n,B) = dim(A_1,...,A_n)\Rightarrow$ 
	
	$\quad rank(A_1,...,A_n,B) = rank(A_1,...,A_n) \Rightarrow rank\tilde{A} =rank A$.
	
	$\quad \Leftarrow)$ Пусть $rank\tilde{A} =rank A$. Тогда $ rank(A_1,...,A_n,B) = rank(A_1,...,A_n) \Rightarrow$
	
	$\quad dimL(A_1,...,A_n,B) = dimL(A_1,...,A_n).$ Значит $L(A_1,...,A_n) \subseteq L(A_1, ..., A_n, B)$, по тео-
	
	$\quad$реме о монотонности размерности $\Rightarrow L(A_1,...,A_n)=L(A_1, ..., A_n, B) \Rightarrow B$ линейно 
	
	$\quad$выражается через $A_1,...,A_n \Rightarrow B =  \alpha_1 A_1 + ... + \alpha_n A_n \Rightarrow (\alpha_1,...,\alpha_n)$ --- решение системы 
	
	$\quad AX = B$. А значит система совместна. $\quad \boxtimes$
	\par\bigskip
	$\bullet$\textit{ Система $AX = 0$ называется \textbf{приведенной} однородной системой для $AX = B$.}
	\par\bigskip
	\textbf{Теорема}
	
	Если $X = (x_1,...,x_n)$ --- решение системы  $AX=B$, а $L_o$ --- множество решений приведенной системы $AX = 0$, то $L = \{ x + y \ | \ \forall \ y\in L_o \}$ --- множество решений $AX = B$.
	\par\bigskip
	$\blacklozenge$ Пусть $\forall \ y \in L_o : y = (y_1,...,y_n) \Rightarrow Ay_1+...+Ay_n = 0$. Построим последовательность
	
	$\quad x+y$, тогда:
	
	$\quad A_1(x_1 + y_1) + ... + A_n(x_n + y_n)=(A_1 x_1 + ... + A_n x_n) + (A_1 y_1 + ... + A_n y_n) = B + 0 = B$.
	
	$\quad$Пусть $\forall \ Z\in L : Z(z_1,...z_n) \Rightarrow A_1z_1 + ... + A_nz_n = B$. Возьмём $y$ : $y=z-x$ и построим 
	
	$\quad$последовательность
	$Ay = A(z-x) = Az - Ax = B - B=0 \Rightarrow Ay = 0, y = L_o. \quad \boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	$AX = B, A\in P_{m,n}$ имеет единственное решение $\Longleftrightarrow$ $rankA - rank\tilde{A} = n$.
	\par\bigskip
	$\blacklozenge \ rankA = n \Longleftrightarrow L=\{0\}, AX = 0 \Rightarrow X = 0. \quad \boxtimes$
	
	\chapter{Линейные операторы}
	
	
	
	
	
	\section{Определение и простейшие свойства линейных операторов:}
	$\quad\ $Пусть $V,U$ --- векторные пространства над $P$. Отображение $f : V \rightarrow U$ называется \textbf{линейным оператором} (линейным отображением), если
	
	\begin{enumerate}
		\item $f(a+b) = f(a) + f(b),\quad \forall a,b \in V$
		\item $f(\alpha a) = \alpha f(a), \quad \forall a\in V,\  \forall \alpha \in P$
	\end{enumerate}
	
	\textbf{Примеры линейных отображений}
	
	\begin{enumerate}
		\item Изоморфизм
		\item $f : V\rightarrow V\quad f(a) = a \quad \forall a\in V$
		\item $f:v\rightarrow U\quad f(a) = \overrightarrow{0}\quad\forall a\in V$
		\item $D: P[x] \Rightarrow P[x]\quad f(g) = g'$, $f(x) \mapsto f'(x)\quad D(f(x)) = f'(x)$
		\item $P_{n,n} \rightarrow P_{n,n}\quad A\mapsto BA, \forall A\in P_{n,n}$
		\item Оператор поворота $V_2$
	\end{enumerate}
	
	\textbf{\textit{Свойства линейных операторов:}}
	
	\begin{enumerate}
		\item $f(0_v) = 0_v$
		
		$f(-a) = -f(a), \quad \forall a\in V$
		
		$\blacklozenge \ f(0_v) = f(0\cdot 0_v) = 0\cdot f(0_v) = 0_v$
		
		$\quad f(-a) = f((-1)\cdot a) = (-1)\cdot f(a) = -f(a) \quad \boxtimes$
		
		\item $f: V\rightarrow V$ отображает ЛЗ систему векторов в ЛЗ систему векторов.
		
		$\blacklozenge$ Пусть $A(a_1,...a_n)$ --- ЛЗ $\Rightarrow \exists\  \alpha_1 a_1 + ... + \alpha_n a_n = 0_v$
		
		$\quad f(A) = (f(a_1),...f(a_n))$
		
		$\quad \alpha_1 f(a_1) + ... + \alpha_n f(a_n) = f(\alpha_1 a_1 + ... + \alpha_n a_n) = f(0_v) = 0_v \Rightarrow f(A) = (f(a_1),...,f(a_n))$ 
		
		$\quad$--- ЛЗ система векторов. $\quad \boxtimes$
		
		\textit{\textbf{Следствие}}
		
		$\forall A(a_1,...,a_n)\Rightarrow rank f(A) \leqslant rank A$
		\item Если $f:V\rightarrow V$ и $A(a_1,...,a_n)\Rightarrow f(A) = (f(a_1),...f(a_n))$, то $f(L(A)) = L(f(A))$
		
		$\blacklozenge$ Доказательство следует из равенства $f(\alpha_1 a_1 + ... + \alpha_n a_n) = \alpha_1 f(a_1) + ... + \alpha_n f(a_n)$
		
		$\quad\forall\alpha_i\in P:i=\overline{1,n}\quad\boxtimes$
		\item Если $U\subseteq V$, то $f(U) \subseteq V,\ dimf(U) \leqslant dimU$
		
		$\blacklozenge$ Пусть $A(a_1,...,a_n)$ --- базис $U$, для которого $U = L(A)$.
		
		$\quad$Тогда $f(U) = f(L(A))=L(f(A))\Rightarrow f(U) \subseteq V$
		
		$\quad dim f(U) = dim f(L(A)) = dim L(f(A)) = rank f(A) \leqslant rank A = dim L(A) = dim U;$
		
		$\quad$то есть $dimf(U) \leqslant dimU\quad\boxtimes$
	\end{enumerate}
	
	
	
	
	
	
	
	
	
	\section{Матрица линейного оператора.}
	$\quad\;\ $\textbf{Теорема}
	
	\textit{Пусть $V$ --- векторное пространство над $P$, $dim V = n$, $A(a_1,...,a_n)$ --- базис $V$, $B(b_1,...,b_n)$ --- некоторая система векторов пространства $V$. Тогда $\exists! f:V\rightarrow V : f(a_i) = b_i, \ i = \overline{1,n}$.}
	\par\bigskip
	$\blacklozenge$ Вследствие того, что $A$ --- базис $V$, любой вектор $c$ можно представить в виде 
	
	$\quad c = \alpha_1a_1 + ... + \alpha_n a_n$. Покажем, что $f(c) = \alpha_1 b_1 + ... + \alpha_n b_n$.
	\par\bigskip
	$\quad$ \underline{1 cвойство:}
	
	$\quad$1) Вектор $a_i$ в базисе $A$ имеет разложение $a_i = 0\cdot a_1 + .... + 0\cdot a_n$. Тогда
	
	$\quad f(a_i) = 0\cdot b_1 + .... + b_i + ... + 0\cdot b_n = b_i,\ i = \overline{1,n}.$
	
	$\quad$2) $\forall c, d \in V,\ c = \alpha_1 a_1 + ... + \alpha_n a_n, d = \beta_1 a_1 + ... + \beta_n a_n \Rightarrow (\alpha_1 + \beta_1) a_1 + ... + (\alpha_n + \beta_n) a_n =$
	
	$\quad = c+d$
	
	$\quad f(c+d) = (\alpha_1 + \beta_1) b_1 + ... + (\alpha_n + \beta_n) b_n = (\alpha_1 b_1 + ... + \alpha_n b_n) + (\beta_1 b_1 + ... + \beta_n b_n) = f(c) + f(d)$.
	\par\bigskip
	$\quad$ \underline{2 cвойство:}
	
	$\quad \forall\ \alpha \in P,\ f(\alpha c) = \alpha \alpha_1 b_1 + ... + \alpha \alpha_n b_n = \alpha(\alpha_1 b_1 + ... + \alpha_n b_n) = \alpha f(c) \Rightarrow f$ --- линейный 
	\par
	\quad оператор.
	\par\quad3) Пусть $g:V\rightarrow V$ --- линейное отображение: $g(a_i) = b_i,\ i = \overline{1,n},$ Тогда $\forall c \in V$ 
	
	\quadможно представить в виде $c = \alpha_1 a_1 + ... + \alpha_n a_n$.
	
	$\quad g(c) = g(\alpha_1 a_1 + ... + \alpha_n a_n) = \alpha_1 g(a_1) + ... + \alpha_n g(a_n) = \alpha_1 b_1 + ... + \alpha_n b_n = f(c) \Rightarrow g = f \quad \boxtimes$
	\par\bigskip
	\textit{$\bullet$ Пусть $A = (a_1,...,a_n)$ --- базис $n$-мерного пространства $V$. $f:V\rightarrow V$ --- линейный оператор этого пространства такой, что $f(a_i) = \alpha_{1i} a_1 + \alpha_{2i} a_2 + ... + \alpha_{ni} a_n,\ i = \overline{1,n}.$}
	
	\textit{$A_i = \begin{pmatrix} \alpha_{1i} \\ \alpha_{2i} \\ ... \\ \alpha_{ni} \end{pmatrix} $ --- координатный столбец. Тогда матрица $A_1...A_n = M_f$ называется \textbf{матрицей линейного оператора} $f$ \textbf{в базисе} $A$ $($Обозначение $M_f^A$ или $M_f(A))$.}
	\par\bigskip
	Из определения следует, что $M_f$ является матрицей перехода $A = (a_1,...,a_n) \rightarrow f(A) = (f(a_1), ..., f(a_n)) : M_f = S_{A\rightarrow f(A)}$. 
	\par\bigskip
	\textbf{Пример:}
	\par
	$f:R_2\rightarrow R_1$ 
	\par
	$a_1(2,1),\ a_2(1,1),\ f(x,y) = (2x-3y, x+5y),\ X_a = \begin{pmatrix} 1\\ -1 \end{pmatrix}.$ 
	\par
	$f(x_1) = (1,7),\ f(x_2) = (-1, 6)$
	\par
	$\begin{pmatrix} 2 & 1 & \vline & 1 & -1 \\ 1 & 1 & \vline & 7 & 6 \end{pmatrix} \sim ... \sim \begin{pmatrix} 1 & 0 & \vline & -6 & -7 \\ 0 & 1 & \vline & 13 & 13 \end{pmatrix} \Rightarrow M_f \begin{pmatrix} -6 & -7 \\ 13 & 13 \end{pmatrix},$ 
	\par
	$X_{f(a)} = \begin{pmatrix} -6 & -7 & \vline & 1 \\ 13 & 13 & \vline & -1 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$
	\par\bigskip
	\textbf{Теорема}
	\par
	\textit{Пусть $V$ --- ВП, $dim V = n$, $A=(a_1,...,a_n)$ --- базис $V$, $f:V\rightarrow V$ --- линейный оператор, а $M_f$ --- матрица этого линейного оператора. Тогда координатный столбец $X_{f(a)} = M_f X_a,\ \forall\ a \in V$.}
	\par\bigskip
	$\blacklozenge\ f(a) = f(\alpha_1 a_1 + ... + \alpha_n a_n) = \alpha_1 f(a_1) + ... + \alpha_n f(a_n) = f(A) X_a$, \par\quadгде $f(A)$ --- матрица-строка $(f(a_1),...,f(a_n))$.\par
	$\quad f(A) = A\cdot S_{A\rightarrow f(A)} = A\cdot M_f\Rightarrow f(a) = (A\cdot M_f) X_A = A(M_f X_A) \Rightarrow X_{f(a)} = M_f X_a. \quad \boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Пространство линейных операторов.}
	$\quad\; \bullet$ \textit{Линейный оператор $f:V\rightarrow V$ (оператор пространства $V$ в себя) называется \textbf{линейным оператором} или \textbf{линейным преобразованием} пространства $V$. Множество линейных операторов обозначается $End(V)$.}
	\par\bigskip
	Пусть $V$ --- $n$-мерное пространство над $P$, а $f$ и $g$ --- линейные операторы пространства $V$ ($f, g \in End(V))$.
	\par\bigskip
	$\bullet$\textit{\textbf{ Суммой операторов} $f$ и $g$ называется отображение $(f + g) : V\rightarrow V$ такое, что }
	\begin{center}
		$(f+g)(a) = f(a) + g(a)\quad \forall\ a \in V$
	\end{center}
	
	$\bullet$\textit{\textbf{ Произведением оператора $f$ на скаляр $\alpha$} называется отображение $(\alpha f) : V\rightarrow V$ такое, что }
	\begin{center}
		$(\alpha f)(a) = \alpha f(a)\quad \forall\ a \in V$
	\end{center}
	
	$\bullet$\textit{\textbf{ Композицией операторов} $f$ и $g$ называется отображение $(g \circ f) : V\rightarrow V$ такое, что }
	\begin{center}
		$(g \circ f)(a) =g(f(a))\quad \forall\ a \in V$
	\end{center}
	
	\textbf{Теорема}
	
	\textit{Если $f$ и $g\in End(V)$, то $(f+g), (\alpha f), (g\circ f) \in End(V)$, причем для матриц этих операторов в фиксированном базисе справедливы равенства:}
	
	\begin{center}
		$M_{f+g} = M_f + M_g,\quad M_{\alpha f} = \alpha M_f,\quad M_{g \circ f} = M_g M_f$
	\end{center}
	
	$\blacklozenge$ Доказательство проводится для случая $f+g$. Для остальных случаев доказательство аналогично.
	
	$\quad$1) $(f+g)(a+b) = f(a+b) + g(a+b) = f(a) + f(b) + g(a) + g(b) = f(a) + g(a) + f(b) + g(b) =$ 
	
	$\quad (f+g)(a) + (f+g)(b),\quad \forall\ a,b \in V$
	
	$\quad$2) $(f+g)(\alpha a) = f(\alpha a) + g(\alpha a) = \alpha f(a) + \alpha g(a) = \alpha (f(a) + g(a)) = \alpha (f+g)(a), $
	
	$\quad \forall\ a \in V,\ \forall\ \alpha \in P$
	
	$\quad$Из доказанного выше следует, что $(f+g)\in End(V)$.
	
	$\quad$Теперь покажем, что $M_{g\circ f} = M_g M_f$. Пусть $M_f = (\alpha_{ij}) \in P_{n,n}, M_g = (\beta_{ij})\in P_{n,n}$ --- 
	
	$\quad$матрицы операторов $f$ и $g$ в базисе $A = (a_1,...,a_n)$. Тогда $f(a_j) = \alpha_{1j} a_1 + ... + \alpha_{nj} a_n$,
	
	$\quad g(a_j) = \beta_{1j} a_1 + ... + \beta_{nj} a_n,\ j=\overline{1,n}$.
	
	$\quad (g\circ f)(a_j) = g(f(a_j)) = g(\alpha_{1j} a_1 + ... + \alpha_{nj} a_n) = \alpha_{1j} g(a_1) + ... + \alpha_{nj} g(a_n) =$ 
	
	$\quad \alpha_{1j} (\beta_{1j} a_1 + ... + \beta_{nj} a_n) + ... + \alpha_{nj} (\beta_{1n} a_1 + ... + \beta_{nn} a_n) =$ 
	
	$\quad (\alpha_{1j}\beta_{11} + ... + \alpha_{nj}\beta_{1n}) a_1 + ... + (\alpha_{1j} \beta_{n1} + ... + \alpha_{nj} \beta_{nn}) a_n \Rightarrow M_{g\circ f} = M_g M_f\quad \boxtimes$
	\par\bigskip
	\textbf{Теорема}
	\par
	\textit{$End (V)$ над полем $P$ является векторным пространством относительно операций $f+g$ и $\alpha f$}
	\par\bigskip
	$\blacklozenge\ (f+g)(a+b) = f(a) + g(b) + f(b) + g(a) = (f+g)(a) + (f+g)(b)$ по определению. $\boxtimes$
	\par\bigskip
	\textbf{Теорема}
	\par
	\textit{$End(V)$ изоморфно пространству матриц. ($\varepsilon$-изоморфизм.)}
	\par
	\textit{Пусть $A$ --- базис $V$, $\varepsilon:End(V) \rightarrow P_{n,n}$. Тогда $\varepsilon(f) = M_f$.}
	\par\bigskip
	$\blacklozenge$ Пусть $f, g \in End(V),\ \exists\ a \in V,\ f(a)\ne g(a) \Rightarrow M_f X_a \ne M_g X_a \Rightarrow (M_f - M_g) X_a \ne 0 \Rightarrow$
	\par
	$\quad M_f - M_g \ne 0 \Rightarrow M_f \ne M_g \Rightarrow \varepsilon(f) \ne \varepsilon (g) \Rightarrow \varepsilon$ --- инъекция.
	\par\bigskip
	$\quad \forall \varepsilon \in P_{n,n}\ \exists\ f \in End(V) : \varepsilon(f) = c$, и пусть $A = (a_1,...,a_n)$ --- базис, $c = (\gamma_{i,j})$. Тогда $\exists$ 
	
	$\quad$линейный оператор, который отображает векторы $a_i$ в $b_i = \gamma_{1,j} a_1 +...+\gamma_{n,j} a_n,\ j=\overline{1,n},$ 
	
	\quad--- вектора базиса $(b_1,...,b_n)$, $f(a_i) = b_i,\ i=\overline{1,n}$, и матрица этого оператора совпадает
	
	\quadс матрицей $c$. $\Rightarrow \varepsilon$ --- сюръекция. А значит и биекция [сюръекция + инъекция =
	
	\quad= биекция]. 
	
	\par\bigskip
	$\quad \varepsilon(f+g) = M_f + M_g = \varepsilon(f) + \varepsilon(g),$
	\par
	$\quad \varepsilon(\alpha f) = M_{\alpha f} = \alpha \varepsilon_f, \qquad \forall f,g \in End(V), \forall \alpha \in P$.
	\par
	$\quad$Следовательно, отображение линейно. $\quad\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	\section{Ранг и дефект линейного оператора.}
	$\quad \; \ $Пусть $f:V\rightarrow V$, где $V$ --- $n$-мерное векторное пространство над $P$.
	\par\bigskip
	\textit{$\bullet$ Множество векторов $f(V) = Imf = \{f(a)\ |\ a\in V\}$ называется \textbf{образом} оператора $f$.}
	
	\textit{$\bullet$ Множество векторов $Ker f = \{a\in V\ |\ f(a) = 0_v\}$ называется \textbf{ядром} оператора $f$.}
	\par\bigskip
	\textbf{Теорема}
	
	\textit{$f(V) \subseteq V,\ Ker f \subseteq V$}.
	\par\bigskip
	$\blacklozenge\ 1.\ \forall\ U \subseteq V \Rightarrow f(U) \subseteq V,\ V \subseteq V\Rightarrow f(V) \subseteq V\Rightarrow Imf \subseteq V$
	
	$\quad$2. $f(0_v) = 0_v \Rightarrow 0_v \in Ker f \Rightarrow Kerf \ne \{\varnothing\}$.
	
	$\quad \forall\ a,b \in Ker f,\ f(a+b) = f(a) + f(b) = 0_v + 0_v = 0_v \Rightarrow (a+b) \in Ker f$.
	
	$\quad \forall\ \alpha \in P,\ f(\alpha a) = \alpha  f(a) = \alpha \cdot 0_v = 0_v,\ \forall \alpha \in P\Rightarrow\alpha a \in Kerf,\ Kerf \subseteq V$. $\quad \boxtimes$
	\par\bigskip
	\textit{$\bullet$ $rankf = dim (Im f)$ --- \textbf{ранг} линейного оператора.}
	
	\textit{$\bullet$ $def f = dim (Ker f)$ --- \textbf{дефект} линейного оператора.}
	\par\bigskip
	\textbf{Теорема}
	\par
	\textit{$f:V\rightarrow V$ --- инъекция $\Longleftrightarrow Kerf = \{0_v\}$}.
	\par\bigskip
	$\blacklozenge \Rightarrow)\ f:V\rightarrow V$ --- инъекция $\Rightarrow f(0_v) = 0_v$. Так как инъективный оператор отображает 
	
	$\quad$различные элементы в различные, то $\nexists\ \vec{a} : f(a) = 0_v$ $\Rightarrow Kerf = \{ 0_v \}$.
	
	$\quad \Leftarrow )$ Пусть $Kerf = \{ 0_v \}$ и $\exists\ a,\ b\in V : a\ne b,\ f(a) = f(b) \Rightarrow f(a) - f(b) = 0_v \Rightarrow$
	
	$\quad f(a-b) = 0_v \Rightarrow \underset{\ne 0_v}{a-b} \in Kerf \Rightarrow\nexists\ a \ne b$ --- противоречие. Значит $f$ --- инъекция. $\quad\boxtimes$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $M_f$ --- матрица оператора $f:V\rightarrow V$ в базисе $A(a_1,...,a_n)$, тогда }
	
	1) $rank f = rank M_f$; 
	
	2) $deff = dim V - rank f$.
	\par\bigskip
	$\blacklozenge$ 1) $rank f= dim(Imf)=dimf(V) = dimf(L(A)) = dim L(f(A)) = dimL(f(a_1,...,a_n)) =$ 
	
	$\qquad = rank f(A)$.
	
	$\qquad rank(f(a_1),...,f(a_n))=rank M_f \Rightarrow rank f(A)= rank M_f \Rightarrow rankf = rank M_f$.
	
	$\quad$2) Пусть $a \in V$, $X_a = \begin{pmatrix} \alpha_1 \\ ... \\ \alpha_n \end{pmatrix}$, тогда $X_{f(a)} = M_f X_a$. 
	
	$\qquad\ a=\alpha_1 a_1 + ... + \alpha_n a_n$; $a\in Kerf \Longleftrightarrow f(a) = 0_v \Rightarrow M_f X_a = 0$.
	
	$\qquad$ Значит ядро состоит из векторов, координатные столбцы которых совпадают с 
	
	$\qquad$ множеством решений системы, $def f = dim(Ker f) = dimV-rankM_f = $
	
	$\qquad\ = dimV - rankf.\quad\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	\section{Изменение матрицы линейного оператора при замене базиса. Подобные матрицы.}
	$\quad \;\ $Пусть $A, B \in P_{n,n}.$
	
	$\bullet$\textit{ Матрица $B$ \textbf{подобна} матрице $A$, если $\exists$ невырожденная матрица $S  \in P_{n,n}, \ \det S \not= 0$}:
	
	$B = S^{-1}AS \Rightarrow B \sim A.$
	
	$\bullet \ S$ \textit{--- \textbf{траснформирующая матрица} (трансформирует матрицу $A$ в $B$)}
	\par\bigskip
	\textit{ \textbf{Свойства подобия:}}
	\begin{enumerate}
		\item  \textit{Отношение подобия матриц} \textit{--- отношение эквивалентности}
		
		$\blacklozenge$ \ a)  рефлексивность$ \ (A \ \sim A): S = E_n,  \ A = E_n^{-1}AE_n$
		
		$\quad$ $ $б$) \ $симметричность$ \ (B \sim A \Rightarrow A \sim B) :$
		
		$\quad$ $ \ \ \  B = S^{-1}AS \Rightarrow S^{-1}BS  = A \Rightarrow B \sim A$
		
		$\quad$ $ \ \ \  A = SBS^{-1}, \ S_1 = S^{-1}, \ A = S_1^{-1}BS_1 \Rightarrow A \sim B$
		
		$\quad$ $ $в$) \ $транзитивность$ \ (A \sim B, B \sim C \Rightarrow A \sim C) :$
		
		$\quad$  $\ \ \  A \sim B : A = S_1^{-1}BS_1, \ B \sim C : B = S_2^{-1}CS_2 \Rightarrow C = S_2BS_2^{-1}$
		
		$\quad$ $\ \  A= S_1^{-1}(S_2^{-1}CS_2)S_1 = [S_1^{-1}S_2^{-1} = (S_2S_1)^{-1}] = S_1^{-1}S_2^{-1}CS_2S_1 = [S_2S_1 = S] = S^{-1}CS \Rightarrow A \sim C$
		
		$\quad$ $ \ \ \ S_1 = S_2 \quad \boxtimes$
		
		\item  \textit{Ранги подобных матриц равны:  $rankB = rankA$, если $B = S^{-1}AS$ (если в произведении одна из матриц невырожденная, то ранг произведения равен рангу другой матрицы в произведении).}
		
		\fbox{Вспомнить: $A = BC, \exists\  C^{-1}, \ rank A = rank B$}
		
		$\blacklozenge \ \det S \not= 0, \ B = (S^{-1}A)S \Rightarrow rank B = rank (S^{-1}A), \ \det S^{-1} \not= 0$ 
		
		$\quad$ $rank(S^{-1}A) = rank A \Rightarrow rank B = rank A \quad \boxtimes$
		
		\item \textit {$B = S^{-1}AS \Rightarrow \det B = \det A$}
		
		$\blacklozenge$ \ $ \det B = \det (S^{-1}AS) = \det S^{-1} \cdot \det A \cdot \det S = \dfrac 1{\det S} \cdot \det S \cdot \det A = \det A \quad \boxtimes$
		
		\par\bigskip
	\end{enumerate}
	Пусть $f: V \rightarrow V$ --- линейный оператор пространства $V$ над полем $P$.
	$A,\  B$ --- базисы пространства $V$.
	\par\bigskip
	
	\textbf{Теорема}
	
	
	\textit{Матрицы $M^A$ и $M^B$ в базисах $A(a_1, \dots, a_n)$ и $B(b_1, \dots, b_n)$ соотвественно подобны, причем матрица, трансформирующая  $M^A$ в $M^B$ является матрицей перехода от базиса $A$ к базису $B$, т.е.$M^B = (S_{A\rightarrow B})^{-1}M^AS_{A\rightarrow B}.$}
	
	$\blacklozenge\ $ Пусть произвольный вектор $a \in V. \ \ X_A = \begin{pmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{pmatrix}$ и $X_B = \begin{pmatrix} \beta_1 \\ \vdots \\ \beta_n \end{pmatrix}$ --- координатные 
	
	$\quad$ столбцы этого вектора в базисах A и B соотвественно, тогда $X^A = S_{A\rightarrow B} X^B.$ 
	
	$\quad$ (далее $S = S_{A\rightarrow B}$).
	
	$\quad$ Так как полученное соотношение верно для всех векторов пространства $V$, то оно 
	
	$\quad$ верно и для вектора $b_1$ $\Rightarrow$ первые столбцы матриц $M^A S$ и $SM^B$ равны. Продолжая 
	
	$\quad$ рассуждения аналогичным образом и используя остальные вектора базиса $B$, полу-
	
	$\quad$ чим равенства столбцов матрицы, а значит $M^A S = SM^B$. А так как $S$ --- матрица 
	
	$\quad$ перехода от базиса к базису, то она невырожденная  $\Rightarrow \ M^B = S^{-1}M^A S$, где $S = $
	
	$\quad \ S_{A\rightarrow B}. \quad \boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Инвариантные подпространства.}
	$\bullet$ \textit{Пусть $f:{V \rightarrow V. \ U \subset V }$ --- \textbf{инвариантно относительно} $V$, если $f(U) \subset U$.}
	\par\bigskip
	\textbf{Примеры:}
	\begin{enumerate}
		\item $\{0_V\}, V;$
		\item $\mathop{\text{Im}}f;$
		\item $\ker f, \forall a \in \ker f$, где $f(a) = \{0_V\}.$
	\end{enumerate}
	%\par\bigskip
	\textit{ \textbf{Свойства инвариантных подпространств:}}
	\begin{enumerate}
		\item $f:{V \rightarrow V}, \ U_1, \ U_2$ \textit{--- инвариантны относительно} $f$ $\Rightarrow$ \ $U_1 + U_2,\ U_1 \cap U_2$ \ \textit{--- инвариантны относительно} $f$
		
		$\blacklozenge \ f(U_1) \subset U_1, f(U_2) \subset U_2, \ a \in  U_1 + U_2 \Rightarrow a = a_1 + a_2,\ a_1 \in U_1, \ a_2 \in U_2.$
		
		$\quad f(a) = f(a_1 + a_2) = f(a_1) + f(a_2) \Rightarrow$ [из определения линейного оператора] $\Rightarrow f(a) \in$ 
		
		$\quad U_1 + U_2 \Rightarrow f(U_1 + U_2) \subset U_1 + U_2.$
		
		$\quad a \in U_1 \cap U_2 \Rightarrow a\in U_1,\ a \in U_2 \Rightarrow f(a) \in U_1, \ f(a) \in U_2 \ \Rightarrow f(a) \in U_1 \cap U_2 \Rightarrow $
		
		$\quad f(U_1 \cap U_2)  \in U_1 \cap U_2.  \quad \boxtimes$
		
		\item $U \subset V,\   f(U) \subset U,\  g(U) \subset U \Rightarrow (f + g)(U) \subset U,\  (\alpha f)(U) \subset U,\  (f \circ g)(U) \subset U.$
		
		$\blacklozenge \ a \in U \Rightarrow f(a) \in U, \ g(a) \in U \Rightarrow (f + g)(a) = f(a) + g(a) \Rightarrow (f + g)(a) \in U.$
		
		$\quad (\alpha f)(a) = \alpha f(a) \Rightarrow (\alpha f)(a) \in U.$
		
		$\quad  (f \circ g)(a) = f(g(a)) = (f \circ g)(a) \in U. \quad \boxtimes$
		
		\item  $f: V \rightarrow V,\  U \subset V, \ f(U) \subset U,\ f|_U : U \rightarrow U,\  f|_U = f(a)\  \forall a \in U,\  f|_U(a) = f(a)$.
		
	\end{enumerate}
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Если векторное пространство имеет нетривиальное инвариантное относительно оператора  $f$ подпространство, то  $\exists$ базис, в котором матрица оператора $f$ блочнотреугольная.}
	\par\bigskip
	$\blacklozenge\ dim V = n, \ U \in V, \ f(U) \in U$.
	
	$\quad dim U = k, \ 0<k<n, \ (a_1, ..., a_n)$ --- базис $U$.
	
	$\quad A = (\underbrace{a_1, ...,  a_k}_{U}, a_{k+1}, ... , a_n)$ --- базис $V$.
	
	$\quad$ $a_1 \in U \Rightarrow f(a_1) \in U \Rightarrow f(a_1) = \alpha_{11}a_1 + \dots + \alpha_{k1}a_k $
	
	$\quad$ $a_2 \in U \Rightarrow f(a_2) \in U \Rightarrow f(a_2) = \alpha_{12}a_1 + \dots + \alpha_{k2}a_k $
	
	$\quad$ $\dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots$
	
	$\quad$ $a_i \in U \Rightarrow f(a_i) \in U \Rightarrow f(a_i) = \alpha_{1i}a_1 + \dots + \alpha_{ki}a_k $
	
	$\quad$ $f(a_n) = \alpha_{1n}a_1 + \dots + \alpha_{kn}a_n + \dots + \alpha_{nn}$
	
	\par\bigskip
	$\quad M_f = $\left( \begin{tabular}{c|c}
		\begin{tabular}{cc} \begin{matrix} \alpha_1_1 & \alpha_1_2 & \dots & \alpha_1_k \\ \vdots & \dots & \dots & \vdots \\ \alpha_k_1 & \alpha_k_2 & \dots & \alpha_k_k \end{matrix} \end{tabular} & \begin{matrix} \alpha_1_,_k_+_1 & \dots & \alpha_1_n \\ \vdots & \dots & \vdots \\ \alpha_k_,_k_+_1 & \dots & \alpha_k_n \end{matrix} \\ \hline \begin{matrix} 0 \ \ & 0 & \dots & 0 \\ \vdots \ \ & \dots & \dots & \vdots \\ 0 \ \ & 0 & \dots & 0 \end{matrix} & \begin{matrix} \alpha_k_,_k_+_1 & \dots & \dots \\ \vdots & \dots & \vdots \\ \alpha_n_,_k_+_1 & \dots & \alpha_n_n \end{matrix} \end{tabular} \right)$
	
	\par\bigskip
	$\quad$ Блок $\begin{pmatrix} \alpha_{11} & \dots & \alpha_{1k}  \\ \dots & \dots & \dots \\ \alpha_{k1} & \dots & \alpha_{kk} \end{pmatrix}$ --- матрица линейного оператора $f|_U$ в базисе $(a_1, \dots, a_k). \quad \boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие 1}}
	
	\textit{$V = U_1 \oplus U_2,\ f: V \rightarrow V \Rightarrow f(U_1) \subset U_1,\ f(U_2) \subset U_2 $ $\Rightarrow$ \ $\exists$ базис, в котором матрица $f$ блочнодиагональная.}
	\par\bigskip
	$\blacklozenge\ dim (U_1 \oplus U_2) = dim U_1 + dim U_2$; \ $ A_1, \ A_2$ --- базисы $U_1,  U_2$.
	
	$\quad (A_1, A_2)$ --- базис $V$; $f(A_1)$ выражается через $A_1$; \ $f(A_2)$   --- через $A_2. \quad \boxtimes$
	\par\bigskip
	
	\textit{\textbf{Следствие 2}}
	
	\textit {Если векторное пространство является $ \oplus$ (прямой суммой) инвариантных относительно $f$ подпространств, то $\exists$ базис, где матрица $f$ блочнодиагональная.}
	
	$\bullet \ f: V \rightarrow V$ \textit{\textbf {--- оператор простой структуры}, если $\exists$ базис пространства $V$, в котором оператор $f$ имеет диагональную матрицу.}
	
	$\bullet$ \textit{\textbf{Диагонализируемая матрица} --- если имеет подобную диагональную матрицу.}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Собственные векторы и собственные значения линейного оператора.}
	$\quad \ $Пусть $f$: $V \rightarrow V$ --- линейный оператор над полем $P$.
	\par\bigskip
	$\bullet$ \textit{Если для некоторого $a$ $\not= 0_v$, $a \in V$ $\exists$ $\lambda \in P$ такое, что $f(a) = \lambda a$,  то $a$ --- \textbf{собственный}}
	
	\ \ \textit{\textbf{вектор}, a $\lambda$ --- \textbf{собственное значение.}}
	\par\bigskip
	Если $f(a)$ = 0, то $\forall$ $a$ $\in$ V все векторы собственные с $\lambda$ = 0.
	
	\par\bigskip
	\textit{ \textbf{Свойства:}}
	\begin{enumerate}
		\item \textit{Собственные векторы линейного оператора, соотвествующие попарно различным сосбственным значения линейно независимы.}
	\end{enumerate}  
	
	$\blacklozenge$ Пусть $A$ = ($a_1, \dots, a_k$) --- система векторов, состоящая из собственных векторов
	
	$\quad$оператора $f$, соотвествующих попарно различным собственным значениям $\lambda_1, \dots, \lambda_k$,
	
	$\quad$и предположим, что данная система векторов линейно зависима. Тогда базис сис-
	
	$\quad$темы векторов $A$ состоит из менее, чем $k$ векторов, и тогда будем считать, что 
	
	$\quad$подсистема $(a_1, \dots, a_s)$ --- базис системы $A$ (s < k). Тогда вектор $a_{s+1}$ выражается
	
	$\quad$через эту систему, т.е. $a_{s+1}$ = $\alpha_1a_1 + \ldots + \alpha_sa_s \Rightarrow$ \ $\lambda_{s+1}a_{s+1}$ =  $\alpha_1 \lambda_{s+1} a_1$ + $\dots$ + 
	
	$\quad$+ $\alpha_s \lambda_{s+1}a_s$. (1)
	
	$\quad$С другой стороны, $\lambda_s_+_1a_s_+_1$ = $f(a_s_+_1)$ = $f(\alpha_1a_1 + \ldots + \alpha_sa_s)$ = \ $\alpha_1 f(a_1) + \ldots + \alpha_sf(a_s)$
	
	$\quad$= $\alpha_1\lambda_1a_1 + \ldots + \alpha_s\lambda_sa_s$. (2)
	
	$\quad$Теперь от (1) отнимем (2) : $0_v = \alpha_1(\lambda_s_+_1  - \lambda_1)a_1 + \dots + \alpha_s(\lambda_s_+_1 - \lambda_s)a_s$ $\Rightarrow$
	
	$\quad \alpha_i(\lambda_{s+1}  - \lambda_i) = 0$ $\forall\ i = \overline{1, s}$.
	
	$\quad$Так как собственные значения $\lambda_i$ попарно различные, то $(\lambda_{s+1} - \lambda_i)$ $\not=$ 0 $\Rightarrow$ 
	
	$\quad \alpha_i = 0\ \forall i = \overline{1, s}  \ \Rightarrow a_{s+1} = 0_v \ \Rightarrow$ ПРОТИВОРЕЧИЕ с тем, что вектор $a_{s+1}$ --- 
	
	$\quad$собственный $\Rightarrow$ $(a_1, \dots, a_k)$ --- линейно независимая система. $\quad \boxtimes$
	\begin{enumerate}
		\item[2.] \textit{Ненулевая линейная комбинация собственных векторов, соответствующих одному собственному значению, является собственным вектором, соответствующим тому же собственному значению}.
	\end{enumerate}
	
	$\blacklozenge$ Пусть ($a_1, \dots, a_n)$ --- собственные векторы, \ $f(a_i) = \lambda_0 a_i$, где $i = \overline{1,n}$ 
	
	$\quad$ $f(\alpha_1a_1 + \ldots + \alpha_na_n)$ = $\alpha_1 f(a_1) + \ldots + \alpha_n f(a_n)$ = $\alpha_1 \lambda_0a_1 + \ldots + \alpha_n \lambda_0 a_n$ = 
	
	$\quad\ \lambda_0(\alpha_1 a_1 + \ldots + \alpha_n a_n)$. $\quad \boxtimes$
	
	
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{Множество, состоящее из всех собственных векторов, соответствующих собственному значению и $0_v$, является подпространством пространства $V$.}
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Одномерное подпространство инвариантно относительно линейного оператора $f$ $\Longleftrightarrow$ все его ненулевые векторы --- собственные векторы оператора $f$.}
	\par\bigskip
	$\blacklozenge$ $\Rightarrow)$ Пусть одномерное пространство $U$ инвариантно относительно линейного опера-
	
	$\quad$тора $f$. Тогда  $\forall$ $a$ $\in$ $U$, $a$ $\not=$ 0, $f(a)$ $\in$ $U$ $\Rightarrow$ $a$ --- базис $U$ $\Rightarrow$ $\exists$ $\lambda$ $\in$ $P$ такой, что
	
	$\quad$$f(a)$ = $\lambda$$a$ $\Rightarrow$ $a$ --- собственный вектор $f$.
	
	$\quad \Leftarrow$) Пусть $\forall$ $a$ $\not=$ 0, $a$ $\in$ $U$ $f(a) = \lambda a$. Т.к. $U$ --- подпространство, то $\lambda a$ $\in$ $U$ $\Rightarrow$
	
	$\quad f(a) \in a \Rightarrow f(U) \in U. \quad \boxtimes$
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Линейный оператор $f:V \rightarrow V$ --- оператор простой структуры $\Longleftrightarrow$ \ $\exists$ базис пространства $V$, состоящий из его собственных векторов.}
	\par\bigskip
	$\blacklozenge$ $\Rightarrow$) Пусть $f$ --- оператор простой структуры $\Rightarrow$ $\exists$ базис $A(a_1, \dots, a_n)$, в котором мат-
	
	$\quad$рица $M_A(f) = \begin{pmatrix} \lambda_1 & \dots & \dots & 0 \\ 0 & \lambda_2 & \dots & 0 \\ \dots & \dots & \dots & \dots \\ 0 & 0 & \dots & \lambda_n \end{pmatrix}$ $\Rightarrow$ $f(a_1) = \lambda_1 a_1$, $f(a_2) = \lambda_2 a_2$ \dots $f(a_n) = \lambda_n a_n$ $\Rightarrow$ 
	\par\bigskip
	$\quad f(a_i) = \lambda_i a_i$, где $i = \overline{1, n}$.
	\par\bigskip
	$\quad$Если матрица диагональная, то диагональ состоит из ее собственных значений. 
	\par\bigskip
	$\quad$$\Leftarrow$) Пусть $\exists$ базис $A(a_1, \dots, a_n)$, который состоит из собственных векторов оператора
	
	$\quad f$. Тогда $f(a_i) = \lambda_i a_i$, где $i = \overline{1, n}$ $\Rightarrow$ $M_f = \begin{pmatrix} \lambda_1 & \dots & \dots & 0 \\ 0 & \lambda_2 & \dots & 0 \\ \dots & \dots & \dots & \dots \\ 0 & 0 & \dots & \lambda_n \end{pmatrix}$ $\Rightarrow$ $f$ --- оператор 
	
	$\quad$простой структуры. $\quad \boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{Линейный оператор $f: V \rightarrow V$, имеющий $n$ различных сосбственных значений, является оператором простой структуры.} 
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Алгебраическая и геометрическая кратности собственного значения.}
	
	$\quad \; \ $Пусть $V$ --- векторное пространство над полем $P$, $f$ --- линейный оператор $n$-мерного векторного пространства.
	\par\bigskip
	\textbf{Теорема}
	\begin{enumerate}
		\item \textit{Ненулевой вектор $a$ $\in$ $V$ является собственным вектором оператора $f$, соответствующим собственному значению $\lambda$ $\Longleftrightarrow$ когда его координатный столбец $X_a$ в некотором базисе является ненулевым решением матричного уравнения $(M_f - \lambda E)X_a = 0$, где $M_f$ --- матрица оператора в базисе, $X_a$ --- координатный столбец вектора $a$ в базисе. }
		\item \textit{$\lambda_0$ $\in$ P является собственным значением оператора $f$ $\Leftrightarrow$ когда
			$\det(M_f - \lambda_0 E_n)$ = 0.}
	\end{enumerate}
	
	$\blacklozenge$ 1. Пусть $(a_1, \dots, a_n)$ --- базис пространства $V$. Тогда вектор $a$ можно разложить по
	
	$\quad$этому базису : $a = \alpha_1a_1 + \dots + \alpha_na_n$, $X_a$ = $\begin{pmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{pmatrix}$ --- координатный столбец вектора 
	
	$\quad$$a$ в базисе.
	\par\bigskip
	$\quad$Пусть вектор $a$ --- собственный вектор оператора $f$, соответствующий собственному
	
	$\quad$значению $\lambda$, $f(a)$ = $\lambda a$. Два вектора равны $\Longleftrightarrow$ когда равны их координаты. Если 
	
	$\quad$$X_a$ --- координатный столбец вектора $a$, то вектор $\lambda a$ имеет координатный столбец 
	
	$\quad$$\lambda X_a$, а вектор $f(a)$ = $M_f X_a$. Значит, равенство $f(a)$ = $\lambda a$ $\Longleftrightarrow$ $M_fX_a - \lambda X_a = 0$ 
	
	$\quad$$\Longleftrightarrow$ $M_f X_a - \lambda E_n X_a = 0$ $\Longleftrightarrow$ (M_f - \lambda E_n)X_a = 0.
	\par\bigskip
	$\quad$2. $\lambda_0$ --- собственное значение оператора $f$  $\Longleftrightarrow$ когда $\exists$ собственный вектор, соответ-
	
	$\quad$ствущий этому значению, т.е. $f(a) = \lambda a$. Это значит, что, исходя из п.1, $\exists$ ненулевое
	
	$\quad$решение матричного уравнения $(M_f - \lambda_0 E_n)X_a = 0$ только тогда, когда
	
	$\quad\det(M_f - \lambda E_n)X_a = 0. \quad \boxtimes$
	\par\bigskip
	Пусть $A = (a_i_,_j) \in P_n_,_n.$ Тогда
	\par\bigskip
	$\bullet \ A - \lambda E_n$ = $\begin{pmatrix} a_1_1 - \lambda & a_1_2 & \dots & a_1_n \\ a_2_1 & a_2_2 - \lambda & \dots & a_2_n \\ \dots & \dots & \dots& \dots \\ a_n_1 & a_n_2 & \dots & a_n_n - \lambda \end{pmatrix}$ --- \textit{характеристическая матрица.}
	\par\bigskip
	$\bullet \ \det(A - \lambda E_n)$ --- \textbf{\textit{характеристический многочлен матрицы}} \textit{A, его степень }
	
	$\quad$\textit{равна} $n$ (т.е. $deg(\det(A - \lambda E_n))$ = $n$). \textit{Корни этого уравнения --- \textbf{характеристиче-}}
	
	$\quad$\textit{\textbf{ские числа.}}
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Характеристические многочлены подобных матриц равны.}
	\par\bigskip
	$\blacklozenge$ Если матрицы $A$ и $B$ подобны, то $\exists$ невырожденная матрица $S$ такая, что $B = S^{-1}AS$.
	
	$\quad$Тогда $\det(B - \lambda E_n) = \det(S^{-1}AS - \lambda E_n) = \det(S^{-1}AS - S^{-1}\lambda E_n S) =$
	
	$\quad \det(S^{-1}(A - \lambda E_n)S) = \det S^{-1} \cdot \det(A - \lambda E_n) \cdot  \det S = \dfrac1{\det S} \cdot \det(A - \lambda E_n) \cdot \det S =$
	
	$\quad \det(A - \lambda E_n) \quad \boxtimes$
	\par\bigskip
	Из теоремы следует, что собственные значения линейного оператора являются корнями 
	
	характеристического уравнения этого линейного оператора.
	\par\bigskip
	$\bullet$ \ \textit{\textbf{Алгебраическая кратность} собственных значений --- это кратность корня}
	
	$\quad$\textit{характеристического многочлена.}
	
	\par\bigskip
	Т.к. степень характеристического многочлена равна размерности пространства $V$, то 
	
	сумма алгебраических кратностей собственных значений линейного оператора \textbf{не}
	
	\textbf{превышает} размерности пространства $V$.
	\par\bigskip
	$\bullet$ \ \textit{Подпространство, состоящее из $\overrightarrow{0}$ и всех собственных векторов линейного}
	
	$\quad$\textit{оператора, соответствующих одному собственному значению $\lambda_0$, называется}
	
	$\quad$\textit{собственным \textbf{подпространством} оператора $f$, соответствующим собственному}
	
	$\quad$\textit{значению $\lambda_0$.} \textit{Обозначается $L(\lambda_0)$. Его размерность называется \textbf{геометрической} }
	
	\quad\textit{\textbf{кратностью} собственного значения }$\lambda_0$.
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Геометрическая кратность собственного значения линейного оператора не превышает его алгебраической кратности.}
	\par\bigskip
	$\blacklozenge$ Пусть $\lambda_0$ --- собственное значение и оно имеет геометрическую кратность $S$. Пусть
	
	$\quad$система $(a_1, \dots, a_n)$ --- базис $L(\lambda_0)$. Дополним его до базиса всего пространства $V$
	
	$\quad$$A = (a_1, \dots, a_s, a_s_+_1, \dots, a_n)$ и построим матрицу $M_f$. А т.к. векторы $(a_1, \dots, a_s)$ --- 
	
	$\quad$собственные векторы оператора $f$, соответствующие собственному значению $\lambda_0$, то
	
	$\quad f(a_i) = \lambda_0 a_i \forall i = \overline{1, s}. $
	\par\bigskip
	$\quad$$M_f$ = $\left( \begin{tabular}{c|c}
		\begin{tabular}{cc} \begin{matrix} \lambda_0 & 0 & \dots & 0 \\ 0 & \lambda_0 & \dots & 0 \\ 0 & 0 & \dots & 0 \\ 0 & 0 & \dots & \lambda_0 \end{matrix} \end{tabular} & $B$ \\ \hline \begin{matrix} 0 & \ 0 & \ \dots & 0 \\ 0 & \ 0 & \ \dots & 0 \end{matrix} & $C$ \end{tabular} \right)$ = \bigg(\begin{tabular}{c|c}
		\begin{tabular}{cc} \lambda_0 E_S \end{tabular} & $B$ \\ \hline 0 & $C$
	\end{tabular}\bigg)
	\par\bigskip
	$\quad\det(M_f - \lambda E_n) = \det(\lambda_0 E_s - \lambda E_s) \cdot \det(C - \lambda E_{n-s}) = (\lambda - \lambda_0)^{s} \cdot \det(C - \lambda E_{n-s}))$. Ну а 
	
	$\quad$т.к. $(\lambda - \lambda_0)^{s}|\det(M_f - \lambda E_{n-s}) \Rightarrow$ алгебраическая кратность $k \geqslant s. \quad \boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{Сумма геометрических кратностей собственных значений линейного оператора не превосходит размерности пространства $V$.}
	\par\bigskip
	$\blacklozenge \sum s_i \ \geqslant \sum k_i \ \geqslant n = dim V \quad \boxtimes$
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $f : V \rightarrow V$ и $dim V = n$. Линейный оператор $f$ является линейным оператором простой структуры $\Longleftrightarrow$ сумма геометрических кратностей его собственных значений равна размерности $V$.}
	\par\bigskip
	$\blacklozenge$ \ $\Rightarrow$) Пусть $f$ --- оператор простой структуры $\Rightarrow$ $\exists$ базис $A = (a_1, \dots, a_n)$, состоящий
	
	$\quad$из собственных векторов этого оператора. Обозначим через $\lambda_1, \dots, \lambda_k$ собственные
	
	$\quad$значения оператора $f$, а через $S_1, \dots, S_k$ количество собственных векторов в базисе 
	
	$\quad$$A$, соответствующих этим собственным значениям $\Rightarrow$ $S_1 + \dots + S_k = \dim V = n$. Т.к. 
	
	$\quad$количество векторов в линейно независимой системе не превосходит размерности 
	
	$\quad$пространства, то и количество собственных векторов в базисе $A$, соответсвующих 
	
	$\quad$собственным значениям $\lambda_i$, не превосходит размерности $L(\lambda_i)$, т.е. $S_i$ $\leqslant$ $r_i$, где $r_i$ --- 
	
	$\quad$геометрическая кратность $\Rightarrow S_1 + S_2 + \dots + S_k \leqslant r_1 + \dots + r_k$ $\leqslant n \Rightarrow r_1 + \dots + r_k = n.$
	\par\bigskip
	$\quad \Leftarrow$) Пусть сумма геометрических кратностей собственных значений оператора $f$ 
	
	$\quad$равна $n$. Тогда объединение базисов собственных подпространств линейного опера-
	
	$\quad$тора состоит из $n$ векторов, которые являются собственными векторами оператора 
	
	$\quad f$, при этом линейно независимы, т.к. соответствуют различным собственным значе-
	
	$\quad$ниям $\Rightarrow$ $A$ --- базис пространства $V$, состоящий из собственных векторов оператора 
	
	$\quad f \Rightarrow$ оператор $f$ --- оператор простой структуры. $\quad \boxtimes$
	
	
	
	
	
	
	
	
	
	\chapter{Полиномиальные матрицы}
	
	\section{Эквивалентность полиномиальных матриц. Система НОД миноров полиномиальных матриц.}
	
	$\quad$ \textit{\textbf{Полиномиальные матрицы} - матрицы, элементы которых} $A(\lambda)$ = $\begin{pmatrix} a_{11}(\lambda)& \dots & a_{1n}(\lambda) \\ \dots & \dots & \dots \\ a_{n1}(\lambda) & \dots & a_{nn}(\lambda) \end{pmatrix}$, 
	
	\textit{где} $a_{ij} \ \in P$\textit{ }$[\lambda]$\textit{}.
	\par\bigskip
	\textit{ \textbf{Элементарными преобразованиями} называются следующие преобразования:}
	\begin{enumerate}
		\item  \textit{Умножение строки на число $\alpha$ $\not=$ 0, \ $\alpha \in P$.}
		
		\item  \textit{Прибавление к одной строки другой, умноженной на многочлен $f(\lambda) \in P$ [$\lambda$] из кольца}.
	\end{enumerate}
	\par\bigskip
	$\bullet$ \ \ \textit{Матрица $B(\lambda)$ называется \textbf{эквивалентной} матрице $A(\lambda)$, если она может быть получена из $A(\lambda)$ с помощью конечного числа элементарных преобразований строк и столбцов. Обозначение: $A(\lambda)$ $\sim$ $B(\lambda)$ }
	
	\par\bigskip
	$\bullet$ \ \ \textit{Эквивалентность полиномиальных матриц \textbf{рефлексивна, транзитивна и сим-}}
	
	$\quad$\textit{\textbf{метрична.}}
	
	\par\bigskip
	Пусть $r = rank \ A(\lambda)$. Тогда, все миноры матрицы $A(\lambda)$ порядка выше $r$ равны 0. А 
	
	среди миноров порядка $k \in \{1, \dots, r\} \ \exists$ ненулевой.
	\par\bigskip
	$\bullet$\ \ \textit{Система многочленов $d_1(\lambda)$, $\dots$, $d_n(\lambda)$ называется \textbf{системой НОД миноров} матрицы $A(\lambda)$, если при $k \in \{1, \dots, r\}$ $d_k(\lambda)$ --- НОД миноров $k$-ого порядка со старшим}
	\textit{коэффициентом 1, а при $k \in \{r+1, \dots, n\}$ $d_k(\lambda)$ = 0.}
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{У эквивалентных матриц $A(\lambda)$ и $B(\lambda)$ системы НОД миноров совадают.}
	\par\bigskip
	$\blacklozenge$ Покажем, что система НОД миноров не меняется при элементарных преобразованиях 
	
	$\quad$строк.
	\begin{enumerate}
		\item Пусть $i$ --- ая строка матрицы $A(\lambda)$ умножена на $\alpha$ $\not=$ 0. Тогда миноры, в которые эта строка не входит, не меняются, а миноры, в которые входят элементы этой строки, умножаются на $\alpha$. Но НОД системы многочленов не меняется, если некоторые из этих многочленов умножаются на ненулевую константу.
		\item Пусть матрица $B(\lambda)$ получена из матрицы $A(\lambda)$ прибавлением к $i$-ой строке элементов $j$-ой строки, умноженных на многочлен $c(\lambda)$. При этом миноры, в которые не входят элементы $i$-ой строки, не изменяются. Не меняются также миноры, в которые входят одновременно и элементы $i$-ой строки, и элементы $j$-ой. Рассмотрим миноры, в которые входят элементы $i$-ой строки, но не входят элементы $j$-ой, т.е. :
		
		$|a_i_1(\lambda) + c(\lambda)a_j_1(\lambda) \hspace{0.5 cm} \dots \hspace{0.5 cm} a_i_n(\lambda) + a_j_n(\lambda) \cdot c(\lambda)| = |\underbrace{a_i_1 \dots a_i_n}_{M_1}| + c(\lambda)|\underbrace{a_j_i + a_j_n}_{M_2}| = $
		
		$= M_1 + c(\lambda)M_2.$
		
		Заметим, что определители $M_1$ и $M_2$ с точностью до знака являются минорами матрицы $A(\lambda)$ $\Rightarrow$ все миноры матрицы $B(\lambda)$ либо равны минорам матрицы $A(\lambda)$, либо линейно выражаются через них.
		\par\bigskip
		
		Пусть $d^{A}_k (\lambda)$ и $d^{B}_k (\lambda)$ --- $k$-тые многочлены в системе НОД миноров матриц $A(\lambda)$ и $B(\lambda)$ соответственно. И пусть $rank \ A(\lambda) = r$. Тогда, если $k \in \{r+1, \dots, n\}$, то $d^{A}_k (\lambda)$ = 0 $\Rightarrow$ все миноры $k$-того порядка матрицы $A(\lambda)$ равны 0 $\Rightarrow$ все миноры $k$-того порядка матрицы $B(\lambda)$ также равны 0 $\Rightarrow$ $d^{B}_k (\lambda)$ = 0.
		
		Пусть $k \in \{1, \dots, r\}$. Тогда многочлен $d^{A}_k (\lambda)$ --- НОД миноров $k$-того порядка матрицы $A$ $\Rightarrow$ он делит все миноры $k$-того порядка матрицы $A$ $\Rightarrow$ он делит все миноры $k$-того порядка и матрицы $B$ $\Rightarrow$ $d^{A}_k (\lambda)$ делит НОД миноров $k$-того порядка матрицы $B$, т.е. $d^{A}_k (\lambda)$ | $d^{B}_k (\lambda)$.
		
		Заметим, что матрица $A(\lambda)$ может быть получена из матрицы $B(\lambda)$ с помощью обратного элементарного преобразования $\Rightarrow$ $d^{B}_k (\lambda)$ | $d^{A}_k (\lambda)$, и т.к. их старшие коэффициенты равны 1, то $d^{B}_k (\lambda)$ = $d^{A}_k (\lambda)$. $\quad \boxtimes$ \end{enumerate}
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{Ранги эквивалентных матриц равны.}
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Каноническая форма полиномиальной матрицы.}
	
	$\quad K(\lambda ) = \begin{pmatrix} f_1(\lambda) & 0 & \dots & 0 \\ 0 & f_2(\lambda) & \dots & 0 \\ 0 & 0 & \dots & f_n(\lambda) \end{pmatrix} = diag(f_1(\lambda) \dots f_n(\lambda)) $
	
	\par\bigskip
	Диагональная матрица {\textbf{каноническая,}}\ если:
	\begin{enumerate}
		\item  \textit{Старшие коэффициенты миноров равны 1}
		
		\item  \textit{Каждый диагональный многочлен $f_i(\lambda)$, где i = $\overline{1, r}$ \ и \ $r = rank \ K(\lambda)$, является делителем следующего элемента $f_{i+1}(\lambda)$, т.е. $f_i(\lambda)\ |\ f_{i+1}(\lambda)$}
	\end{enumerate}
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Для любой полиномиальной матрицы $\exists$ эквивалентная ей полиномиальная и при том единственная.}
	\par\bigskip
	$\blacklozenge$ Пусть A($\lambda$) $\in$ $P_{n,n}$. \ Если A($\lambda$)=0, то она каноническая.
	\par\bigskip
	$\quad$Пусть A($\lambda$) $\not=$ 0. Докажем существование эквивалентной канонической матрицы по 
	
	$\quad$индукции по порядку матрицы $n$.
	\par\bigskip
	$\quad$Пусть $n$ = 1. A($\lambda$) = (a($\lambda$)). Умножим матрицу A($\lambda$) на элемент поля P, обратный
	
	$\quad$старшему коэффициенту a($\lambda$) и получим каноническую матрицу, эквивалентную ис-
	
	$\quad$ходной.
	\par\bigskip
	$\quad$Пусть $n$ > 1 и предположим, что для любой полиномиальной матрицы порядка n-1 
	
	$\quad$существует эквивалентная каноническая матрица. Покажем, что $A(\lambda)$ также может 
	
	$\quad$быть приведена элементарными преобразованиями к канонической.
	\par\bigskip
	$\quad$Пусть $S$ --- класс эквивалентности такой, что $S = \{B(\lambda) \in P_{n,n} \ |\  B(\lambda) \sim A(\lambda)\}$.
	\par\bigskip
	$\quad$Матрица $B(\lambda)$ из $S$ такая, что:
	\begin{enumerate}
		\setlength{\itemindent}{5em}
		\item  $b_{11}(\lambda) \not= 0$
		\item старший коэффициент $b_{11}$ равен 1
		\item $deg\ b_{11}(\lambda) < \forall\ b_{ij}(\lambda)$ \ (степень многочлена $b_{11}$ - наименьшая среди сте-
		
		$\quad \quad \quad \quad \quad$пеней всех многочленов, образующих матрицу из $S$)
	\end{enumerate}
	
	$\quad$Разделим многочлен $b_{12}(\lambda)$ с остатком на многочлен $b_{11}(\lambda)$, т.е. представим его в
	
	$\quad$виде : $b_{12}(\lambda) = b_{11}(\lambda)q(\lambda) + r(\lambda)$, где $deg\ r(\lambda) < deg\ b_{11}(\lambda)$ или $r(\lambda) = 0$. Затем ко
	
	$\quad$второму столбцу матрицы $B(\lambda)$ прибавляем первый столбец, умноженный на $q(x)$. 
	
	$\quad$В результате получим матрицу $B_1(\lambda)$, у которой первый элемент второго столбца
	
	$\quad$равен $r(\lambda)$.
	\par\bigskip
	$\quad$Преобразование, с помощью которого получена матрица $B_1$, является элементарным
	
	$\quad\Rightarrow B_1(\lambda) \sim B(\lambda) \Rightarrow B(\lambda) \in S$.
	\par\bigskip
	$\quad$Если $r(\lambda) \not= 0$, то в $S\ \exists$ матрица $B_1(\lambda)$, у которой один из элементов имеет степень,
	
	$\quad$меньшую, чем $b_{11}$ $\Rightarrow$ ПРОТИВОРЕЧИЕ с тем, что степень многочлена $b_{11}$ наимень-
	
	$\quad$шая среди степеней многочленов, являющихся элементами матриц $S \Rightarrow r(\lambda) = 0 \Rightarrow$
	
	$\quad$первый элемент второго столбца матрицы $B_1$ равен 0.
	\par\bigskip
	$\quad$Проведем аналогичные преобразования для остальных элементов первой строки и 
	
	$\quad$первого столбца матрицы $B(\lambda)$. В результате получим матрицу $\widetilde{B}(\lambda)$:
	\par\bigskip
	$\quad\widetilde{B}(\lambda)$ = $\left( \begin{tabular}{c|c}
		\begin{tabular}{cc} b_1_1(\lambda) \end{tabular} & \begin{matrix} 0 \hspace{1.3 cm}  \dots & \hspace{1.3 cm} &0 \end{matrix} \\ \hline \begin{matrix} 0 \\ \vdots \\ \vdots \\ 0 \end{matrix} & \begin{matrix} c_1_1(\lambda) & \dots & c_{1(n-1)}(\lambda) \\ \vdots & \vdots & \vdots \\ \vdots & \vdots & \vdots \\ \dots & c_{(n-1)1}(\lambda) & c_n_n(\lambda) \end{matrix} \end{tabular} \right)$ = $\left( \begin{tabular}{c|c}
		\begin{tabular}{cc} b_1_1(\lambda) \end{tabular} & $0$ \\ \hline \begin{matrix} 0  \end{matrix} & $C(\lambda)$ \end{tabular} \right)$
	\par\bigskip
	$\quad$при этом $C(\lambda)$ - полиномиальная матрица порядка $n-1$ $\Rightarrow$ по индуктивному предпо-
	
	$\quad$ложению имеет каноническую матрицу $С(\lambda) = diag (\widetilde{c}_1_1(\lambda), \dots, \widetilde{c}_{(n-1)(n-1)}(\lambda))$. 
	\par\bigskip
	$\quad$Если эти преобразования применить к матрице $\widetilde{C}(\lambda)$, то они не будут менять эле-
	
	$\quad$менты первой строки и первого столбца и приведут матрицу $\widetilde{C}$ к диагональной
	
	$\quad K(\lambda) = diag (b_1_1(\lambda), \widetilde{c}_1_1(\lambda), \dots, \widetilde{c}_{(n-1)(n-1)}(\lambda)).$
	\par\bigskip
	$\quad$Старшие коэффициенты ненулевых многочленов $K(\lambda)$ равны 1 и каждый многочлен
	
	$\quad$\widetilde{c}_i(\lambda)| \ \widetilde{c}_i_+_1($\lambda$). Покажем, что многочлен $b_1_1(\lambda)$ | \ \widetilde{c}_1($\lambda$). Для этого прибавим к 1-ой 
	
	$\quad$строке матрицы $K(\lambda)$ 2-ую и получим матрицу вида:
	\par\bigskip
	$\quad$\begin{pmatrix} b_1_1(\lambda) & & \widetilde{c}_1_1(\lambda) & & 0 \\ 0 & \ddots & \widetilde{c}_1_1(\lambda) & & 0 \\ \vdots &  & \vdots & \ddots & \vdots \\ 0 & & 0 & & \widetilde{c}_{(n-1)(n-1)}(\lambda)\end{pmatrix} \in S.
	\par\bigskip
	$\quad$По доказанному выше, у любой матрицы из $S$, первый элемент которой равен $b_{11}$, 
	
	$\quad$все элементы строки делятся на $b_{11}$ \Rightarrow \widetilde{C}_1_1($\lambda$) делится на $b_{11}$ $\Rightarrow$ все свойства канони-
	
	$\quad$ческой матрицы выполняются $\Rightarrow$ K($\lambda$) --- каноническая матрица. $\quad \boxtimes$
	\par\bigskip
	$\quad\bullet$ \textit{Каноническая матрица, эквивалентная матрице A($\lambda$), называется \textbf{канони-}}
	
	$\quad$ \ \textit{\textbf{ческой} формой матрицы A($\lambda$)}.
	
	\par\bigskip
	$\quad\bullet$ \textit{Диагональные элементы канонической матрицы называются \textbf{инвариантными }}
	
	\quad\textit{\textbf{множителями.}}
	
	\par\bigskip
	\textit{\textbf{Следствие 1}}
	
	\textit{Матрицы $A(\lambda) \sim B(\lambda) \Longleftrightarrow$ равны их системы инвариантных множителей.}
	
	
	
	\par\bigskip
	\textit{\textbf{Следствие 2}}
	
	\textit{Матрицы $A(\lambda) \sim B(\lambda) \Longleftrightarrow$ равны их системы НОД миноров.}
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Система элементарных делителей полиномиальной матрицы.}
	
	\hspace{0.5 cm}$\bullet$ \textit{Многочлен $f(x)$ $\in$ $P[\lambda]$ единственным образом представим в виде:}
	
	\textit{$f(\lambda) = a \cdot (g_1(\lambda))^{k_1} \ (g_2(\lambda))^{k_2} \dots (g_s(\lambda))^{k_s}$, где}
	
	\textit{$a$ --- старший коэффициент многочлена $f$,}
	
	\textit{$k$ --- кратность, }
	
	\textit{$g_i(\lambda)$ --- различные неприводимые многочлены со старшим коэффициентом 1, при этом}
	
	\textit{многочлены $(g_i(\lambda))^{k_i}$ называются \textit{\textbf{элементарными делителями}} многочлена $f(\lambda)$.}
	
	\par\bigskip
	
	$\bullet$ \textit{\textbf{ Системой элементарных делителей (СЭД)} полиномиальной матрицы назы-}
	
	\textit{вается совокупность элементарных делителей всех непостоянных инвариантных}
	
	\textit{множителей полиномиальной матрицы. При этом каждый элементарный делитель}
	
	\textit{включается в эту систему столько раз, во сколько инвариантных множителей он}
	
	\textit{входит.}
	
	\par\bigskip
	
	\textbf{Пример:}
	
	$\begin{pmatrix} \lambda^2 & \dots \\ \dots & \lambda^3 + \lambda^2 \end{pmatrix}, \hspace{0.5 cm}  \lambda^3 + \lambda^2 = \lambda^2(\lambda+1) \ \Rightarrow$ СЭД: $\{\lambda^2, \lambda^2, \lambda + 1\}$
	
	\par\bigskip
	\textbf{Теорема}
	\textbf{(Критерий эквивалентности полиномиальных матриц)}
	
	\textit{Две полиномиальные матрицы одного порядка эквивалентны $\Longleftrightarrow$ равны их СЭД и ранги.}
	
	$\blacklozenge$ $\Rightarrow$) Если две полиномиальные матрицы $A(\lambda)$ $\sim$ \ $B(\lambda)$, то:
	
	\begin{enumerate}
		\setlength{\itemindent}{3em}
		\item Их системы НОД миноров совпадают $\Rightarrow$ $rank \ A(\lambda) = rank \ B(\lambda)$ 
		\item Их $f^A_i(\lambda)$ = $f^B_i(\lambda)$ (ИМ), где $i = \overline{1, n}$ $\Rightarrow$ СЭД($A(\lambda)$) = СЭД($B(\lambda)$)
	\end{enumerate}
	
	$\quad \Leftarrow$) Пусть полиномиальная матрица $A(\lambda)$ имеет порядок $n$, ранг $r$ и СЭД $S$.
	\par\bigskip
	$\quad$Если $r < n$, то $f_{r+1} = \dots = f_n(\lambda) = 0$.
	\par\bigskip
	$\quad$Пусть система $S$ состоит из степеней неприводимых многочленов $p_1(\lambda) \dots p_s(\lambda)$. Т.к. 
	
	$\quad$многочлен $f_r(\lambda)$ делится на каждый из предыдущих $f_i(\lambda)$, то он равен произведению
	
	$\quad$всех многочленов $p_i(\lambda)$ с максимальной степенью из присутствующих в $S$. Удалив из 
	
	$\quad$$S$ ЭД, порождаемые многочленом $f_r(\lambda)$, получим новую систему многочленов $f_i$, с 
	
	$\quad$помощью которой аналогично восстановим многочлен $f_{r-1}(\lambda)$ и т.д.
	\par\bigskip
	$\quad$В результате построения мы исчерпаем всю систему $S$, т.к. произведение многочле-
	
	$\quad$нов СЭД равно произведению ненулевых инвариантных множителей, при этом воз-
	
	$\quad$можны 2 случая: 
	\begin{enumerate}
		\setlength{\itemindent}{3em}
		\item На последнем шаге находим $f_1(\lambda)$ и построение закончено.
		\item На последнем шаге получаем $f_j(\lambda)$, где $j$ > 1. В этом случае
		
		$\quad \quad \quad$$f_1(\lambda)$ = \dots = $f_j_-_1(\lambda)$ = 1. $\quad \boxtimes$
	\end{enumerate}
	
	\par\bigskip
	\textbf{Теорема (Следствие)}
	
	\textit{СЭД диагональной полиномиальной матрицы равна объединению систем элементарных делителей ее диагональных блоков. При этом каждый элементарный делитель учитывается столько раз, во сколько диагональных блоков он входит.}
	\par\bigskip
	$\blacklozenge$ Рассмотрим диагональную матрицу $A(\lambda)$ = $diag \ \{g_1(\lambda), \dots, g_n(\lambda)\}$. Без ограничений 
	
	$\quad$общности будем считать, что 
	
	$\quad$$g_i(\lambda)$ $\not=$ 0, $i = \overline{1, r}$
	
	$\quad$$g_i(\lambda)$ = 0, $i = \overline{r+1, n}$.
	\par\bigskip
	$\quad$Тогда $rank \ A(\lambda)$ = $r$. Пусть $f_1(\lambda) \dots f_n(\lambda)$ --- инвариантные множители $A(\lambda)$ и 
	
	$\quad$$d_1(\lambda) \dots d_n(\lambda)$  --- система НОД миноров $A(\lambda)$. Т.к. $rank \  A(\lambda) = r$, то многочлены
	
	$\quad$$d_i(\lambda)$ = $f_i(\lambda)$ = 0 \ $\forall$ $i = \overline{r+1, n}$. Так как $A(\lambda)$ имеет лишь один ненулевой минор
	
	$\quad$$r$-ого порядка, то $d_r(\lambda)$ = $g_1(\lambda) \dots g_r(\lambda)$ = $f_1(\lambda) \dots f_r(\lambda)$ $\Rightarrow$ элементарные делители 
	
	$\quad$многочленов $g_i(\lambda)$ и $f_i(\lambda)$ являются степенями одних и тех же неприводимых много-
	
	$\quad$членов $p_1(\lambda) \dots \ p_k(\lambda)$. Разложим многочлены $g_i$ по этим неприводимым многочленам:
	\par\bigskip
	\hspace{1 cm}$g_1(\lambda) = (p_1(\lambda))^{\alpha_1_1} \cdot (p_2(\lambda))^{\alpha_1_2} \cdot ... \cdot (p_k(\lambda))^{\alpha_1_k}$
	
	\hspace{1 cm}$g_2(\lambda) = (p_1(\lambda))^{\alpha_2_1} \cdot (p_2(\lambda))^{\alpha_2_2} \cdot ... \cdot (p_k(\lambda))^{\alpha_2_k}$
	
	\hspace{1 cm}$\qquad\qquad\qquad\qquad\quad\dots$
	
	\hspace{1 cm}$g_r(\lambda) = (p_1(\lambda))^{\alpha_r_1} \cdot (p_2(\lambda))^{\alpha_r_2} \cdot ... \cdot (p_k(\lambda))^{\alpha_r_k}$
	\par\bigskip
	$\quad$Каждую из систем чисел ($\alpha_1_i, \alpha_2_i, \dots, \alpha_r_i)$ переобозначим следующим образом :
	
	$\quad$$\beta_1_i$ = min\{$\alpha_1_i, \alpha_2_i, \dots, \alpha_r_i$\}
	
	$\quad$$\beta_2_i$ --- следующее в порядке возорастания
	
	$\qquad\qquad\qquad\qquad ...$
	
	$\quad$$\beta_r_i$ = max\{$\alpha_1_i, \alpha_2_i, \dots, \alpha_r_i$\}
	\par\bigskip
	$\quad$Тогда, $d_1(\lambda) = (p_1(\lambda))^{\beta_1_1} (p_2(\lambda))^{\beta_1_2} \dots (p_k(\lambda))^{\beta_1_k}$
	
	\hspace{1.7 cm}$d_2(\lambda) = (p_1(\lambda))^{\beta_1_1 + \beta_2_1} (p_2(\lambda))^{\beta_1_2 + \beta_2_2} \dots (p_k(\lambda))^{\beta_1_k + \beta_2_k}$
	
	\hspace{1.7 cm}$\dots$
	
	$\quad$Следовательно, $f_1(\lambda) = d_1(\lambda) = (p_1(\lambda))^{\beta_1_1} \dots (p_k(\lambda))^{\beta_1_k}$
	
	\hspace{3.4 cm}$f_2(\lambda) = \dfrac {d_2(\lambda)}{d_1(\lambda)} = (p_1(\lambda))^{\beta_2_1} \dots (p_k(\lambda))^{\beta_2_k}$
	
	\hspace{3.4 cm}$\dots$
	
	\hspace{3.4 cm}$f_r(\lambda) = \dfrac {d_r(\lambda)}{d_r_-_1(\lambda)} = (p_1(\lambda))^{\beta_{r_1}} \dots (p_k(\lambda))^{\beta_{r_k}}$
	\par\bigskip
	$\quad$Следовательно, CЭД инвариантных множителей матрицы $A$ состоит из тех же много-
	
	$\quad$членов, что и объединение СЭД ее диагональных элементов. $\quad \boxtimes$
	
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{СЭД блочнодиагональной матрицы есть объединение СЭД ее диагональных элементов.}
	
	$\blacklozenge$ Пусть $A(\lambda)$ = $diag \ (A_1(\lambda), \dots, A_n(\lambda))$, где $A_i(\lambda)$ $\in$ $P_{n,n}$. Каждая матрица $A_i(\lambda)$ имеет 
	
	$\quad$единственную каноническую форму $K_i(\lambda) = diag \ (f_{1i}(\lambda), \dots, f_{ni}(\lambda)). \quad \boxtimes$
	
	
	
	
	
	
	
	
	
	
	\section{Унимодулярные матрицы.}
	$\quad \bullet$ \textit{Матрица называется \textbf{унимодулярной}, если её определитель равен отличному от нуля скаляру:}
	
	$\quad A(\lambda){\in} P_{nn}\quad detA(\lambda) = a\ {\ne}\ 0, a \in P$
	
	
	$\quad A(\lambda) = \begin{bmatrix}
		{\lambda} - 1 & {\lambda}\\
		{\lambda} & {\lambda} + 1
	\end{bmatrix}$, $detA(\lambda) = {\lambda}^2 - 1 - {\lambda}^2 = -1$
	\par\bigskip
	\textit{\textbf{Свойства унимодулярных матриц:}}
	\begin{enumerate}
		\item \textit{$A(\lambda)$ --- унимодулярная $\Longleftrightarrow f_n(\lambda) = 1$, (последний инвариантный множитель равен 1)}
		\par\bigskip
		$\blacklozenge$ $A(\lambda)$ --- унимодулярная $\Longleftrightarrow detA(\lambda) = a \ne 0 \Longleftrightarrow
		f_n(\lambda) = 1 \Longleftrightarrow f_1(\lambda), ...,  f_n(\lambda) = f_n(\lambda) = 1 \quad \boxtimes$
		
		\item \textit{$A(\lambda)$ --- унимодулярная $\Longleftrightarrow \exists A^{-1}(\lambda)$}
		\par\bigskip
		$\blacklozenge \Rightarrow )\ A(\lambda)$ --- унимодулярная $\Longrightarrow detA(\lambda) = a \ne 0 \Longrightarrow \frac 1{detA} = \frac 1a \ne 0$
		
		$A\tilde(\lambda)$ --- присоединённая к $A(\lambda)$
		
		$A^{-1}(\lambda) = \frac 1{detA}A\tilde(\lambda)$ \quad $A^{-1}(\lambda) * A(\lambda) = E_n$
		
		$\Leftarrow)\  \exists A^{-1}(\lambda) \Longrightarrow A^{-1}(\lambda) * A(\lambda) = E_n$;
		
		$det(A(\lambda) * A^{-1}(\lambda)) = detA(\lambda) * detA^{-1}(\lambda) = detE_n = 1 \Longrightarrow$
		
		$detA(\lambda) * detA^{-1}(\lambda) = 1 \Longrightarrow detA(\lambda) = a \ne 0 \Longrightarrow A(\lambda)$ --- унимодулярная \quad $\boxtimes$
	\end{enumerate}
	\par\bigskip
	
	Матрицы вида:
	\par\bigskip
	$S(\alpha)$ = $\begin{bmatrix} 1 & ... & 0 \\ 0 & 1 & ... \\ ... & ... & ... \\ 0 & ... & 1 \end{bmatrix}$ \quad
	$S_{ij}(a(\lambda)) = \begin{bmatrix} 1 & ... & 0 \\ ... & a(\lambda)  & ... \\ 0 & ... & 1 \end{bmatrix}$
	
	$A(\lambda) = \begin{pmatrix} a_{11}(\lambda) & a_{12}(\lambda) \\ a_{21}(\lambda) & a_{22}(\lambda) \end{pmatrix}$ \quad $S_{21}(a(\lambda)) = \begin{pmatrix} 1 & 0 \\ a(\lambda) & 1 \end{pmatrix}$
	
	$S_1(\alpha) = \begin{pmatrix} \alpha & 0 \\ 0 & 1 \end{pmatrix}$ \quad $S_1 \cdot A(\alpha) = \begin{pmatrix} \alpha a_{11}(\lambda) &  \alpha a_{12}(\lambda) \\ a_{21}(\lambda) & a_{22}(\lambda) \end{pmatrix}$
	
	$A(\lambda) \cdot S_1(\alpha) = \begin{pmatrix} \alpha a_{11}(\lambda) & a_{12}(\lambda) \\ \alpha a_{21}(\lambda) & a_{22}(\lambda) \end{pmatrix}$
	
	$S_{21}(\alpha) \cdot A(\lambda) = \begin{pmatrix} a_{11}(\lambda) & a_{12}(\lambda) \\ a(\lambda)a_{12}(\lambda) + a_{11}(\lambda) & a(\lambda)a_{12}(\lambda) + a_{12}(\lambda) \end{pmatrix}$
	\par\bigskip
	называются \textbf{элементарными}.
	\par\bigskip
	\begin{enumerate}
		\item[3.] \textit{Полиномиальная матрица унимодулярна $\Longleftrightarrow$ она представлена в виде произведения
			элементарных матриц}
		
		$\blacklozenge \Rightarrow ) A(\lambda)$ --- унимодулярная $\Longrightarrow A(\lambda) \sim E_n$
		
		$\quad \Leftarrow$) Пусть матрица есть произведение её элементарных матриц, тогда её опреде-
		
		\quadлитель равен произведению определителей элементарных матриц $\Longrightarrow$ определи-
		
		\quadтель элементарной матрицы есть число. \quad $\boxtimes$
	\end{enumerate}
	
	\textbf{Теорема}
	
	$A(\lambda), B(\lambda) \in P_{n,n}$
	
	$A(\lambda) \sim B(\lambda) \Longleftrightarrow \exists U(\lambda), V(\lambda) \in P_{n,n}, B(\lambda) = U(\lambda) * A(\lambda) * V(\lambda)$
	\par\bigskip
	$\blacklozenge\ A(\lambda) \sim B(\lambda) \Longrightarrow$ они получаются одна из другой с помощью элементарных преобра-
	
	\quad зований. \quad $\boxtimes$
	
	
	
	
	
	
	
	
	\section{Жорданова нормальная форма матрицы.}
	$\quad \; J_n(\alpha) = \begin{bmatrix}
		\alpha & 1 & 0 & ... & 0 \\
		0 & \alpha & 1 & ... & ... \\
		... & ... & ... & 1 & 0 \\
		... & ... & ... & \alpha & 1 \\
		0 & ... & ... & ... & \alpha \end{bmatrix} 
	$ --- \textbf{жорданова клетка}. Пример: $ J_3(7) = \begin{bmatrix} 7 & 1 & 0 \\ 0 & 7 & 1 \\ 0 & 0 & 7 \end{bmatrix}$
	\par\bigskip
	$\bullet$ \textit{\textbf{Жорданова матрица} –-- блочно-диагональная матрица, диагональные элементы которой являются жордановыми клетками.}
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $J_n(\alpha)$ --- жорданова клетка, $J_n(\alpha) - \lambda E_n$ --- ее характеристическая матрица. Тогда ее СЭД --- $(\lambda - \alpha)^n$}.
	\par\bigskip
	$\blacklozenge\ J_n(\alpha) - \lambda E_n = \begin{bmatrix} \alpha - \lambda & 1 & 0 & ... & 0 & 0 \\ 0 & \alpha - \lambda & 1 & ... & 0 & 0 \\ 0 & 0 & \alpha - \lambda & ... & ... & ... \\ ... & ... & ... & ... & ... & ...\\ 0 & 0 & 0 & ... & \alpha - \lambda & 1 \\ 0 & 0 & 0 & ... & 0 & \alpha - \lambda \end{bmatrix}$
	\par\bigskip
	$\quad \alpha_1 = 1, \alpha_2 = 1 \quad ... \quad \alpha_{n-1} = 1$
	\par\bigskip
	$\quad \alpha_n(\lambda) = (\lambda - \alpha)^n$
	\par\bigskip
	$\quad f_1 = 1, f_2 = 1 \quad ... \quad  f_{n-1} = 1$
	\par\bigskip
	$\quad f_n(\lambda) = (\lambda - \alpha)^n$
	\par\bigskip
	\quad СЭД: $(\lambda - \alpha)^n \quad \boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{Если $J = diag\{J_{n_1}(\alpha_1), J_{n_2}(\alpha_2) ... J_{n_k}(\alpha_k)\}$ --- жорданова матрица, то её СЭД: }
	
	$(\lambda - \alpha_1)^{n_1}, (\lambda - \alpha_2)^{n_2} \quad ... \quad (\lambda - \alpha_k)^{n_k} $
	\par\bigskip
	\textbf{Теорема}
	
	\textit{$A \in P_{n,n}$ имеет подобную жорданову матрицу $\Longleftrightarrow$ характеристический многочлен $A$ разложим в произведение многочленов 1-ой степени, т.е. характеристический многочлен имеет ровно $n$ корней с учётом их кратности.}
	\par\bigskip
	$\blacklozenge\ \Rightarrow)\ J$ подобна $A \Rightarrow det(A- \lambda E_n) = det(J - \lambda E_n)$
	\par\bigskip
	$\quad det(J - \lambda E_n) = (\lambda - \alpha_1)^{n_1} (\lambda - \alpha_2)^{n_2} \quad ... \quad (\lambda - \alpha_k)^{n_k} = det(A - \lambda E_n)$
	\par\bigskip
	$\quad \Leftarrow)\ det(A - \lambda E_n) = (\lambda - \alpha_1)^{n_1} (\lambda - \alpha_2)^{n_2} \quad ... \quad (\lambda - \alpha_k)^{n_k}$
	\par\bigskip
	\quad СЭД: $(\lambda - \alpha_1)^{n_1}, (\lambda - \alpha_2)^{n_2}, \quad ..., \quad (\lambda - \alpha_k)^{n_k} \quad \quad n_1 + n_2 + ... + n_k = n$
	\par\bigskip
	$\quad J = diag\{J_{n_1}(\alpha_1), J_{n_2}(\alpha_2) ... J_{n_k}(\alpha_k)\}$
	\par\bigskip
	\quad СЭД: $(\lambda - \alpha_1)^{n_1}, (\lambda - \alpha_2)^{n_2}, \quad ..., \quad (\lambda - \alpha_k)^{n_k}$
	\par\bigskip
	$\quad J - \lambda E_n$ и $A - \lambda E_n$ имеют одинаковый СЭД и rank $\Rightarrow A - \lambda E_n \sim J - \lambda E_n \Rightarrow A - \lambda E_n$ 
	
	\quad подобна $J - \lambda E_n \Rightarrow A$ подобна $J \quad \boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	$\forall A \in \mathbb{C}_{n,n},\ \exists$ \textit{подобная ей жорданова матрица. }
	\par\bigskip
	$\bullet$ \textit{Жорданова матрица, подобная $A$, --- \textbf{жорданова нормальная форма матрицы A}}.
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $J_1, J_2 \in P_{n,n}$ --- две жорадновы матрицы.
		$J_1$ подобна $J_2 \Longleftrightarrow$ они состоят из одинаковых жордановых клеток}.
	\par\bigskip
	$\blacklozenge \quad J_1$ подобна $J_2 \Longleftrightarrow J_1 - \lambda E_n \sim J_2 - \lambda E_n \Longleftrightarrow$ СЭД $(J_1 - \lambda E_n) =$ СЭД $(J_2 - \lambda E_n) \Longleftrightarrow$ жордановы клетки совпадают. $\quad \boxtimes$
	\par\bigskip
	
	\textit{\textbf{Следствие}}
	
	\textit{Жорданова нормальная форма матрицы определена с точностью до порядка следования диагональных блоков.}
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Теорема о количестве клеток жордановой нормальной формы матрицы. Построение жордановой нормальной формы с помощью вычисления ранга матрицы.}
	
	$\quad$ \ \textbf{Теорема}
	
	\textit{$A \in P_{n,n}, J $ --- ЖНФ $A$, тогда:
		\begin{enumerate}
			\item Диагональные элементы $J$ являются собственными значениями $A$;
			\item Сумма порядков клеток Жордана, соответсвующих собственному значению $\lambda_0$, равна алгебраической кратности $\lambda_0$;
			\item Количество клеток Жордана, соответствующих собственному значению $\lambda_0$, равна геометрической кратности $\lambda_0$, т.е. $l(\lambda_0) = n - rank(A - \lambda_0\cdot E)$ --- количество клеток;
			\item Количество клеток Жордана порядка $n$, соответствующих собственному значению $\lambda_0$: $l_r(\lambda_0) = rank(A - \lambda_0 E)^{r - 1} + rank(A - \lambda_0 E)^{r + 1} - 2\cdot rank(A - \lambda_0 E)^{r}$
		\end{enumerate}
	}
	
	$\blacklozenge$
	1) $A$ подобна $J \Rightarrow det(A - \lambda E) = det(J - \lambda E) \Rightarrow $ собственные значения $A$ равны собственным значениям $J$, т.к. это корни одних и тех же характеристических многочленов.
	
	2) $\lambda_0$ --- собственное значение кратности $k \Rightarrow det(A - \lambda E) = det(J - \lambda E) = (\lambda - \lambda_0)^r \cdot ... \Rightarrow $ ровно $k$ диагональных элементов $J$ есть $\lambda_0$.
	
	3) Рассмотрим $J_k(\alpha) - \lambda_0 E$:
	$\begin{pmatrix} \alpha - \lambda_0 & 1 & 0 & 0 & ... & 0 & 0 \\
		0 & \alpha - \lambda_0 & 1 & 0 & ... & 0 & 0 \\
		0 & 0 & \alpha - \lambda_0 & 1 & ... & 0 & 0 \\
		... & ... & ... & ... & ... & ... & ...\\
		0 & 0 & 0 & 0 & ... & \alpha - \lambda_0 & 1 \\
		0 & ... & ... & ... & ... & ... & \alpha - \lambda_0
	\end{pmatrix}$
	
	Если $\alpha = \lambda_0 \Rightarrow rank(J_k(\alpha) - \lambda_0 \cdot E) = k - 1$
	
	Если $\alpha \ne \lambda_0 \Rightarrow rank(J_k(\alpha) - \lambda_0 \cdot E) = k$
	
	$J = diag{J_1, ..., J_n}, rank(J) = rank(J_1) + ... + rank(J_n)$ (ранг блочнодиагональной матрицы равен сумме рангов её диагональных блоков).
	
	$J - \lambda_0\cdot E $ --- тоже блочно-диагональная и её ранг равен сумме рангов её диагональных блоков.
	
	Т.к. матрицы подобны, то $rank(A - \lambda_0 E) = rank(J - \lambda_0 E)$.
	
	4) $J_n - \lambda_0 E = $
	$\begin{pmatrix} \alpha - \lambda_0 & 1 & 0 & 0 & ... & 0 & 0 \\
		0 & \alpha - \lambda_0 & 1 & 0 & ... & 0 & 0 \\
		0 & 0 & \alpha - \lambda_0 & 1 & ... & 0 & 0 \\
		... & ... & ... & ... & ... & ... & ...\\
		0 & 0 & 0 & 0 & ... & \alpha - \lambda_0 & 1 \\
		0 & ... & ... & ... & ... & ... & \alpha - \lambda_0
	\end{pmatrix}$
	
	$\alpha \ne \lambda_0 \Rightarrow \alpha - \lambda_0 \ne 0 \Rightarrow rank(J_k(\alpha) - \lambda_0\cdot E) = k, rank(J_k(\alpha) - \lambda_0\cdot E)^r = k, \forall r \in N$
	
	В случае $\alpha = \lambda_0 J_n(\alpha) - \lambda_0 E = $
	$\begin{pmatrix}  0 & 1 & 0 & 0 & ... & 0 & 0 \\
		0 & 0 & 1 & 0 & ... & 0 & 0 \\
		0 & 0 & 0 & 1 & ... & 0 & 0 \\
		... & ... & ... & ... & ... & ... & ...\\
		0 & 0 & 0 & 0 & ... & 0 & 1 \\
		0 & ... & ... & ... & ... & ... & 0
	\end{pmatrix}$ $\Rightarrow rank(J_k(\alpha) - \lambda_0\cdot E) = k - 1$.
	
	Возведём эту матрицу в квадрат и получим $\begin{pmatrix}  0 & 0 & 1 & 0 & ... & 0 & 0 \\
		0 & 0 & 0 & 1 & ... & 0 & 0 \\
		0 & 0 & 0 & 0 & ... & 0 & 0 \\
		... & ... & ... & ... & ... & ... & ...\\
		0 & 0 & 0 & 0 & ... & 0 & 0 \\
		0 & ... &  ... & ... & ... & ... & 0
	\end{pmatrix}$ $\Rightarrow $
	
	$rank(J_k(\alpha) - \lambda_0\cdot E)^2 = k - 2$.
	
	Продолжая рассуждать аналогичным образом, получим:
	\begin{equation*}
		rank(J_k(\alpha) - \lambda_0\cdot E)^r = 
		\begin{cases}
			k - r, & r < k\\
			0, & r \geqslant k
		\end{cases}
	\end{equation*}    
	
	Рассмотрим разности:
	
	$rank(J(\alpha) - \lambda_0 E)^{r - 1} - rank(J(\alpha) - \lambda_0 E)^r,$ --- количество клеток порядка $\geqslant r$
	
	$rank(J(\alpha) - \lambda_0 E)^{r - 1} - rank(J(\alpha) - \lambda_0 E)^r,$ --- количество клеток порядка $\geqslant r + 1$
	
	Тогда количество клеток, порядок которых равен $r$:
	
	$l_r(\lambda_0) = rank(J(\alpha) - \lambda_0 E)^{r + 1} - 2 \cdot rank(J(\alpha) - \lambda_0 E)^{r} + rank(J(\alpha) - \lambda_0 E)^{r - 1}$.
	
	Т.к. $A$ и $J$ подобны, то $A - \lambda_0 \cdot E$ и $J - \lambda_0 \cdot E$ подобны $\Rightarrow (A - \lambda_0 \cdot E)^r$ и $(J - \lambda_0 \cdot E)^r$ подобны $\Rightarrow rank(A - \lambda_0 \cdot E) = rank(J - \lambda_0 \cdot E)$. $\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	\section{Жорданов базис.}
	$\quad$ Пусть $V$ --- ВП над $P$. $f:V\longrightarrow V$ --- линейный оператор. $E = \{e_1, ..., e_n\}$ --- базис $V$.
	
	$M_f$ --- матрица оператора $f$ в базисе $E$.
	\par\bigskip
	$\bullet$ \textit{\textbf{Жорданов базис} для линейного оператора --- базис пространства $V$, в котором матрица $M_f$ этого оператора $f$ является жордановой.}
	\par\bigskip
	$\bullet$ \textit{Система векторов $(a_1, ..., a_n) \in V$ --- \textbf{жорданова цепочка}, если:} 
	\par\bigskip
	
	$f(a_1) = \lambda_0 a_1 \quad \vec{a_1}$ --- \textit{начало цепочки}
	
	$f(a_2) = \lambda_0 a_2 + a_1 \quad \vec{a_2}$ --- \textit{первый присоединённый к $\vec{a_1}$}
	
	$f(a_3) = \lambda_0 a_3 + a_2$
	
	\quad \quad \quad ...
	
	$f(a_n) = \lambda_0 a_n + a_{n-1},$ \textit{где} $\lambda_0$ --- \textit{собственное значение}
	\par\bigskip
	\textit{Вся цепочка соответствует} $\lambda_0$.
	\par\bigskip
	\textit{\textbf{Свойства:}}
	\begin{enumerate}
		\item \textit{Пусть} $(a_1, ..., a_n) \in V$ \textit{соответствует} $\lambda_0$.
		
		$X_1 ... X_n$ --- \textit{координатные столбцы} $a_1...a_n$ \textit{в базисе} $E \Longrightarrow (M_f - \lambda_0 E_n) X_i = \begin{cases}0, i = 1; \\ x_{i-1}, i>1. \end{cases}$
		
		$\blacklozenge$ Если $ i = 1,\ f(a_1) = \lambda_0 (a_1) \Longleftrightarrow M_f X_1 = \lambda_0 X_1 \Longleftrightarrow M_f X_1 - \lambda_0 X_1 = 0 \Longleftrightarrow (M_f -  \lambda_0) X_1 = 0$ 
		
		\quad Если $ i > 1,\ f(a_i) = \lambda_0 a_i + a_{i-1} \Longleftrightarrow M X_i = \lambda_0 X_i + X_{i-1} \Longleftrightarrow M X_i - \lambda_0 X_i = X_{i-1} \Longleftrightarrow (M - \lambda_0) X_i = X_{i-1} \quad \boxtimes$
	\end{enumerate}
	
	\textit{\textbf{Следствие}}
	
	$(M - \lambda_0 E_n)^s X_i = \begin{cases} 0, i \leqslant s, \\ X_{i-1}, i > s. \end{cases}$
	
	\begin{enumerate}
		\item[2.] \textit{Жорданова цепочка всегда ЛНЗ.}
		
		$\blacklozenge$ От противного:
		
		Пусть $a_1, ..., a_n$ --- ЛЗ $\Longleftrightarrow \exists\ \alpha_1 a_1 + ... + \alpha_n a_n = 0$, пусть $\alpha_1 \ne 0$  $(S$ --- самый маленький индекс) $\Longleftrightarrow \alpha_1 a_1 + ... + \alpha_S x_S = 0$, умножим всё на $(M - \lambda_0 E_n)^{s-1}$, тогда все векторы до последнего станут $ = 0$, а последний $ = 1$. 
		
		$(M_f - \lambda_0 E_n)^{s-1}X_s, \quad a_s = \alpha_s X_s$
		
		$(M_f - \lambda_0 E_n)^{s-1} \alpha_i X_i = 0, \quad i < S$
		
		$\alpha_s X_1 = 0 \Longrightarrow X_1 = 0$ --- $ ?!$ (собственный вектор не может быть равен нулю) $\Longrightarrow$ жорданова цепочка ЛНЗ. $\quad \boxtimes$
		
		\item[3.] \textit{Cистема векторов, состоящая из жордановых цепочек, ЛНЗ $\Longleftrightarrow$ ЛНЗ подсистема, составленная из начал этих жордановых цепочек.}
		
		$\blacklozenge$ Аналогично пункту 2. $\quad \boxtimes$
	\end{enumerate}
	
	\textbf{Теорема}
	
	\textit{Базис пространства $V$ является жордановым для $f \Longleftrightarrow$ он состоит из жордановых цепочек}
	
	$\blacklozenge \Leftarrow)\ A = (A_1 ... A_n)$ --- базис, $A_i$ --- жорданова цепочка $\Longrightarrow$ будет $k$ независимых 
	
	\quadвекторов и строим матрицу:
	\par\bigskip
	\begin{center}
		$M$ =
		$\left(  \begin{tabular}{c|c|c} 
			\begin{matrix} \lambda_0 & 1 & 0 & ... & 0 \\ 0 & \lambda_0 & 1 & ... & 0 \\ ... & ... & ... & ... & ... \\ 0 & 0 & 0 & ... & 1 \\ 0 & 0 & 0 & ... & \lambda_0 \end{matrix} & 0 & ... \\
			\hline
			0 & J_2 & ... \\
			\hline
			... & ... & J_k 
		\end{tabular} \right )$
	\end{center}
	$\quad\quad\quad \Rightarrow)\ M = diag\{J_1 ... J_k \}$ --- тоже жордановы цепочки. $\quad \boxtimes$
	
	
	
	
	
	
	
	\section{Минимальный многочлен матрицы.}
	$\quad \;$Пусть $f(\lambda) = \alpha_m \lambda^m + \alpha_{m-1} \lambda^{m-1} + ... + \alpha_1 \lambda + \alpha_0, \alpha \in P, \alpha_i \ne 0$ --- некоторый многочлен над $P$. $A \in P_{n,n}$.
	
	$\bullet$ \textit{Матрица $f(A) = \alpha_m A^m + \alpha_{m-1} A^{m-1} + ... + \alpha_1 A + \alpha_0 E_n$ называется \textbf{значением многочлена} $f$ при $\lambda = A.$}
	\par\bigskip
	\textit{\textbf{Свойства значений:}}
	\begin{enumerate}
		\item $f(\lambda) = g(\lambda) \Rightarrow f(A)  = g(A)$.
		\item $(f+g) (A) = f(A) + g(A)$.
		\item $(f\cdot g) (A) = f(A) \cdot g(A)$.
	\end{enumerate}
	\par
	$\bullet$ \textit{Многочлен $f(\lambda)$ называется \textbf{\textit{аннулирующим}} для A, если $f(A) = 0$}
	\par\bigskip
	Размерность $P_{n,n}$ равна  $n^2 \Rightarrow A^{n^2}, A^{n^2 - 1}, ..., A^2, A, E_n$ --- ЛЗ $\Rightarrow \exists\ f(A)$.
	\par\bigskip
	$\bullet$ \textbf{\textit{Минимальным многочленом}} \textit{называется аннулирующий многочлен, старший коэффицент которого равен 1, а степень --- минимальная из всех ненулевых многочленов.}
	\par\bigskip
	\textit{\textbf{Свойства:}}
	\begin{enumerate}
		\item \textit{Минимальный многочлен определён однозначно}.
		
		$\blacklozenge$ Пусть $\exists\ m_1(\lambda),\ m_2(\lambda): m_1(\lambda) \ne m_2(\lambda)$. Рассмотрим $m(\lambda) = m_1(\lambda) - m_2(\lambda) :$ 
		
		$\quad m(\lambda) \ne 0$
		
		$\quad deg (m(\lambda)) < deg (m_1(\lambda)),\ deg (m(\lambda)) < deg (m_2(\lambda)) \Rightarrow m_1(\lambda) = m_2(\lambda) \quad \boxtimes$
		\item $f(\lambda)$ \textit{является аннулирующим многочленом матрицы $\Longleftrightarrow$ он делится на минимальный многочлен матрицы.}
		
		$\blacklozenge \Rightarrow)\ f(\lambda) $ --- аннулирующий, $f(A) = 0, m(\lambda)$ --- минимальный
		
		$\quad f(\lambda) = m(\lambda) \cdot q(\lambda) + r(\lambda) = 0$ или $deg r(\lambda) < deg m(\lambda)$
		
		$\quad f(A) (=0) = m(A) (=0) \cdot q(A) + r(A) \Rightarrow r(A) = 0 \Rightarrow f(\lambda) = m(\lambda) \cdot q(\lambda) \Rightarrow m(\lambda)|f(\lambda)$
		
		$\quad\Leftarrow)\ m(\lambda)|f(\lambda) \Rightarrow f(\lambda) = m(\lambda) \cdot q(\lambda), f(A) = m(A) \cdot q(A) = 0 \Rightarrow f(A) = 0 \Rightarrow f(\lambda)$ --- 
		
		\quadаннулирующий $\quad \boxtimes$
	\end{enumerate}
	\par
	\textbf{Теорема}
	
	\textit{Минимальный многочлен матрицы $A$ равен последнему инвариантному множителю её характеристической матрицы $A - \lambda E_n$}.
	\par\bigskip
	\textit{\textbf{Следствие 1 (теорема Гамильтона-Кэли)}}
	
	\textit{Характеристический многочлен матрицы является аннулирующим для матрицы.}
	\par\bigskip
	$\blacklozenge\ A - \lambda E_n  \sim K(\lambda) = \begin{pmatrix} f_1 & ... & 0 \\ ... & ... & ... \\ 0 & ... & f_n \end{pmatrix}. \quad XM(A - \lambda E_n)$ с точностью до знака равен произведению инвариантных множителей $A - \lambda E_n \Longrightarrow$ он делится на $f_n$ (наибольший инвариантный множитель) $\Longrightarrow XM(A - \lambda E_n)$ --- аннулирующий. $\quad \boxtimes$
	
	
	
	
	\par\bigskip
	\textit{\textbf{Следствие 2}}
	
	\textit{Минимальные многочлены подобных матриц равны.}
	\par\bigskip
	$\blacklozenge\ A$ и $B$ подобны $\Rightarrow A - \lambda E_n \sim B - \lambda E_n \Rightarrow K(A-\lambda E_n) \sim K(B - \lambda E_n) \Rightarrow f_{nA} = f_{nB} \Rightarrow$
	
	$\quad min(A) = min(B) \quad \boxtimes$
	
	
	
	
	
	
	
	
	
	
	\chapter{Квадратичные формы}
	
	
	\section{Эквивалентность квадратичных форм.}
	
	$\quad \;$ $\bullet$ \textbf{\textit{Квадратичная форма}} \textit{от $X_1 ... X_n$ над полем $P$ --- многочлен от этих переменных, каждый член которого имеет коэффициент $\alpha$, степень 2 относительно} $f(x_1, ..., x_n) = \sum\limits_{i,j=1}^n \alpha_{ij} x_i x_j, \quad \alpha_{ij} \in P, \quad i,j = \overline{1, n}$.
	\par\bigskip
	\textit{Квадратичные формы равны, если коэффиценты равны}
	\par\bigskip
	$\bullet$ \textit{Представление квадратичной формы в виде формы, коэффициенты которой удовлетворяют условию $\alpha_{ij} = \alpha{ji}$ называется \textbf{симметричной формой}.}
	\par\bigskip
	\textbf{Пример:}
	
	$f(x_1, x_2) = x_1^2 + 3 x_2^2 + 6 x_1 x_2 = x_1^2 + 3 x_2^2 + 3 x_1 x_2 + 3 x_2 x_1$ --- симметричная форма.
	\par\bigskip
	$\bullet$ \textit{Матрица $A_f = (\alpha_{ij}),\ i, j = \overline{1,n}$ (составленная из коэффициентов) --- \textbf{матрица квадратичной формы}.}
	\par\bigskip
	$\bullet$ $rank A_f = rank f$ --- \textit{\textbf{ранг квадратичной формы.}}
	\par\bigskip
	Если записать переменные $x_i$ в столбец $X = \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix}$ то в матричном виде квадратичную форму можно записать как $f(X) = X^T A_f X.$ 
	
	$\bullet$ \textit{Если $X = \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix}$ и $Y = \begin{pmatrix} y_1 \\ \vdots \\ y_n \end{pmatrix}$ --- столбцы переменных, то замена $x_i$ на $y_i$:}
	\par\bigskip
	$\begin{cases} x_1 = s_{11} y_1 + ... + s_{1n} y_n, \\ x_1 = s_{21} y_1 + ... + s_{2n} y_n, \\ \qquad\qquad... \\ x_n = s_{n1} y_1 + ... + s_{nn} y_n; \\ \end{cases} \quad s_{ij} \in P$ --- \textit{\textbf{линейное преобразование переменных}}.
	\par\bigskip
	$\bullet$\textit{ Матрица $S(s_{i,j}), i,j = \overline{1,n}$ --- \textbf{матрица преобразования}}.
	\textit{Если $det S \ne 0$, то $S$ --- \textbf{невырожденная}.}
	\par\bigskip
	$\bullet$ \textit{Квадратичная форма $f(X) = f(x_1, ..., x_n)$ \textbf{эквивалентна} $g(Y) = g(y_1, ..., y_n)$, если $\exists X = SY,\ det S \ne 0 : f(XY) = g(Y)$, то есть $S$ переводит $f$ в $g : f  \xrightarrow{S} g$}.
	\par\bigskip
	\textit{Отношение эквивалентности квадратичной формы --- отношение эквивалентности:}.
	\begin{enumerate}
		\item Рефлексивность: $f \sim f$, так как $X = E_n X S = E-n,\ f(E_n X) = f(X)$.
		\item Симметричность: $f(X) \sim g(X) \Rightarrow \exists\ S: f(SY) = g(Y)$.
		
		$\blacklozenge\ det S \ne 0,\ \exists\ S^{-1} X = SY,\ Y = S^{-1}X$
		
		$\quad g(S^{-1} X) = f(S(S^{-1}X)) = f(X) \Rightarrow g \sim f. \quad \boxtimes$
		\item Транзитивность: $f(X) \sim g(Y), \quad g(Y) \sim h(E) \Rightarrow f(X) \sim h(E)$
		
		$\blacklozenge\ \exists\ S=S_1S_2,\ det S \ne 0: X = S_1 Y,\ Y = S_2 Z \Rightarrow $
		
		$\quad f(S_1Y) = g(Y),\ g(S_1Z) = h(Z)\Rightarrow h(Z) = g(S_2Z) = f(S_1(S_2Z)) = f((S_1S_2)Z) = $
		
		$\quad f(SZ) \Rrightarrow f(SZ) = h(Z) \Rightarrow f(X) \sim h(Z). \quad \boxtimes$
	\end{enumerate}
	
	$\bullet$ \textit{Матрицы $A, B \in P_{n,n}$ \textbf{конгруэнтны}, если $\exists\ S,\ detS \ne 0: B = S^T A S$}
	\par\bigskip
	\textbf{Теорема}
	
	$f(X) \sim g(Y) \Longleftrightarrow A_f$ и $A_g$ \textit{конгруэнтны}
	\par\bigskip
	$\blacklozenge$ Пусть $f(X) = X^T a_f X,\ g(Y) = Y^T A_g Y$, тогда
	\par
	$\quad f(X) \sim g(Y) \Longleftrightarrow \exists S: X = SY,\ f(SY) = g(Y) \Longleftrightarrow (SY)^T A_f (SY) = Y^T A_g Y $
	\par
	$\quad Y^T(S^T A_f S) Y = Y^T A_g Y \quad \forall Y\Longleftrightarrow A_g = S^T A S \Longleftrightarrow A_f$ и $A_g$ --- конгруэнтны. $\quad \boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit{$f\sim g \Longleftrightarrow rank f = rank g$}.
	
	
	
	
	
	
	
	
	\section{Канонический вид квадратичной формы.}
	
	$\quad \;\bullet$ \textit{Квадратичная форма \textbf{\textit{каноническая}}, если ee матрица диагональная:}
	\par\bigskip
	$f(x_1...x_n) = \alpha_{11}x_1^2 + \alpha_{22}x_2^2 + ... + \alpha_{nn}x_n^2,\ \alpha_{ij} \in P,\ i = \overline{1,n}$
	\par\bigskip
	\textbf{Теорема (Лагранжа)}
	\par
	\textit{Для любой квадратичной формы $\exists$ эквивалентная ей каноническая квадратичная форма}.
	\par\bigskip
	$\blacklozenge\ f(x_1...x_n) = \alpha_{11}x_1^2 + ... + \alpha_{nn}x_n^2 = \sum\limits_{i=1}^n \alpha_{ii} x_i^2$
	
	$\quad n = 1 \quad f(x_1) = \alpha_1 x_1^2$
	
	$\quad f(x_1...x_n) = \sum\limits_{i,j=1}^n \alpha_{ij} x_i x_j \quad \alpha_{ij} = \alpha_{ji}$
	\par\bigskip
	\quadПроведём доказательство по индукции по количеству переменных в КФ($n$)
	\par\bigskip \quadБаза: $n - 1: f(x) = \alpha_{11}x_1^2$ – уже каноническая.
	ИП: пусть утверждение теоремы верно 
	
	\quad$\exists$ КФ с числом переменных меньше $n$.
	Покажем, что оно верно и для КФ с $n$ пере-
	
	\quadменными.
	\begin{enumerate}
		\item $\exists \alpha_{ii} \ne 0 \quad \alpha_{ii} \ne 0$
		
		$f(x_1...x_n) = \alpha_{11}x_1^2 + \alpha_{12}x_1 x_2 + ... + \alpha_{1n}x_1 x_n + \alpha_{21}x_2x_1 + ... + \alpha_{n1}x_nx_1 = \sum\limits_{i,j=2}^n \alpha_{ij} x_i x_j = \alpha_{11}x_1^2 + 2 \alpha_{12}x_1 x_2 + ... + 2 \alpha_{1n}x_1 x_n + \sum\limits_{i,j=2}^n \alpha_{ij} x_i x_j = \dfrac{1}{\alpha_{11}}(\alpha_{11}x_1^2 + 2 \alpha_{11}\alpha_{12}x_1 x_2 + ... + 2 \alpha_{11}\alpha_{1n}x_1 x_n) + \sum\limits_{i,j=2}^n \alpha_{ij} x_i x_j = \dfrac{1}{\alpha_{11}}(\alpha_{11}x_1 + \alpha_{12}x_2 + ... + \alpha_{1n}x_n)^1 - \dfrac{1}{\alpha_{11}}(\alpha_{12}x_2 + ... + \alpha_{1n}x_n)^2 + \sum\limits_{i,j=2}^n \alpha_{ij} x_i x_j = \dfrac{1}{\alpha_{11}}(\alpha_{11}x_1 + \alpha_{12}x_2 + ... + \alpha_{1n}x_n)^2 + g(x_2...x_n)$
		\par\bigskip
		$g \sim \tilde{g}$
		
		$\tilde{g}(y_2...y_n) = \beta_2 y_2^2 + ... + \beta_n y_n^2$
		\par\bigskip
		$\begin{cases} y_2 = S_{22}x_2 + ... + S_{2n} x_n \\ y_3 = S_{32}x_2 + ... + S_{3n} x_n \\ \qquad\qquad... \\ y_n = S_{n2}x_2 + ... + S_{nn} x_n \end{cases}$
		
		$Y = SX \quad S = (S_{ij}) \quad i,j = \overline{\alpha, n} \quad detS \ne 0$
		\par\bigskip
		$\begin{cases} y_1 = \alpha_{11}x_1 + ... + \alpha_{1n} x_n \\ y_2 = S_{22}x_2 + ... + S_{2n} x_n \\ \qquad\qquad... \\ y_n = S_{n2}x_2 + ... + S_{nn} x_n \end{cases}$
		
		$det \left( \begin{tabular}{c|c}
			\begin{tabular}{cc} \alpha_1_1(\lambda) \end{tabular} & \begin{matrix} \alpha_{12} \hspace{1.3 cm}  \dots & \hspace{1.3 cm} & \alpha_{1n} \end{matrix} \\ \hline \begin{matrix} 0 \\ \vdots \\ 0 \end{matrix} & \begin{matrix} S_{22} & \dots & S_{2n} \\ \vdots & \vdots & \vdots \\ S_{n2} & ... & S_{nn} \end{matrix} \end{tabular} \right)$ = $det$ $\left( \begin{tabular}{c|c}
			\begin{tabular}{cc} \alpha_{11} \end{tabular} & \alpha_{12}...\alpha_{1n}\\ \hline \begin{matrix} 0  \end{matrix} & S$ $\end{tabular} \right) =$
		
		$= \alpha_{11} detS \ne 0$
		\item $\alpha_{11} = 0 \quad i = \overline{1,n} \quad A_f = 0 \Longrightarrow f(x_1...x_n) = 0$
		
		$\exists \alpha{ij} \ne 0 \quad (\alpha_{12} \ne 0)$
		\par\bigskip
		$\begin{cases} x_1 = y_1 + y_2 \\ x_2 = y_1 - y_2 \\ x_i = y_i \quad i = \overline{3,n} \end{cases}$
		
		$2\alpha_{12} x_1 x_2 = 2\alpha_{12} (y_1 - y_2) (y_1 + y_2) = 2 \alpha_{12} y_1^2 - 2\alpha_{12} y_2^2 \quad \boxtimes$
	\end{enumerate}
	
	\textbf{\textit{Канонический вид квадратичной формы}} --- эквивалентная ей каноническая квадратичная форма.
	
	
	
	
	
	
	
	
	\section{Формула Якоби.}
	
	\quad\;Рассмотрим квадратичную форму $f(x_1,...,x_n) =\sum\limits^n_{i,j=1}\alpha_{ij}x_ix_j,\ \alpha_{ij} = \alpha_{ji}.$ Матрица $A = (\alpha_{ij})$ является матрицей квадратичной формы.
	
	$\bullet$\textit{\textbf{ Угловыми минорами} $A$ называются миноры $\Delta_1 = \alpha_{11},\ \Delta_2 = \begin{vmatrix} \alpha_{11} & \alpha_{12}\\ \alpha_{21} & \alpha_{22} \end{vmatrix}$, ...,}
	
	\quad$\Delta_k = \begin{vmatrix} \alpha_{11} & ... & \alpha_{1k}\\ ...&...&... \\ \alpha_{k1} & ... & \alpha_{kk} \end{vmatrix}, ...,$ $\Delta_n = det A$.
	\par\bigskip
	\textbf{Теорема (Формула Якоби)}
	
	\textit{Если матрица квадратичной формы $f$ имеет ненулевые угловые миноры $\Delta_i$, то квадратичная форма эквивалентна $\dfrac{1}{\Delta_1}y_1^2+\dfrac{\Delta_1}{\Delta_2}y_2^2+...+\dfrac{\Delta_{n-1}}{\Delta_n}y_n^2$}.
	\par\bigskip
	$\blacklozenge$ Так как $\Delta_1 \ne 0$, то $\alpha_{11}\ne0\Rightarrow$ форма $f$ представлена в виде:
	
	$\quad f(x_1,...,x_n) = \alpha_{11}x_1^2 + 2\alpha_{12}x_1x_2 + ... + 2\alpha_{1n} x_1 x_n + \sum\limits^n_{i,j=2}\alpha_{i}x_ix_j = \dfrac{1}{\alpha_{11}}(\alpha_{11}^2x_1^2 + 2x_1\alpha_{11}\cdot$
	
	$\quad\cdot(\alpha_{12}x_2 + ... + \alpha_{1n}x_n) + (\alpha_{12}x_2 + ... + \alpha_{1n}x_n)^2) - \underbrace{\dfrac{1}{\alpha_{11}}(\alpha_{12}x_2 + ... + \alpha_{1n}x_n)^2 + \sum\limits^n_{i,j=2}\alpha_{i}x_ix_j}_{g(x_2,...,x_n)} =$
	
	$\quad=\dfrac{1}{\alpha_{11}}(\alpha_{11}x_1 + \alpha_{12}x_2 + ... + \alpha_{1n}x_n)^2 +  g(x_2,...,x_n)$, где $g(x_2,...,x_n)$ --- квадратичная\par\quad форма.
	
	$\quad$Обозначим матрицу квадратичной формы $g$ через $B = (\beta_{ij}), (i,j) = \overline{2,n}$.
	
	$\quad$Выпишем элементы $\beta_{ij}: g(x_2,...,x_n) = f - \dfrac{1}{\alpha_{11}}(\alpha_{11}x_1+...+\alpha_{1n}x_n)^2\Rightarrow\beta_{ij} = \alpha_{ij} - \dfrac{\alpha_{1i}\alpha_{1j}}{\alpha_{11}}.$
	
	$\quad$С другой стороны, если к первому столбцу матрицы $A$ применить алгоритм Гаусса, 
	\par\bigskip
	\quadто есть получить из матрицы $A$ матрицу $A' = \begin{pmatrix} \alpha_{11} & \alpha_{12} & ... & \alpha_{1n} \\ 0 & \alpha'_{22} & ... & \alpha'_{2n}  \\ ... & ... & ... & ... \\ 0 & \alpha'_{n2} & ... & \alpha'_{nn} \end{pmatrix}$, где элементы 
	\par\bigskip
	\quad$A'$: $\alpha'_{ij} = \alpha_{ij} + \alpha_{1j}(-\dfrac{\alpha_{i1}}{\alpha_{11}}) = \alpha_{ij} - \dfrac{\alpha_{1j}\alpha_{i1}}{\alpha_{11}} = \alpha_{ij} - \dfrac{\alpha_{1j}\alpha_{1i}}{\alpha_{11}} = \beta_{ij}\Rightarrow$ матрица $A'$ имеет вид: 
	\par\bigskip
	\quad$A' = \left( \begin{tabular}{c|c}
		\begin{tabular}{cc} \alpha_{11} \end{tabular} & \alpha_{12}...\alpha_{1n}\\ \hline \begin{matrix} 0  \end{matrix} & $B$ \end{tabular} \right)$
	\par\bigskip
	\quadТаким образом, процесс выделения полных квадратов в квадратичной форме $f$ сов-
	
	\quadпадает с первым шагом метода Гаусса.
	
	$\quad$При этом элементы первой строки матрицы $A'$ совпадают с коэффициентами при 
	
	\quadпеременных $x_i$ в выделенном квадрате. Элемент, обратный первому элементу $A'$, 
	
	\quadсовпадает с коэффициентом при выделенном квадрате, а остальные --- совпадают с 
	
	\quadэлементами квадратичной формы $g$.
	
	\quadЗаметим, что преобразования не меняют угловых миноров: $\Delta_2 = \alpha_{11}\alpha'_{22}\ne 0\Rightarrow \alpha'_{22}\ne $
	
	$\quad0\Rightarrow$ мы можем применять следующие шаги метода Гаусса. Спустя $n-1$ шаг мы 
	
	\quadполучим матрицу $C = (\gamma_{ij})$, которая является верхнетреугольной $\Rightarrow detC \ne 0\Rightarrow $
	
	$\quad f(x_1,...,x_n) = \dfrac{1}{\gamma_{11}}\underbrace{(\gamma_{11}x_1 + ...+\gamma_{1n}x_n)^2}_{y_1} + ... + \dfrac{1}{\gamma_{nn}}(\gamma_{nn}x_n)^2\Rightarrow$ квадратичная форма $f$ 
	
	\quadможет быть получена из $\Tilde{f}(y_1,...,y_n) = \dfrac{1}{\gamma_{11}}y_1^2+...+\dfrac{1}{\gamma_{nn}}y_n^2$ при помощи преобразований:
	$$\begin{cases} y_1 = \gamma_{11}x_1 + ... + \gamma_{1n}x_n,\\
		y_2 = \gamma_{2}x_1 + ... + \gamma_{2n}x_n,\\
		\qquad\qquad\quad...\\
		y_n = \qquad\qquad\quad\;\gamma_{nn}x_n;
	\end{cases}$$
	
	\quadПри этом матрица этого преобразования совпадает с матрицей $C$, и, следовательно, 
	
	\quadневырожденная $\Rightarrow$ преобразование также невырожденное $\Rightarrow f\sim \Tilde{f}$ 
	
	\quadВыражаем коээфициенты $\Tilde{f}$ через элементы матрицы $A$. Матрица $C$ получена из 
	
	\quadматрицы $A$ путем преобразований, не изменяя угловые миноры $\Rightarrow$
	
	$\quad\Delta_1 = \gamma_{11},$
	
	$\quad\Delta_2 = \gamma_{11}\gamma_{22},$ 
	
	$\quad\qquad...$
	
	$\quad\Delta_n = \gamma_{11}\gamma_{22}...\gamma_{nn};$
	\par\bigskip
	$\quad\dfrac{1}{\gamma_{11}}=\dfrac{1}{\Delta_1},$
	
	$\quad\dfrac{1}{\gamma_{22}}=\dfrac{\gamma_{11}}{\Delta_2} = \dfrac{\Delta_1}{\Delta_2}$,
	
	\quad\qquad ...
	
	$\quad\dfrac{1}{\gamma_{nn}} = \dfrac{\Delta_{n-1}}{\Delta_n}.\quad\boxtimes$
	
	
	
	
	
	
	
	
	
	
	\section{Нормальные квадратичные формы.}
	$\bullet\quad$ \textit{\textbf{Нормальная квадратичная форма} имеет вид:}\\
	$$x_1^2+...+x_r^2+0\cdot x_{r+1}^2+...+0\cdot x_n^2\qquad\qquad0\le r\le n$$ \\
	$$f(x_1,...,x_n)=x_1^2+...+x_r^2$$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Для любой комплексной квадратичной формы существует единственная эквивалентная ей нормальная квадратичная форма.}
	\par\bigskip
	$\blacklozenge$ $f \sim \alpha_1 x_1^2+...+\alpha_n x_n^2 \quad \quad \alpha_i\ne0 \quad i=\overline{1,r}\quad \alpha_i=0\quad i=\overline{r+1,n}$
	
	$\quad \begin{cases}
		y_i=\sqrt{\alpha_i} x_i \quad \quad i=\overline{1,r}\\
		y_i=x_i \quad \quad i=\overline{r+1,n}\\
	\end{cases}$
	
	\quad $f \sim y_1^2+...+y_r^2$
	
	\quad$f(x_1,...,x_n)=x_1^2+...+x_r^2$
	
	\quad$g(x_1,...,x_n)=x_1^2+...+x_q^2$
	
	\quad$f \sim g \quad \rightarrow \quad rank\,f=rank\,g \quad\rightarrow \quad r=g \quad \rightarrow \quad f(x)=g(x)\quad \quad \boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	$f \sim g \quad \Longleftrightarrow \quad rank\,f=rank\,g $
	\par \bigskip
	$\bullet\quad$\textit{\textbf{Нормальная действительная форма} имеет вид:}
	$$x_1^2+...+x_p^2-x_{p+1}^2-...-x_r^2+0 \cdot x_{r+1}^2+...+0 \cdot x_n^2$$
	$$0 \le p \le r \le n$$
	\par \bigskip
	\textbf{Теорема (закон инерции)}
	
	\textit{Для любой действительной квадратичной формы существует единственная эквивалентная ей нормальная квадратичная форма.}
	\par\bigskip
	$\blacklozenge$ $\alpha_1 x_1^2+...+\alpha_n x_n^2$
	
	\quad$\begin{cases}
		\alpha_i > 0 \quad i=\overline{1,p}\\
		\alpha_i < 0 \quad i=\overline{p+1,r}\\
		\alpha_i=0 \quad i=\overline{r+1,n}
	\end{cases}$ \quad \quad $\begin{cases}
		y_i=\sqrt{\alpha_i} x_i \quad i=\overline{1,r}\\
		y_i=x_i \quad i={r+1, n}
	\end{cases}$
	
	$\quad y_1^2+...+y_p^2-y_{p+1}^2-...-y_r^2$
	
	$\quad f(x), \, g(y)\quad  \rightarrow \quad f \sim g \quad \rightarrow \quad rank \, f = rank \, g=r \ne 0$ нормальные для одной и той 
	
	\quadже формы
	
	\quad$f(x)=x_1^2+...+x_p^2-...-x_{p+1}^2-...-x_r^2$
	
	\quad$g(y)=y_1^2+...+y_q^2-y_{q+1}^2-...-y_r^2$
	
	\quad Пусть $p\ne q \quad p<q$
	
	\quad $f \sim q \rightarrow \exists \quad S: \quad X=SY \quad f(SY)=g(Y)$
	
	\quad $\begin{cases}
		x_i=S_{11} y_1+...+S_{1n} y_n\\
		\qquad\qquad........\\
		x_n=S_{n1} y_1+...+S_{nn} y_n
	\end{cases}$ \quad \quad 
	$\begin{cases}
		S_{11} y_1+...+S_{1q} y_q=0\\
		\qquad\qquad........\\
		S_{p1} y_1+...+S_{pq} y_q=0
	\end{cases}$
	
	\quad $(\tilde y_1 ,..., \tilde y_p) \quad \tilde Y=
	\begin{pmatrix}
		\tilde y_1 \\
		...\\
		\tilde y_p\\
		...\\
		0\\
	\end{pmatrix} 
	\quad \tilde X=S \tilde Y$
	
	\quad $\tilde X=S \tilde Y=
	\begin{pmatrix}
		S_{11}\tilde y_1+...+S_{1n}\tilde y_n\\
		........\\
		S_{n1}\tilde y_1+...+S_{nn}\tilde y_n
	\end{pmatrix} \quad \quad \tilde x_1=...=\tilde x_p=0$
	
	\quad $f(SY)=g(Y)$
	
	\quad $F(S \tilde Y)=g(\tilde Y)$ \quad \quad $f(\tilde X)=g(\tilde Y)$
	
	\quad $f(\tilde X)=-x_{p+1}^2-...-x_r^2 \le 0$
	
	\quad$g(\tilde Y)=y_1^2+...+y_p^2>0$
	\quad $f(\tilde X)=g(\tilde Y) \quad ?! \quad \rightarrow \quad p=q \quad \quad \boxtimes$
	\par \bigskip
	$ \bullet $\textit{ Количество "$\lambda$"\,в действительной квадратичной форме --- \textbf{положительный индекс инерции}.} 
	\par \bigskip
	$\bullet$\textit{ Количество "$-1$"\, --- \textbf{отрицательный индекс инерции}.}
	\par \bigskip
	$\bullet$\textit{\textbf{ Сигнатура} --- разность между положительными и отрицательными индексами.}
	\par\bigskip 
	\quad $f(x_1,x_2,x_3)=x_1^2-x_2^2-x_3^2 \quad \quad S=-1$
	\par\bigskip 
	\quad $g(y_1,y_2,y_3)=y_1^2+y_2^2-y_3^2 \quad \quad S=1$
	\par \bigskip
	\textit{\textbf{Следствие}}
	
	$f \sim g \quad \Longleftrightarrow \quad rank\,f=rank\,g \quad S(f)=S(g)$
	\par\bigskip
	$\bullet$\textit{\textbf{ Нормальный вид квадратичной формы} --- эквивалентная ей нормальная квадратичная форма.}\\
	
	
	
	
	
	
	
	
	
	\section{Знакоопределенные действительные квадратичные формы.}
	$\quad\; \bullet\quad$ \textit{Действительная квадратичная форма \textbf{положительно определенная}\textit{, если для любого набора чисел}}
	$\gamma_1,...,\gamma_n, \gamma_i\, \in\, \mathbb{R} \Rightarrow f(\gamma_1,...,\gamma_n)>0$
	\par\bigskip
	$\bullet\quad$ \textit{Действительная квадратичная форма \textbf{отрицательно определенная}, если для любого набора чисел}
	$\gamma_1,...,\gamma_n, \gamma_i\, \in\, \mathbb{R} \Rightarrow f(\gamma_1,...,\gamma_n)<0$
	\par\bigskip
	Если записать Г = $\begin{pmatrix}
		\gamma_1\\
		...\\
		\gamma_n\\
	\end{pmatrix} \in \mathbb{R}_n \backslash \{0\}$, то
	
	$f($Г$)>0 \,$ --- положительно определенная
	
	$f($Г$)<0 \,$ --- отрицательно определенная
	\par \bigskip
	\textbf{Теорема}
	
	\textit{Квадратичная форма} $f(x_1,...,x_n)$\textit{ положительно определенная} $\Longleftrightarrow f(x_1, ..., x_n) \sim g(y_1, ..., y_n)=y_1^2+...+y_n^2$.
	\par\bigskip
	$\blacklozenge \Rightarrow)$ Пусть $f(x)>0,\ \forall\, x\, \in \, \mathbb{R}_n \backslash \{0\} $\par
	$\quad g(y_1,...,y_n)=\alpha_1 y_1^2+...+\alpha_n y_n^2$ --- нормальный вид $f$\par
	$\quad$От противного: пусть $\alpha_n \ne 1 \quad $ $(\alpha_n=-1 \quad$ или $\quad \alpha_n=0)$\par
	$\quad$Тогда $e_n=\, \begin{pmatrix}
		0\\
		0\\
		...\\
		1\\
	\end{pmatrix},\ g(e_n)=\alpha_n \leqslant 0\Rightarrow f \sim g\Rightarrow \exists \, X=SY,\ det \, S \ne 0$\par
	$\quad f(SY)=g(Y) \Longleftrightarrow f(S e_n)=g(e_n)=\alpha_n \leqslant 0\Rightarrow f(S e_n) \leqslant 0$\par
	$\quad S e_n = \begin{pmatrix}
		S_{1n}\\
		...\\
		S_{nn}\\
	\end{pmatrix} \, \ne \, 0$ --- $?!$, так как $f$ тогда отрицательно определенная\par
	$\quad$Значит $\alpha_n=1 \, \Rightarrow \, g(Y)=y_1^2+...+y_n^2$
	\par\bigskip
	$\quad \Leftarrow )\ f(X) \sim g(Y)=y_1^2+...+y_n^2 \, \Rightarrow \, \exists\ Y=SX,\ det\, S \ne 0$\par
	$\quad g(SX)=f(X)$\par
	$\quad g(Y)>0,\forall\ Y\, \in\, \mathbb{R}_n\backslash \{0\} $\par
	$\quad g(SX) \geqslant 0$\par
	$\quad g(SX)=0 \, \Longleftrightarrow \, SX=0 \, \Longleftrightarrow \, S^{-1}SX=S^{-1} 0 \, \Longleftrightarrow \, X=0$\par
	$\quad g(X)>0, \forall\ x\ne 0$\par
	$\quad g(SX)>0, \forall\ x \, \in \, \mathbb{R}_n \backslash \{0\} \Rightarrow f(x)>0, \forall x \ne 0 \quad \boxtimes$
	\par \bigskip
	\textit{\textbf{Следствие 1}}\par
	\textit{ Все положительноопределенные формы эквивалентны друг другу.}
	\par \bigskip
	\textit{\textbf{Следствие 2}}\par
	\textit{Матрица положительноопределенной формы имеет положительный определитель}.
	\par \bigskip
	$\blacklozenge\ f(x)$ --- положительноопределенная с $A_f : det\, A_f >0$\par
	$\quad f \sim g\Rightarrow A_f=S^{-1} A_g S, det \, S \ne 0$\par
	$\quad f \sim g(Y)=y_1^2+...+y_n^2$\par
	$\quad A_g=E_n$\par
	$\quad A_f=S^{T} E_n S = S^{T} S$\par
	$\quad det \, A_f = det \, S^{T} S = det\, S^{T} \cdot det \, S= det\, S \cdot det \, S = det^2\, s>0 \quad \boxtimes$\par
	\par \bigskip
	\textbf{Теорема (Критерий Сильвестра)}\par
	$f(x)>0\Longleftrightarrow$\textit{ главные угловые миноры её матрицы положительны. }$
	(\Delta_i > 0,\ i=\overline{1,n})$
	
	$\begin{pmatrix}
		a_{11}& a_{12}&a_{13}&...&a_{1n}\\
		a_{21}& a_{22}&a_{23}&...&a_{2n}\\
		...&...&...&...&...\\
		a_{n1}& a_{n2}&a_{n3}&...&a_{nn}\\
	\end{pmatrix}= A,\quad \quad 
	\begin{matrix}
		\Delta_1=a_1 \\
		\Delta_2=\begin{vmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{vmatrix} \\
		...\\
		\Delta_n =det \, A\\
	\end{matrix}
	$
	\par \bigskip
	$\blacklozenge \Rightarrow )$ Пусть $f(x_1,...,x_n) = 
	\sum_{i,j=1}^n \alpha_{ij} x_i x_j,\ f(x_1,...x_n)>0$\par
	$\quad$Рассмотрим $f_m(x_1,...,x_m) = 
	\sum_{i,j=1}^m\alpha_{ij} x_i x_j,\ 1 \leqslant m < n$\par
	$\quad$Предположим, что $\exists\ (\beta_1,...,\beta_n): f_m(\beta_1,...,\beta_m) \leqslant 0$\par
	$\quad f_m > 0$\par
	$\quad det \, A_{fm}=\Delta_m>0, i=\overline{1,n}$
	\par \bigskip
	$\quad \Leftarrow )\ \Delta_i > 0,\ i=\overline{1,n} \Rightarrow f(x_1,...,x_n) \, \sim \, \dfrac1{\Delta_1} y_1^2 +...+\dfrac1{\Delta_n} y_n^2$\par
	$\quad \Delta_i=\dfrac{\Delta i -1}{\Delta i}, \ \Delta 0=1$\par
	$\quad \Delta_i >0, \ i=\overline{1,n}$\par
	$\quad z_i=\dfrac1{\sqrt{\Delta_i}} y_i$\par
	$\quad f \, \sim \, z_1^2+...+z_n^2 \, \Rightarrow \, f(x)=0\quad\boxtimes$
	\par \bigskip
	\textit{\textbf{Следствие}}
	
	$f(x)<0 \Longleftrightarrow $\textit{ четные угловые миноры }$\Delta_{2i} >0$\textit{, а нечетные угловые миноры  }
	\par $\Delta_{2i+1} <0,\ i=\overline{1,n}$
	\par \bigskip
	\textbf{Пример:}
	
	$f(x_1,x_2,x_3)=2 x_1^2+x_2^2+2 x_3^2+ 2 x_1 x_2 + \lambda x_1 x_2 + 2 x_3 x_2$\textit{ и чтобы была положительной при }$\lambda$\\
	\par \bigskip
	$\quad A_f = \begin{pmatrix}
		2&1&\dfrac{\lambda}2\\
		1&1&1\\
		\dfrac{\lambda}2&1&2
	\end{pmatrix}$
	$\quad \quad  \begin{matrix}
		\Delta_1>0 \\
		\Delta_2=\begin{vmatrix} 2 & 1 \\ 1 & 1 \end{vmatrix} =1 >0 \\
		\Delta_3 =\begin{vmatrix} 2&1&\dfrac{\lambda}2\\
			1&1&1\\
			\dfrac{\lambda}2&1&2 \end{vmatrix} =\lambda - \dfrac{\lambda^2}4 >0\\
	\end{matrix}$
	
	$\quad \lambda -\dfrac{\lambda^2}4 >0$
	
	$\quad \lambda^2-4 \lambda < 0$
	
	$\quad \lambda \in (0,4)$
	
	
	
	
	
	
	
	
	
	
	
	
	
	\chapter{Евклидово пространство}
	
	
	
	
	
	
	\section{Определение и простейшие свойства евклидовых пространств.}
	\par \bigskip
	\quad\; Пусть $V$ --- векторное пространство над полем $\mathbb{R}$. Отображение $V \times V \rightarrow \mathbb{R}$, ставящее 
	$a,b \in V \mapsto ab \in \mathbb{R}$ называют \textbf{скалярным произведением}, если:
	
	$1)\ ab=ba$
	
	$2)\ (\alpha a)b=\alpha(ab)\, , \forall \alpha \in \mathbb{R}$
	
	$3)\ (a+b)c=ac+bc$
	
	$4)\ a\cdot a>0, \forall\ a \ne 0_v$
	\par \bigskip
	\textbf{Примеры}
	
	$1)\ a \cdot b =|a||b| \cos{\alpha}$
	
	$2)\ a=(\alpha_1,...,\alpha_n), \, b=(\beta_1,...,\beta_n);\, a,b \in \mathbb{R}_n$
	
	$ab=\alpha_1 \beta_1 +...+ \alpha_n \beta_n$
	
	$3)\ f,g \in [a,b] \quad (f,g)= \int_a^b \, f(x) g(x) dx$
	\par \bigskip
	$\bullet$\textit{ Действительное векторное пространство с определенным на нем скалярным произведением --- \textbf{Евклидово пространство}}.
	\par \bigskip
	\textit{\textbf{Простейшие свойства:}}
	
	$1)\ a(\alpha b)=\alpha(ab), \quad \forall a,b \in V, \, \alpha \in \mathbb{R}$
	\par \bigskip
	$\blacklozenge\ a(\alpha b)=\alpha(b)a=\alpha(ba)=\alpha(ab) \quad \boxtimes $
	\par \bigskip
	$2) a(b+c)=ab+ac, \quad \forall a,b,c \in V$
	\par \bigskip
	$\blacklozenge\ a(b+c)=(b+c)a=ba+ca=ab+ac \quad \boxtimes $
	\par \bigskip
	$3) a\cdot 0_v=0_v \cdot a =0, \quad \forall a \in V$
	\par \bigskip
	$\blacklozenge\  a\cdot 0_v+ a\cdot 0_v= a(0_v+0_v)=a \cdot 0_v \Rightarrow  a\cdot 0_v=0\quad\boxtimes$
	\par \bigskip
	\textit{\textbf{Следствие: }}
	$0_v \cdot 0_v =0$
	\par \bigskip
	Пусть $B=(b_1,...,b_n),\ b_i \in V,\ i=\overline{1,n}$ --- система векторов, принадлежащая евклидову пространству.
	
	$\bullet\ G_B=
	\begin{pmatrix}
		b_1 b_1 & b_1 b_2 & ... & b_1 b_n\\
		b_2 b_1 & b_2 b_2&...& b_2 b_n\\
		...&...&...&...&\\
		b_n b_1 &b_n b_2 &...&b_n b_n
	\end{pmatrix} \in P_{n,n}$\textit{ --- \textbf{матрица Грама} системы В.}
	
	$b_i b_j =b_j b_i, \ i,j=\overline{1,k} \Rightarrow (G_B)^T=G_B \,$(\textit{то есть матрица симметричная)}.
	
	\textit{И если $B$ --- базис $V$, то} $G_B$\textit{--- \textbf{матрица скалярного произведения} базиса В}.
	\par \bigskip
	\textbf{Теорема}
	
	\textit{Пусть} $ B=(b_1,...,b_n)$\textit{--- базис $V$,}
	
	$ X=\begin{pmatrix}
		\alpha_1\\
		...\\
		\alpha_n
	\end{pmatrix}$\textit{--- кординаты векторы $x$ в базисе} $B$,
	
	$ Y=\begin{pmatrix}
		\beta_1\\
		...\\
		\beta_n
	\end{pmatrix}$\textit{---кординаты вектора $y$ в базисе} $B$,
	$x,y \in V. $ 
	
	\textit{Тогда скалярное произведение векторов} $x$ и $y$:
	
	$$xy=X^T G_B Y $$
	
	$\blacklozenge$ Если $x=\sum_{i=1}^n \alpha_i b_i,\ y=\sum_{j=1}^n \beta_j b_j $, то
	
	$\quad xy=(\sum_{i=1}^n \alpha_i b_i)(\sum_{j=1}^n \beta_j b_j)= \sum_{i,j=1}^n(\alpha_i b_i)(\beta_j b_j)=$
	
	$\quad=\sum_{i,j=1}^n(\alpha_i \beta_j)(b_i b_j) =\sum_{j=1}^n (\sum_{i=1}^n \alpha_i (b_i b_j))\beta_j = X^T G_B Y$
	
	$\quad (\alpha_1,...,\alpha_n) \begin{pmatrix}
		b_1 & b_j\\
		b_2&b_j\\
		...&...\\
		b_n&b_j
	\end{pmatrix}. \quad \boxtimes$\\
	\par \bigskip
	\textit{\textbf{Следствие}}
	
	\textit{В матрице Грамма системы В, $ G_B$, все главные угловые миноры больше нуля} $$\Delta_i>0,\ i=\overline{1,n}$$
	
	$\blacklozenge\ X = X^T G_B X >0$
	
	$\quad X \ne 0$
	
	$\quad f(X)=X^T G_B X >0, \forall X \ne 0_v \Rightarrow\Delta_i >0, \, i=\overline{1,n}$
	(по теореме Сильвестра). $\boxtimes$
	\par \bigskip
	\textbf{Теорема}
	
	\textit{Рассмотрим} $B=(b_1,...,b_k),\ b_i \in V,\ i=\overline{1,k}.\ B$\textit{ --- линейно зависимая} $\Longleftrightarrow det G_B=0$
	\par \bigskip
	$\blacklozenge $ 1) Пусть 
	$B$ --- линейно независимая система, $ B$ --- базис $L(B)$
	
	$\quad G_B \quad \Delta_i >0, \, i=\overline{1,k}, \quad det G_B =\Delta k >0$
	
	$\quad B$ --- ЛНЗ $\quad \Rightarrow \quad det G_B \ne 0$
	
	$\quad$Пусть $B$ --- ЛЗ $\quad \Rightarrow \alpha_1 b_1+...+\alpha_n b_n =0_v \quad \exists \alpha_i \ne 0$
	
	$\quad\begin{cases}
		\alpha_1(b_1b_1)+...+\alpha_n(b_n b_1)=0\\
		\alpha_1(b_1b_2)+...+\alpha_n(b_n b_2)=0\\
		\qquad\qquad\;\;\, ...\\
		\alpha_1(b_1 b_n)+...+\alpha_n(b_n b_n)=0\\
	\end{cases}$
	
	$\quad G_B \quad \begin{pmatrix}
		\alpha_1\\
		...\\
		\alpha_n
	\end{pmatrix} = 0_v \quad \Rightarrow det G_B=0$
	
	$\quad G_B X=0; \quad \exists X \ne 0\quad\boxtimes$
	\par \bigskip
	\textbf{Теорема}
	
	\textit{Пусть $ A, B$ --- базисы $V$. Тогда $G_B=S^T G_A S.\ S=S_{A \rightarrow B}$}
	\par \bigskip
	$\blacklozenge\;\ x,y \in V$
	
	$\quad X_A,X_B,...,Y_A,Y_B$ --- координаты в разных базисах
	
	$\quad S=S_{A \rightarrow B}$
	
	$\quad X_A=S X_B$
	
	$\quad Y_A=S Y_B$
	
	$\quad x \cdot y=X^T G_B Y$
	
	$\quad$Для $A$: $x \cdot y=X_A^T G_A Y_A=(S X_B)^T G_A (S Y_B)=X_B^T S^T G_A S Y_B$
	
	$\quad$Для $B$: $x \cdot y=X_B^T G_A Y_B$
	
	$\quad X_B^T G_B Y_B=X_B^T(S^T G_A S) Y_B, \forall X_B, Y_B$
	
	$\quad G_B=S^T G_A S \quad \boxtimes $
	
	
	
	
	
	
	
	\section{Ортогональные векторы.}
	$\quad\;$ Пусть $V$ --- Евклидово пространство.
	$a, b \in V$ --- \textbf{ортогональные} $(a \perp b) \Longleftrightarrow a \cdot b=0$
	
	Система векторов $B=(b_1,..,b_k), \, b_i \in V, \, i=\overline{1,k}$ называется \textbf{ортогональной}, если $b_i \cdot b_j = 0, \, i \ne j, \, \forall i,j \in \overline{1,k}$
	\par \bigskip
	\textbf{Лемма}
	
	\textit{Ортогональная система векторов линейно независима.}
	\par \bigskip
	$\blacklozenge\ B(b_1,...,b_k), \, b_i \in V, \, i=\overline{1,k} \quad b_i \cdot b_j=0, \, i \ne j,\ \forall(i,j)=\overline{1,k},\ b_i \ne 0 \Rightarrow B$ --- линейно
	
	\quadнезависима
	\par \bigskip 
	$\quad G_B=\begin{pmatrix}
		b_{1}b_1&0&0&...&0\\
		0&b_{2}b_2&0&...&0\\
		0&0&b_{3}b_3&...&0\\
		...&...&...&...&...\\
		0&0&0&...&b_{n}b_n
	\end{pmatrix},\ b_{i}b_i>0\Rightarrow det G_B \ne 0 \, \Rightarrow \, B$ --- линейно независима.$\quad \boxtimes$
	\par \bigskip
	\textbf{Теорема (Процесс ортогонализации Грама-Шмидта)}
	
	\textit{В любом Евклидовом пространстве существует ортогональный базис}
	\par \bigskip
	$\blacklozenge\ V$ --- Евклидово пространство
	
	$\quad V_B(b_1,...,b_n)$ --- базис $V$
	
	$\quad A=(a_1,...,a_n)$
	
	$\quad \cdot a_1=b_1$
	
	$\quad \cdot a_2=b_2+\alpha a_1 \quad (a_2 \ne 0_v)$
	
	$\quad a_1 a_2 =0 \, \sim \, a_1 a_2 = a_1(b_2 + \alpha a_1) = a_1 b_1 + a_1^2 \alpha =0$
	
	$\quad \alpha = - \dfrac{a_1 b_2}{a_1 a_1} \quad (a_1 \cdot a_1 \ne 0)$
	
	$\quad \cdot a_3=b_3+ \alpha_1 a_1 + \alpha_2 a_2 \quad (a_3 \ne 0_v) \, \rightarrow \, a_1 a_3 =0$ и $a_2 a_3 =0$
	
	$\quad \alpha_1=- \dfrac{a_1 b_3}{a_1 a_1} \quad \alpha_2= - \dfrac{a_2 b_3}{a_2 a_2}$
	
	$\quad a_n=b_n + \sum_{i=1}^{n-1} \alpha_i a_i, \, \alpha_i = - \dfrac{a_i b_n}{a_1 a_1}$
	
	$\quad a_i a_j =0 \, i \ne j \, i,j=\overline{1,n} \, a_i \ne 0_v \, \Rightarrow \, A$ --- линейно независимая
	
	$\quad$В любом Евклидовом пространстве $\exists$ ортогональный базис $\Rightarrow A$ --- базис $V. \quad \boxtimes$
	\par \bigskip
	\textbf{\textit{Ненулевые ортогональные векторы всегда независимы.}}
	\par \bigskip
	\textit{\textbf{Следствие}}
	
	\textit{Любую ортогональную систему ненулевых векторов можно дополнить до ортогонального базиса}
	\par \bigskip
	$\blacklozenge\ A(a_1,...,a_n), \quad a_i \ne a_i a_j =0, \, i\ne j, \, i,j=\overline{1,n}$
	
	$\quad A$ --- ортогональная система $\Rightarrow A$ --- линейно независимая
	
	$\quad (a_1,...,a_n,b_{k+k},...,b_n)$ --- базис
	
	$\quad \quad \Downarrow$
	
	$\quad (a_1,...,a_k,a_{k+1},...,a_n)$ --- ортогональный
	
	$\quad \quad \Downarrow$
	
	$\quad$к этому применяется ортогонализация. $\quad \boxtimes$
	\par \bigskip
	\textbf{Пример:}
	
	Применим процесс ортогонализации на $b_1(1,0,1,0), \, b_2(1,1,3,1), \, b_3(-2,1,0,5)$
	
	$V=L(b_1,b_2,b_3)$
	
	$a_1=b_2+\alpha a_1,$ где $\alpha= - \dfrac{a_1 b_2}{a_1 a_1}=-\dfrac{4}{2}=-2 $
	
	$a_2=(1,1,3,1)+(-2,0,-2,0)=(-1,1,1,1)$
	
	$a_3=b_3+\alpha_1 a_1+ \alpha_2 a_2$
	
	$\alpha_1=- \dfrac{a_1 b_1}{a_1 a_1}=- \dfrac{2}{2}=-1 \quad \alpha_2=- \dfrac{a_2 b_3}{a_2 a_2}=- \dfrac{8}{4}=-2$
	
	$a+3=b_1+a_1-2 a_2=(-2,1,0,5)+(1,0,1,0)+(2,-2,-2,-2)=(1,-1,-1,3)$
	
	$ 
	\begin{matrix}
		a_1(1,0,1,0)& a_1 a_2=0\\
		a_2(-1,1,1,1)&a_1 a_3=0\\
		a_3(1,-1,-1,3)& a_2 a_3=0\\
	\end{matrix}$
	
	
	
	
	
	
	
	
	
	
	\section{Длина вектора. Ортонормированный базис.}
	$\quad\;\ $Пусть $V$ --- Евклидово пространство. $|a|=\sqrt{a \cdot a}, \, a \in V, a \geqslant 0$ где $|a|$\textbf{ --- длина вектора}.
	\par \bigskip
	\textit{\textbf{Свойства длины:}}
	
	\textbf{1) }$|a|\ge 0, \, |a|=0 \, \Longleftrightarrow \, a=0_v$
	\par \bigskip
	$\blacklozenge \quad a \cdot a=0, \, a \ne 0_v \quad a \cdot a =0 \, \Longleftrightarrow a=0_v\quad\boxtimes$
	\par \bigskip
	\textbf{2) }$|\alpha a|=\alpha |a|, \, \forall a \in V, \, \forall \alpha \in \mathbb{R}$
	\par \bigskip
	$\blacklozenge \quad |\alpha a|=\sqrt{(\alpha a)(\alpha a)}=\sqrt{\alpha^2(a \cdot a)}=|\alpha|\sqrt{a\cdot a}=|\alpha||a|\quad\boxtimes$
	\par \bigskip
	\textbf{3) Неравенство Коши-Буняковского}
	
	$|ab| \le |a||b|, \, \forall a,b \in V$
	
	$|ab|=|a||b| \, \Longleftrightarrow \, a,b$\textit{ --- линейно зависимы}
	\par \bigskip
	$\blacklozenge \quad \forall\ a,b \Rightarrow G=\begin{pmatrix}
		aa&ab\\
		ba&bb\\
	\end{pmatrix} \Rightarrow detG=(aabb)-abba=|a|^2 \cdot |b|^2 - |ab|^2 \ne 0$
	
	$\quad\;\ |a \cdot b|=|a||b| \, \Longleftrightarrow \, a,b$\textit{---линейно зависимы} $(det G=0) \quad \boxtimes$
	\par \bigskip
	\textbf{Пример:}
	
	$\quad a, b \in V \, \mu=\arccos{\dfrac{ab}{|a||b|}} \quad \mu \in [0, \pi]$
	
	$\quad \mathbb{R} \quad A=\begin{pmatrix}
		1&2\\
		3&4\\
	\end{pmatrix} \quad B=\begin{pmatrix}
		-1&2\\
		5&3\\
	\end{pmatrix}$
	
	$\quad AB=-1+4+15+12=30 \quad |A|=\sqrt{A \cdot A}=\sqrt{1+4+9+16}=\sqrt{30} \quad|B|=\sqrt{B \cdot B}=$
	
	$\quad\sqrt{1+4+25+9}=\sqrt{39} $
	
	$\quad \mu=\arccos{\dfrac{30}{\sqrt{30}+\sqrt{39}}}=\arccos{\sqrt{\dfrac{30}{39}}}$
	\par \bigskip
	\textbf{4) Неравенство треугольника}
	
	$\quad |a+b| \le |a|+|b|, \, \forall a,b \in V$
	\par \bigskip
	$\blacklozenge \quad |a+b|^2=(a+b)(a+b)=a \cdot a+ b \cdot b + 2ab=|a|^2+|b|^2+2ab \le |a|^2+|b|^2+2|ab| \le $
	
	$\quad\ $ $|a|^2+|b|^2 + 2|a||b|  \quad \boxtimes$
	\par \bigskip
	\textbf{5) Теорема Пифагора}
	
	$\quad$Если $a \perp b$, то $|a+b|^2=|a|^2+|b|^2$
	\par \bigskip
	$\blacklozenge \quad |a+b|^2=(a+b)(a+b)=a \cdot a + b \cdot b +2ab=|a|^2+|b|^2  \quad \boxtimes$
	\par \bigskip
	$\bullet\ $\textit{Вектор называется\textbf{ нормированным}, если его длина равна единице}
	$(b \in V,\ |b|=1)$
	\par \bigskip
	$\bullet\ $\textit{Базис называется \textbf{ортонормированным}, если он ортогональный и нормированный}
	$(B(b_1,...,b_n),\ b_i b_j =0,\ i \ne j,\ i,j=\overline{1,k},\ |b_i|=1,\ i=\overline{1,k})$
	\par \bigskip
	\textbf{Теорема}
	
	\textit{В любом Евклидовом пространстве существует ортонормированный базис}
	\par \bigskip
	$\blacklozenge\ B=(b_1,...,b_n)$ --- ортогональный базис $V \, (b_i,\, b_j=0, \, i \ne j, \, i,j=\overline{1,n})$
	
	$\quad B'=(b_1',...,b_n') \quad b_i'=\dfrac{1}{|b_i|}b_i \, i=\overline{1,n} \quad |b_i|=|\dfrac{1}{|b_i|}b_i|=\dfrac{1}{|b_i|}|b_i|=1 $
	
	$\quad i\ne j,\ b_i' b_j'=\dfrac{1}{|b_i|}b_i \cdot \dfrac{1}{|b_j|}b_j=\dfrac{1}{|b_i||b_j|} b_i b_j =0 $
	\par \bigskip
	$\quad G_{B'} = E_n$ для ортогонального базиса
	\par \bigskip
	$\quad x,y \in V,\ X=\begin{pmatrix}
		\alpha_1\\
		...\\
		\alpha_n
	\end{pmatrix}, \ Y=\begin{pmatrix}
		\beta_1\\
		...\\
		\beta_n
	\end{pmatrix} $
	
	$\quad x \cdot y=X^T G_{B'} Y= X^T E_n Y=X^T Y=(\alpha_1,...,\alpha_n) \begin{pmatrix}
		\beta_1\\
		...\\
		\beta_n
	\end{pmatrix}= \alpha_1 \beta_1+...+\alpha_n \beta_n=$
	
	$\quad\sum_{i=1}^n \alpha_i \beta_i \quad \boxtimes$
	\par \bigskip
	$\bullet\ S \in \mathbb{R}_{nn}$\textit{ --- \textbf{ортогональная матрица}, если }$S^T S= S S^T=E_n \, \Longleftrightarrow \, S^{-1}=S^T$.
	
	\par \bigskip
	\textbf{Теорема}
	
	\textit{Пусть }$A,B$\textit{ --- ортонормированные базисы }$V$, $S=S_{A \rightarrow B}$. \textit{Тогда} $S \cdot S^T=E_n$\textit{ (ортогональная матрица}).
	\par \bigskip
	$\blacklozenge\ G_A, G_B$ --- матрицы скалярного произведения, $\, G_A=G_B=1, \, G_B=S^T G_A S, \, S=S_{A \rightarrow B}$
	
	$\quad E_n=S^T E_n S=S S^T \, \Rightarrow S^T S=E_n \quad \boxtimes$
	
	
	
	
	
	
	
	
	
	
	\section{Ортогональное дополнение.}
	\quad\;Пусть $V$ --- Евклидово пространство, $U \subset V$. Множество $U^{\perp}=\{a \in V \, | \, a \cdot b = 0, \forall\ b \in U\}$\textbf{ --- ортогональное дополнение. }
	\par \bigskip
	\textbf{Теорема}
	
	$U^{\perp} \subset V$\textit{ (ортогональное дополнение пространства} $V$), $U \cap U^{\perp}={0_v}$
	\par \bigskip
	$\blacklozenge\ 0_v \cdot b=0, \, \forall b \in U \, \Rightarrow 0_v \in U^{\perp} \, \Rightarrow U^{\perp} \ne \{\oslash\}$
	
	$\quad a_1,a_2 \in U^{\perp}, \, a_1 b=0, \, \forall b \in U, \, a_2 b=0, \, \forall b \in U$
	
	$\quad(a_1+a_2)b=a_1b+a_2b=0 \, \Rightarrow \, a_1+a_2 \in U^{\perp}$
	
	$\quad (\alpha a_1)b=\alpha(a_1 b)=\alpha\cdot 0=0 \, \Rightarrow \, \alpha a \in U^{\perp}$
	
	$\quad$Следовательно, $ U^{\perp} \subset V$
	
	$\quad a \in U \cap U^{\perp} \, \Rightarrow \, a \in U$ и $a \in U^{\perp} \, \Rightarrow \, a \cdot a=0 \, \Rightarrow \, a=0_v \quad \boxtimes$
	\par \bigskip
	\textbf{Теорема}
	
	\textit{Пусть} $V$\textit{ --- Евклидово пространство. }$ \forall\ U \subset V \Rightarrow V= U \oplus U^{\perp}$.
	\par \bigskip
	$\blacklozenge$\textit{ \underline{1 случай:}} $U=\{0_v\}, \, U^{\perp}=V$ (по определению)
	
	$\quad V=V \oplus \{0_v\}=U^{\perp} \oplus U$
	
	$\quad$\textit{\underline{2 случай:}} $U=V, \, U^{\perp}=\{0_v\},\ V=V \oplus \{0_v\}=U \oplus U^{\perp}$
	
	$\quad$\textit{\underline{3 случай:}} $dim V=n, dim U=k,\ 0<k<n$
	
	$\quad A_1(a_1,...,a_n)$ --- ортогональный базис
	
	$\quad U \, \Rightarrow \, a_i a_j=0, \, i \ne j, \, \forall\  i,j=\overline{1,n}$
	
	$\quad B(a_1,...,a_k,b_1,...,b_s) $ --- ортогональный базис $V,\ k+s=n$
	
	$\quad a \in U \, \Rightarrow \, a=\sum_{i=1}^k \alpha_i a_i,\ \sum_{j=1}^s \beta_j b_j$
	
	$\quad a \cdot \sum_{j=1}^s b_j \beta_j=(\sum_{i=1}^k \alpha_i a_i)(\sum_{j=1}^s \beta_j b_j)=\sum_{i=1}^k \sum_{j=1}^s \alpha_i \beta_j (a_i b_j)=0$
	
	$\quad L(b_1,...,b_s) \subset U^{\perp}$
	
	$\quad \forall x \in V, \, x= \alpha_1 a_1+...+\alpha_n a_n+b_1 \beta_1+...+b_s \beta_s \, \Rightarrow \, V=U + U^{\perp}, \, U \cap U^{\perp}=\{0_v\} \, \Rightarrow \,$
	
	$\quad V=U \oplus U^{\perp} $ $\boxtimes$
	\par \bigskip
	\textit{\textbf{Следствие 1}}
	
	$dim U+dim U^{\perp}= dim V$
	\par \bigskip
	$\blacklozenge \quad V=U \oplus U^{\perp} \, \Rightarrow \, dim V=dimU+dimU^{\perp} \quad \boxtimes$
	\par \bigskip
	\textit{\textbf{Следствие 2}}
	
	$(U^{\perp})^{\perp}=U$
	\par \bigskip
	$\blacklozenge\ dim V=dim U+dim U^{\perp}$
	
	$\quad dim V=dim (U^{\perp})^{\perp}+dim U^{\perp}$
	
	$\quad dim U=dim (U^{\perp})^{\perp} $
	
	$\quad a \in U,\ U^{\perp}=\{b \in V| a\cdot b=0, \, \forall a \in U\}$
	
	$\quad a \in  (U^{\perp})^{\perp} \, \Rightarrow \, \forall a \in V,\ a=a_1+a_2, \, a_1 \in U \, a_2 \in U^{\perp}$, где $a_1$ --- ортогональная проекция 
	
	\quad$a_2$ --- ортогональная составляющая $\quad \boxtimes$
	\par\bigskip
	\textbf{Пример:}\par
	$ a_1(1,1,1,1) \, a_2(1,2,2,0) \, a_3(0,1,0,1) \, , \, V=\mathbb{R}$\par
	$ U=L(a_1,a_2,a_3) \subset \mathbb{R}_4$\par
	$ X=(1,2,6,2)$\par
	$ x=x_1+x_2, \,$ где $\, x_1 \in U, \, x_2 \in U^{\perp}$\par
	$ x=x_1+x_2=\alpha_1 a_1+ \alpha_2 a_2+\alpha_3 a_3 + x_2 \, | \, a_i, \, x_2 a_i=0, \, i=\overline{1,3}$\par
	$ \begin{cases}
		x a_1=\alpha_1(a_1 \cdot a_1)+ \alpha_2 (a_2 \cdot a_1)+ \alpha_3(a_3 \cdot a_1)\\
		x a_2=\alpha_1(a_1 \cdot a_2)+ \alpha_2 (a_2 \cdot a_2)+ \alpha_3(a_3 \cdot a_2)\\
		x a_3=\alpha_1(a_3 \cdot a_1)+ \alpha_2 (a_3 \cdot a_2)+ \alpha_3(a_3 \cdot a_3)\\
	\end{cases}$\par
	$\begin{cases}
		11=4 \alpha_1+5 \alpha_2 + 2 \alpha_3\\
		17=5 \alpha_1+9 \alpha_2 + 2 \alpha_3\\
		4=2 \alpha_1+ 2\alpha_2 + 2 \alpha_3\\
	\end{cases} \, \Rightarrow \,
	\begin{pmatrix}
		4&5&2&\vrule&11\\
		5&9&2&\vrule&17\\
		2&2&2&\vrule&4\\
	\end{pmatrix} \sim \begin{pmatrix}
		4&5&2&\vrule&11\\
		5&9&2&\vrule&17\\
		1&1&1&\vrule&2\\
	\end{pmatrix} \sim \begin{pmatrix}
		1&1&1&\vrule&2\\
		2&3&0&\vrule&7\\
		3&7&0&\vrule&13\\
	\end{pmatrix} \sim$
	
	$\begin{pmatrix}
		1&1&1&\vrule&2\\
		2&3&0&\vrule&7\\
		-1&1&0&\vrule&-1\\ 
	\end{pmatrix}
	\sim \begin{pmatrix}
		0&2&1&\vrule&1\\
		0&1&0&\vrule&1\\
		-1&1&0&\vrule&-1\\
	\end{pmatrix} 
	\sim \begin{pmatrix}
		0&0&1&\vrule&-1\\
		1&0&1&\vrule&1\\
		-1&0&0&\vrule&-2\\
	\end{pmatrix}
	\sim \begin{pmatrix}
		1&0&0&\vrule&2\\
		0&1&0&\vrule&1\\
		0&0&1&\vrule&-1\\
	\end{pmatrix} 
	$\par
	$ \alpha_1=2, \, \alpha_2=1, \, \alpha_3=-1$\par
	$ x_1=2a_1+a_2-a_3=(2,2,2,2)+(1,2,2,0)+(0,-1,0,-1)=(3,3,4,1) \in U$\par
	$x_2=x-x_1=(1,2,6,2)-(3,3,4,1)=(-2,-1,2,1)$\par
	
	
	
	
	
	
	
	
	
	
	\section{Ортогональный оператор.}
	
	\quad\; Пусть $V$ --- Евклидово пр-во. Линейный оператор $f$: $ V \to V$ называется \textbf{ортогональным оператором (ОО)}, если $f(x) \cdot f(y)
	= x \cdot y,\quad \forall x,y \in V$.
	
	\par\bigskip
	
	\textit{ \textbf{Свойства ОО:}}
	\begin{enumerate}
		\item  \textit{ЛО f является ОО $\Longleftrightarrow  \forall x \in V: |f(x)| = |x|$}
		
		$\blacklozenge \ \ \Rightarrow)$ \ Пусть $f$ -- ОО $\Rightarrow |f(x)| = \sqrt{f(x) \cdot f(x)} = \sqrt{x \cdot y} = |x|$
		
		$\quad$   \ $\Leftarrow$) \ Пусть $f$ сохраняет длины всех векторов $\Rightarrow \forall x,y \in V: |x + y|^2 = (x+y)(x+y)= $ 
		
		$\quad  \ \ \ = x \cdot x + 2xy + y \cdot y =\ |x|^2 + 2xy + |y|^2. \ Аналогично |f(x + y)|^2 = |f(x) + f(y) |^2 = $ 
		
		$\quad  \ \ \ = |f(x)^2|+ 2 f(x)f(y) + |f(x)^2|.$ Т.к $f$ сохраняет длинны, то $|x + y|^2 = |f(x + y)|^2$
		
		$\quad\ \ \ $(откуда $\Rightarrow |x|^2 + 2xy + |y|^2 = |f(x)^2| + 2f(x)f(y) + |f(y)^2|$ ); 
		$|x|^2 = |f(x)|^2; |y|^2 = $
		
		$\quad \ \ \ |f(y)|^2 \Rightarrow 2xy = 2f(x)f(y) \Rightarrow xy = f(x)f(y) \Rightarrow f - $ОО$ $ $ \boxtimes$
		
		
		\item  \textit{Модуль собственного значения ОО $|\lambda_{0}| = 1.$  }
		
		$\blacklozenge$ \ \ \ Пусть $x$ -- собственный вектор, $\lambda_{0}$ -- его собственное значение  $\Rightarrow f(x) = \lambda_{0X} .$ Т.к. 
		
		$\quad \ \ \ |x| = |f(x)| \Rightarrow |x| = |\lambda_{0X}| = |\lambda_{0}| \cdot |x| \Rightarrow |\lambda_{0}| = 1. \boxtimes$
		
		\item  \textit{ ОО биективен.  }
		
		$\blacklozenge \ \ \ \forall x \in Ker(f) $(ядру $f$): $f(x) = 0_{V} \Rightarrow |x| = |f(x)| = |0_{V}| = 0 \Rightarrow |x| = 0 \Rightarrow x= 0_{V} \Rightarrow $
		
		$\quad \ \  Ker(f) = \ { 0_{V} }  \Rightarrow f - $ иньекция $ \Rightarrow f- $ сюрьекция $  \Rightarrow f - $ биекция$ \ \boxtimes$
		
		\par\bigskip
	\end{enumerate}
	
	\textbf{Теорема}
	
	\textit{ЛО $f$ является ОО $\Longleftrightarrow$ матрица линецного оператора $M_{f}$ -- ортогональная ($M_{f}^T \cdot M_{f} = M_{f} \cdot M_{f}^T = E)$}
	\par\bigskip
	$\blacklozenge\  \Rightarrow)$ Пусть $B$ --- ОНБ($V$).  $A = M_{f}^B$ (матрица линейного оператора в базисе $B$). Обозначим через $A_i$ координатные столбцы $A$. Тогда $A_i$ -- координатные столбцы $f(b_i)$ в базисе $B \Rightarrow f(b_i)f(b_j) = A_i^TG_BA_j = A_iA_j =$ элементу $A^TA$ в $i$-й строке и $j$-м столбце. С другой стороны, $f$ -- ОО $\Rightarrow f(b_i)f(b_j)= \begin{equation*}
		b_ib_j= 
		\begin{cases}
			0, i \neq j\\
			1, i = j
		\end{cases}
	\end{equation*} \ = AA^T = E$. Аналогично расписывается и $A^TA\quad\boxtimes$ 
	
	$\quad \Leftarrow$) Пусть $M_f = A $ в ОНБ($B$) --- ортогональна. Т.к. $B$ --- ОНБ, то $ G_B = E \Rightarrow \forall x, y \in V$ c координатными столбцами $X$ и $Y$ в базисе $B$ соответственно: $xy = X^TG_BY = X^TY.\\$
	С другой стороны,  $f(x)$ и $f(y)$ в базисе $B$ имеют координатные столбцы $AX$ и $AY$ соответственно $\Rightarrow f(x) и f(y) = (AX)^TG_BAY = X^TA^TAY=[A^TA=E] = X^TY = xy \Rightarrow f $-- ОО $ \boxtimes$  
	\par\bigskip
	\textbf{Теорема}
	
	\textit{ЛО f является ОО $\Longleftrightarrow$ он отображает ОНБ в ОНБ}.
	\par\bigskip
	$\blacklozenge\  \Rightarrow$) Пусть $f$ --- ОО, $ B = (b_1,..., b_n)$ --- ОНБ ($V$). Т.к. ОО сохраняет длины и скалярное произведение, то он переводит ОНСВ в ОНСВ.  При этом из-за сохранений длин $f(B)$ --- ОНСВ без нулевого вектора (т.к. $B$ является базисом, т.е. априори не имеет нулевого вектора) $ \Rightarrow $ СВ $f(B)$ --- базис $V$ (т.к. является ортонормированной системой ненулевых векторов). 
	
	$\quad$ $\Leftarrow$) Пусть $f$ переводит $B(b_1,..., b_n)$ --- ОНСВ в $f(B) = (f(b_1), ..., f(b_n))$ --- т.ж. ОНСВ и пусть $ x,y$ --- два любых вектора $ \in V$. Если $X,Y$ --- их координатные столбцы в базисе $B$, то $x \cdot y = X^TG_BY = $ [ т.к в ОНБ $G_B = 1$ ] $ = X^TY.$ Если $ X = \begin{pmatrix}x_1\\ \vdots \\ x_n\end{pmatrix}$, то $x = x_1b_1+ ... + x_nb_n \Rightarrow f(x) = f(x_1b_1 + ... + x_nb_n) = $ [ т.к. $f$ --- ЛО ] $ = x_1f(b_1)+ ... + x_nf(b_n) \Rightarrow $ координаты $f(x)$ в базисе $f(B)$ равны координатам $x$ в базисе $B\  \Rightarrow  f(x)f(y) = X^TG_{f(B)}Y = X^TY = xy  \Rightarrow f$ --- ОО $\boxtimes$
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Самосопряженный оператор.}
	\quad \; Пусть $V$– Евклидово пространство $f:{V \rightarrow V}$. Тогда говорят, что $f$  является \textbf{самосопряжённым оператором}, если $\forall x, y \in V: f(x)\cdot y=x\cdot f(y)$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $B = (b_1, ..., b_n)$ --- ортогональный базис пространства V, $M_B(f)=A$. Тогда $f$ является самосопряжённым оператором $\Longleftrightarrow$ его матрица в ортонормированном базисе симметрическая ($A = A^T$) }.
	\par\bigskip
	$\blacklozenge\Rightarrow) $
	$B(b_1, ..., b_n)$ --- ортогональный базис пространства $V$ $\Rightarrow  b_ib_j=0, i,j=\overline{1, n}$
	\par\bigskip
	$M_B(f)=A=(\alpha{ij})\in R_{n,n}$
	\par\bigskip
	Тогда $f(b_i)=\alpha_{1i}b_1+...+\alpha_{ni}b_n$
	\par\bigskip
	$f(b_i)b_j=(\alpha_{1i}b_1+...+\alpha_{ni}b_n)b_j=\begin{bmatrix}
		b_ib_j=0, i\neq j\\ 
		b_ib_j=1, i= j
	\end{bmatrix}=\alpha_{ji}$
	\par\bigskip
	$f(b_i)b_j=(\alpha_{1j}b_1+...+\alpha_{nj}b_n)b_i=\alpha_{ij}$
	\par\bigskip
	Так как $f$ --- самосопряженный $\Rightarrow  \alpha_{ji}=\alpha_{ij}$, $\forall i,j=\overline{1, n} \Rightarrow A=A^T$ 
	\par\bigskip
	
	
	$\Leftarrow) $
	Пусть $M_B(f)=A$ и она симметрическая $(A = A^T)$. Т.к. $B$ -  ортонорм., то $G_B=E_n.$
	\par\bigskip
	Учитывая, что $xy=X^TG_BY$, $f(x)=AX$ и $A = A^T$, получим:
	\par\bigskip
	$f(x)\cdot y=(AX)^TG_BY=X^TA^TY=X^TAY=X^TE_n(AY)=X^TG_B(AY)=x\cdot f(y)$
	$ \quad \boxtimes$ 
	
	\textit{ \textbf{\\* Свойства самосопряженного операторов:}}
	\begin{enumerate}
		\item \textit{Характеристическое уравнение самосопряженного оператора имеет только действительные корни.}
		\par\bigskip
		$\blacklozenge$ 
		Пусть $f$ --- самосопряженный оператор, $A$ --- его матрица в ортонормированном базисе $(M_B(f)=A$. Тогда A - симметрическая $(A=A^T)$.\\
		Пусть $\lambda_0$ - мнимый корень характеристического уравнения $det(A-\lambda_0 E)=0$.\\
		Следовательно, $(A-\lambda_0 E)X=0$ имеет ненулевое решение $X_0$.\\
		$(A-\lambda_0 E)X=0 \Rightarrow AX_0=\lambda_0X_0$\\\\
		Тогда $\lambda_0(X_0^T\overline{X_0})=(\lambda_0X_0)^T\overline{X_0}=(\lambda_0X_0)^T\overline{X_0}=(AX_0)^T\overline{X_0}=X_0^TA^T\overline{X_0}=X_0^TA\overline{X_0}=X_0^T(\overline{A} \overline{X_0})=X_0^T(\overline{\lambda_0X_0})=X_0^T(\overline{\lambda_0}\cdot \overline{X_0})=\overline{\lambda_0}(X_0^T\overline{X_0})$\\\
		Т.к. столбец $\begin{pmatrix}x_1\\\vdots \\ x_n\end{pmatrix}$ - ненулевой, то $X_0^T\overline{X_0}=(x_1 ...x_n)\cdot \begin{pmatrix}\overline{x_1}\\\vdots \\ \overline{x_n}\end{pmatrix}=x_1\overline{x_1}+...+x_n\overline{x_n}=|x_1|^2+...+|x_n|^2>0$\\\\
		Следовательно, $X_0^TX_0$ --- невырожденно и, следовательно, $\lambda_0=\overline{\lambda_0}$, т.е. $\lambda_0$ - действительное число.
		$\quad\boxtimes$
		\item \textit{Собственные векторы самосопряженного оператора, соответствующие различным собственным значениям, ортогональны.}
		\par\bigskip
		$\blacklozenge$
		Пусть $a_1$, $a_2$ - собственные векторы самосопряженного оператора $f$, соответствующие
		$\lambda_1$ и $\lambda_2$ ($\lambda_1 \neq \lambda_2$).
		Тогда $f(a_1)=\lambda_1a_1$ и $f(a_2)=\lambda_2a_2$.\\\\
		$\left.\begin{matrix}
			f(a_1)a_2=\lambda_1(a_1a_2)\\
			a_1f(a_2)=a_1(\lambda_2a_2)=\lambda_2(a_1a_2)
		\end{matrix}\right\}\Rightarrow \lambda_1(a_1a_2)=\lambda_2(a_1a_2)$\\\\
		И следовательно $(\lambda_1-\lambda_2)(a_1a_2)=0\Rightarrow a_1a_2=0$
		$\quad\boxtimes$
		\item  Если $f$ --- самосопряженный оператор, $U \subset V$ и $f(U)\subset U$, где $U$ - ортогональное подпространство пространства $V$, то $\Rightarrow f(U^\perp)\subset U^\perp $
		\par\bigskip
		$\blacklozenge$
		$\forall x \in U^\perp \Rightarrow f(x)\in U^\perp$, $\forall x \in U^\perp \Rightarrow xy=0$, $\forall y \in U \\$\\
		$f(x)\cdot y=x\cdot f(y), y \in U \Rightarrow f(y) \in U\Rightarrow xf(y)=0$\\
		$f(x)\cdot y=x\cdot f(y)=0\Rightarrow f(x)\cdot y = 0, \forall y \in U\Rightarrow f(x) \in U^\perp $
		$\quad\boxtimes$
	\end{enumerate}
	
	\textbf{Теорема}
	
	\textit{Для любого самосопряженного оператора $f$ существует ортонормированный базис пространства $V$, состоящий из собственных векторов оператора $f$.}
	\par\bigskip
	$\blacklozenge$
	Пусть $f$ – самосопряженный оператор, $\lambda_1, ..., \lambda_s$ – различные собственные значения оператора $f$. Обозначим через $L(\lambda_i)$ собственные подпространства $f$ соответствующие собственному значению $\lambda_i$. Построим в каждом из них ортонормированные базисы = $B_i$, а затем построим систему векторов $B = (B_1, ..., B_s)$. Покажем, что $B$ – ортонормированный базис пространства $V$.\\
	Т.к. собственные вектора самосопряженного оператора, соответствующие различным собственным значениям ортогональны, то система векторов $B$ является ортонормированной  $\Rightarrow B$ – линейно независима. Предположим, что $B$ не базис $\Rightarrow L(B) \neq V \Rightarrow dim(V) = n > dim(L(B)) = m$. При этом $L(B) \oplus L(B)^\perp = V \Rightarrow dim(L(B)^\perp)\geqslant 1$\\
	
	Покажем, что $L(B)$ инвариантное относительно $f$ подпространство $V$. Пусть $b \in L(B)$,
	тогда $b = \alpha_1b_1 + ... + \alpha_mb_m$, где $b_1 \in B_1$, $b_m \in B_s$. \\
	Тогда $f(b) = f(\alpha_1b_1 + ... + \alpha_mb_m) = \alpha_1f(b_1) +... + \alpha_mf(b_m) = \alpha_1\lambda_1b_1 + ... + \alpha_m\lambda_sb_m \in L(B)$\\
	Следовательно, $L(B)$ --- инвариантное относительно $f$ подпространство $V$\\ 
	Следовательно, $L(B)^\perp$ тоже инвариантно относительно $f$ (по свойству 3)\\
	Следовательно, отображение $f|_{L(B)^\perp}$ (ограничение $f$ на $L(B)^\perp$) является линейным и самосопряженным оператором.\\
	Следовательно, $\exists \lambda_0 \in R$ этого оператора $\Rightarrow \exists x_0 \in L(B)^\perp: f|_{L(B)^\perp}(x_0) = \lambda_0x_0$. \\
	Но $f(x_0) = \lambda_0x_0 = f|_{L(B)^\perp}\perp x_0 \Rightarrow x_0 $– собственный вектор $f$, который $\in L(B)^\perp \Rightarrow$ получаем противоречие с тем, что $L(B)$ изначально содержал все собственные вектора $\Rightarrow B$ - базис. $\boxtimes$
	
	
	
	
	
	
	
	
	\section{Унитарное пространство.}
	\quad\;Пусть $V$ --- векторное пространство над полем $\mathbb{C}$. Тогда отображение $V \times V\mapsto \mathbb{C}$,
	ставящее в соответствие каждой упорядоченной паре векторов $a, b \in V$ число $ab\in \mathbb{C}$, называется \textbf{скалярным произведением}, если:
	\begin{enumerate}
		\item$ab = \overline{ba}$
		\item$(\alpha a)b = \alpha(ab)$
		\item$a(b + c) = ab + ac$
		\item$\forall  a \neq 0_{V} , aa \in R$  и $aa > 0$
	\end{enumerate}
	\textbf{Пример:}
	
	$C_{n}$ $a(\alpha_{1}, ...  , \alpha_{n})$ и $b(\beta_{1}, ...  , \beta_{n})$, 
	$ab= \alpha_{1} \overline{\beta_{1}} + ... + \alpha_{n} \overline{\beta_{n}} = \sum\limits_{i=1}^{n}{\alpha_{i} \overline{\beta_{i}}}$\\
	%\par\bigskip
	\textit{ \textbf{Свойства скалярного произведения:}}
	\begin{enumerate}
		\item $a(\alpha b) = \overline{\alpha}(ab)$, $\alpha \in \mathbb{C}$
		\par\bigskip
		$\blacklozenge\ $
		$a(\alpha b) = \overline{(\alpha b)a}=\overline{\alpha(ba)}=\overline{\alpha}(\overline{ba})= \overline{\alpha}ab$
		$ \quad \boxtimes$
		
		\item $a(b + c) = ab + ac$
		\par\bigskip
		$\blacklozenge$
		$\overline{(b + c)a}=\overline{ba+ca}=\overline{ba} + \overline{ca} = ab + ac$
		$\quad\boxtimes$
		
		\item  $a \cdot 0_{V}=0_V$, $\forall a \in V$
		
	\end{enumerate}
	\par\bigskip
	Из определения скалярного произведения следует, что элементы матрицы Грама
	\par\bigskip
	$G_B=\begin{pmatrix}
		b_1b_1&...& b_1b_n\\ 
		\vdots &  & \vdots \\ 
		b_nb_1&...& b_nb_n
	\end{pmatrix}\in \mathbb{C}_{n,n}$, произвольной системы векторов $B(b_1, ..., b_n)$ удовлетворяет: $b_ib_j=\overline{b_jb_i}$
	\par\bigskip
	$\bullet$\textit{ Матрица  $B(\beta_{ij})$ \textbf{эрмитово сопряженная} для матрицы $A(\alpha_{ij})$, если $\beta_{ij}=\overline{\alpha_{ji}}$, т.е. $A^*=\overline{A^T}$.}
	\par\bigskip
	$\bullet$ \textit{Матрица \textbf{эрмитова}, если $A=A^*$}
	\par\bigskip
	Таким образом, матрица Грама эрмитова $G_B=(G_B)^*$ для любой системы векторов.
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Если $B$ --- базис пространства V, $X=\begin{pmatrix}x_1\\ \vdots \\ x_n\end{pmatrix}$, $Y=\begin{pmatrix}y_1\\ \vdots \\ y_n\end{pmatrix}$ – координатные столбцы векторов $x,y$ в базисе B , то $xy = X^TG_B\overline{Y}$}.
	\par\bigskip
	$\blacklozenge\ $
	$x=\sum\limits_{i=1}^{n}{x_ib_i}$, $y=\sum\limits_{j=1}^{n}{y_jb_j}$
	\par%\bigskip
	$xy=(\sum\limits_{i=1}^{n}{x_ib_i})(\sum\limits_{j=1}^{n}{y_jb_j})=\sum\limits_{i,j=1}^{n}{(x_ib_i)(y_jb_j)}=\sum\limits_{i,j=1}^{n}{(x_i\overline{y_j})(b_ib_j)}=(x_1,...x_n)\cdot G_B\cdot \begin{pmatrix}\overline{y_1}\\ \vdots \\ \overline{y_n}\end{pmatrix}$
	$ \quad \boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	\textit {Если $G_A$ и $G_B$ матрицы скалярного произведения в базисах
		$A,B \in V$ соответственно, то $G_B = S^T G_A \overline{S}$, где $S=S_{A\rightarrow B}$.}
	\par\bigskip
	$\blacklozenge$ 
	$(xy) = X^TG_B\overline{Y}$ - в базисе B, $SX_A=X_B$ для базиса $B$.
	\par\bigskip
	$X^TG_B\overline{Y}=(SX)^TG_A(\overline{SY})=X^T\cdot S^TG_A\overline{S}\cdot \overline{Y}=X^T(S^TG_A\overline{S})\overline{Y}\Rightarrow G_B=S^TG_AS$
	$\quad\boxtimes$
	\par\bigskip
	$a,b\in V$- ортогональные, если $ab=0$ (то же, что и для евклидовых пространств)
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Пусть $B = (b_1, ..., b_n)$ --- базис пространства V. Тогда $det$ $G_B > 0$ (в унитарном пространстве)}.
	\par\bigskip
	$\blacklozenge\ $
	Пусть $A = (a_1, ..., a_n)$ - ортогональный базис пространства V.
	\par\bigskip
	Тогда $a_ia_j = 0, \forall i \neq j \in \overline{1,n}$
	\par\bigskip
	$G_A=\begin{pmatrix}a_1a_1&...& 0\\ \vdots & \ddots  & \vdots \\ 0&...& a_na_n\end{pmatrix}$
	\par\bigskip
	При этом, $a_ia_i > 0$, $i = \overline{1,n}$, следовательно det $G_A = (a_1a_1)...(a_na_n)>0$
	\par\bigskip
	Пусть $B$ - базис $V$. Тогда $G_B = S^T G_A \overline{S}$, $S=S_{A\rightarrow B}$
	\par\bigskip
	det $G_B = det(S^T G_A \overline{S})=det(S^T)\cdot det(G_A)\cdot det(\overline{S})=det(S)\cdot det(G_A)\cdot det(\overline{S})=$\par$=(det(S)\cdot det(\overline{S}))\cdot det(G_A) = |det(S)|^2det(G_A)$ 
	\par\bigskip
	Т.к $|det(S)|>0$ и $det(G_A)>0 \Rightarrow det(G_B)>0$
	$ \quad \boxtimes$
	\par\bigskip
	$\forall a \in V$,  $|a|=\sqrt{aa}$ --- \textbf{длина вектора} a.
	\par\bigskip
	Если каждый $b_i$ ортогонального базиса $B$ умножить на $|\overline{b_i}|$ , то получим ортонормаированный базис пространства $V$. Следовательно, в любом унитарном пространстве существует ортонормированный базис.
	\par\bigskip
	$\bullet$\textit{ Матрица А называется \textbf{унитарной}, если $S^*\cdot S=E_n$.}
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Матрица перехода от ортонормированного базиса к ортонормированному
		является унитарной, т.е. если $S=S_{A\rightarrow B} \Rightarrow$ $S^*\cdot S=E_n$}.
	\par\bigskip
	$\blacklozenge\ $Если А и B --- ортонормированные базисы $V$, то $G_A=E_n=G_B$.
	\par\bigskip
	\quadПри этом, $G_B = S^T G_A \overline{S}$, где $S=S_{A\rightarrow B}$.
	\par\bigskip
	\quadСледовательно, $E_n = S^T \cdot E_n \cdot \overline{S}=S^T \cdot \overline{S}$
	\par\bigskip
	$\quad E_n = E_n^T =  (S^T\cdot \overline{S})^T=\overline{S}^T\cdot S=S^*\cdot S$
	$ \quad \boxtimes$
	\par\bigskip
	$\bullet$\textit{ Линейный оператор унитарного пространства $V$ называется \textbf{унитарным (изометрическим)}, если $\forall x,y \in V$ $f(x)f(y)=xy$. }
	\par\bigskip
	$\bullet$\textit{ Линейный оператор называется \textbf{самосопряженным}, если $\forall x,y \in V$ $f(x)y = xf(y)$. }
	\par\bigskip
	\textit{ \textbf{Свойства унитарного и самосопряженного оператора:}}
	\begin{enumerate}
		\item \textit{Если $f$ --- самосопряженный оператор, то все собственные значения самосопряженного оператора --- действительные числа.}
		
		$\blacklozenge\ $
		$f(a)=\lambda a$, $f(a)\cdot a = \lambda a \cdot a = \lambda(a \cdot a)$\\ 
		$a \cdot f(a)  = a ( \lambda \cdot a) = \overline{\lambda}(a \cdot a)$\\
		$f(a)\cdot a = a \cdot f(a) \Leftrightarrow \lambda(a \cdot a) = \overline{\lambda}(a \cdot a)\Leftrightarrow (\lambda- \overline{\lambda})(a \cdot a)=0$\\
		$\Rightarrow $ т.к. $a \neq 0_V$, $\lambda = \overline{\lambda} \Rightarrow \lambda \in R$.
		$ \quad \boxtimes$
		
		\item  \textit{Если $f$ --- унитарный оператор, то модуль собственного значения унитарного оператора равен 1.}
		
		$\blacklozenge$
		$f(a)=\lambda a$, $f(x)f(y)=xy$.\\
		$|a|^2=a\cdot a = f(a)f(a) = \lambda a \cdot \lambda a = \lambda \overline{\lambda}(aa) = \lambda \overline{\lambda}|a|^2 >0 $
		
		Т.к. $a \neq 0_V$, $\Rightarrow \lambda \overline{\lambda} = 1 \Rightarrow |\lambda|^2=1 \Rightarrow |\lambda|=1$.
		$\quad\boxtimes$
		
	\end{enumerate}
	
	
	
	
	
	
	
	
	
	\section{Приведение действительных квадратичных форм к каноническому виду с помощью ортогональных преобразований.}
	
	\quad\;Пусть $f(x_1...x_n)=\sum\limits_{i,j=1}^{n}{\alpha_{i}x_i x_j}$, $\alpha_{ij}=\alpha_{ji}\in \mathbb{R}$ --- квадратичная форма. Тогда $A=(\alpha_{ij})$ --- матрица этой квадратичной формы через столбец $X=\begin{pmatrix}x_1\\ \vdots \\ x_n\end{pmatrix}.$
	
	Тогда квадратичная форма $f$ в матричном виде имеет вид $f(X)=X^TAX$
	
	Линейное преобразование переменных $X=SY$ называется \textit{\textbf{ортогональным}}, если матрица преобразования ортогональна: $S^TS=E$.
	
	Т.к. ортогональная матрица является невырожденной, то и ортогональное преобразование тоже \textbf{\textit{невырожденное}} ($det S \neq 0)$.
	\par\bigskip
	\textbf{Лемма}
	
	\textit{Для любой действительной симметрической матрицы $A$ существует ортогональная матрица $S$, такая что $S^TAS$ --- диагональная, и её диагональные элементы --- собственные значения матрицы $A$}.
	\par\bigskip
	$\blacklozenge\ $
	Т.к. отображение, ставящее в соответствие каждому линейному оператору матрицу этого линейного оператора в некотором базисе $Е$, является \textit{\textbf{изоморфизмом}}, то существует линейный оператор $f$, матрица которого в базисе $E$ совпадает с матрицей $A$, т.е. $M_f^E$.
	\par\bigskip
	Т.к. $A$ --- симметрическая, а $E$ --- ортонормированная, то $f$ является самосопряженным оператором $\Rightarrow \exists $ ортонормированный базис $B$, составленный из собственных векторов линейного оператора $f$.
	\par\bigskip
	При этом матрица линейного оператора $f$ в этом базисе диагональная и диагональные элементы --- собственные значения матрицы $A$.
	\par\bigskip
	Если $S=S_{E\rightarrow B}$, то $M_f^B = S^{-1}M_f^E S = S^{-1}AS$
	\par\bigskip
	Т.к. $S^TS=E \Rightarrow S^T = S^{-1} \Rightarrow M_f^B = S^{T}AS$
	$ \quad \boxtimes$
	\par\bigskip
	
	
	\textbf{Теорема}
	\par
	\textit{Для любой действительной квадратичной формы $f(x)$ существует линейное ортогональное преобразование переменных $X=SY$, приводящее $f$ к канонической квадратичной форме $\lambda_1y_1^2 + ... \lambda_ny_n^2$, где $\lambda_i$ --- собственное значение матрицы квадратичной формы $f$}.
	\par\bigskip
	$\blacklozenge\ $Пусть $A$ --- симметрическая матрица квадратичной формы $f$. Тогда $f(x)=X^TAX$.
	
	\quadСледовательно, существует ортогональная матрица $S$, такая что $D=S^TAS$ диаго-
	
	\quadнальная с собственными значениями матрицы $A$.
	
	\quadТогда $f(SY)=(SY)^TASY=Y^T(S^TAS)Y=Y^TDY=\lambda_1y_1^2 + ... + \lambda_ny_n^2$
	$ \quad \boxtimes$
	\par\bigskip
	\textit{\textbf{Следствие}}
	\par
	\textit{Квадратичноя форма является положительно определённой $\Longleftrightarrow$ все собственные значения матрицы квадратичной формы > 0.}
	
	
	
	
	
	
	
	\section{Нормированные пространства.}
	Пусть $V$ --- векторное пространство над $P=\begin{Bmatrix}\mathbb{R,C}\end{Bmatrix}$.\\
	Тогда отображение $\left \| \cdot  \right \|:V\rightarrow \mathbb{R}$, ставящее в соответсвие $a \in V \mapsto \left \|a\right \|$, называется \textbf{\textit{векторной нормой}}, если:
	\begin{enumerate}
		\item $\left \|a\right \| \geqslant 0$\\
		$\left \|a\right \| = 0 \Leftrightarrow a = 0_V$
		\item $\left \|\alpha a\right \|=|\alpha|\left \|a\right \|$
		
		\item  $\left \|a+b\right \| \leqslant \left \|a\right \| + \left \|b\right \|$
	\end{enumerate}
	\par\bigskip
	\textbf{Примеры}:
	\par\bigskip
	Пусть $V$ --- или $\mathbb{R}^n$, или $\mathbb{C}^n$; $a=(\alpha_1...\alpha_n) \in V$
	\begin{enumerate}
		\item $\left \|a\right \|_e=\sqrt{\sum\limits_{i=1}^{n}{|\alpha_i}|^2}$ --- \textbf{\textit{евклидова норма.}}\\
		
		\item $\left \|a\right \|_0=\sum\limits_{i=1}^{n}{|\alpha_i}|$ --- \textit{\textbf{октаэдрическая.}}
		
		\item  $\left \|a\right \|_k=\underset{1 \leqslant i \leqslant n}{max|x_i|}$ --- \textbf{\textit{кубическая}}.
	\end{enumerate}
	\hspace{0pt}\\
	По сути,\textit{\textbf{ норма --- аналог длины вектора}}\\
	$\bullet\ (V, \left \| \cdot \right \|)$ ---\textit{ называется \textbf{нормированным пространством}}.
	\par\bigskip
	$\left \| \cdot \right \|_1=\alpha\left \| \cdot \right \|$
	\par\bigskip
	$\left \| a \right \|_1=\alpha\left \| a \right \|$, $\forall a \in V$
	\par\bigskip
	$\left \| a \right \|_1 \leqslant \left \| a \right \|_2$, $\forall a \in V$ $\Rightarrow \left \|  \right \|_1 \leqslant \left \|  \right \|_2$\\\\
	$\bullet$ \textit{Нормы называются \textbf{\textit{эквивалентными}} ($\left \|  \right \|_1 \sim \left \|  \right \|_2$), если существует две положительные константы $(\alpha_1, \alpha_2 > 0)$, такие что $\alpha_1 \left \| \right \|_2 \leqslant \left \|  \right \|_1 \leqslant \alpha_2\left \|  \right \|_2$}
	\begin{enumerate}
		\item \textbf{\textit{Рефликсивность:}} \\
		$\left \| \right \|_1 \sim \left \|  \right \|_1$\\\\
		$\exists \alpha_1=\alpha_2=1$\\
		$1\cdot \left \| \cdot \right \|_1 \leqslant \left \| \cdot \right \|_1 \leqslant 1 \cdot \left \| \cdot \right \|_1$
		\item \textbf{\textit{Симметричность:}}  \\
		$\left \| \cdot \right \|_1 \sim \left \| \cdot \right \|_2 \Rightarrow \left \| \cdot \right \|_2 \sim \left \| \cdot \right \|_1 $\\\\
		$\blacklozenge\ $
		$\left \| \cdot \right \|_1 \sim \left \| \cdot \right \|_2 \Rightarrow \alpha_1 \left \| \cdot \right \|_1 \leqslant \left \| \cdot \right \|_2 \leqslant \alpha_2 \left \| \cdot \right \|_1$ \\\\
		$\left.\begin{matrix}
			\left \| \cdot \right \|_1 \leqslant \alpha_2\left \| \cdot \right \|_2 \Rightarrow \frac{1}{\alpha_2}\left \| \cdot \right \|_1\leq\left \| \cdot \right \|_2\\\\
			\alpha_1\left \| \cdot \right \|_2 \leqslant \left \| \cdot \right \|_1 \Rightarrow \left \| \cdot \right \|_2 \leq\frac{1}{\alpha_1}\left \| \cdot \right \|_1
		\end{matrix}\right\}\frac{1}{\alpha_1}\left \| \cdot \right \|_1 \leqslant \left \| \cdot \right \|_2 \leqslant \frac{1}{\alpha_2}\\
		\Rightarrow \left \| \cdot \right \|_2 \sim \left \| \cdot \right \|_1$
		$\boxtimes$
		\item  \textbf{\textit{Транзитивность:}}\\
		$\left \| \cdot \right \|_1 \sim \left \| \cdot \right \|_2$, $\left \| \cdot \right \|_2 \sim \left \| \cdot \right \|_3 \Rightarrow \left \| \cdot \right \|_1 \sim \left \| \cdot \right \|_3  $\\\\
		$\blacklozenge\ $
		$\left \| \cdot \right \|_1 \sim \left \| \cdot \right \|_2 \Rightarrow \alpha_1\left \| \cdot \right \|_1 \leqslant \left \| \cdot \right \|_2 \leqslant \alpha_2\left \| \cdot \right \|_1\\
		\left \| \cdot \right \|_2 \sim \left \| \cdot \right \|_3 \Rightarrow \beta_1\left \| \cdot \right \|_2 \leqslant \left \| \cdot \right \|_3 \leqslant \beta_2 \left \| \cdot \right \|_2 \Rightarrow\\
		\alpha_1\beta_1\left \| \cdot \right \|_1 \leqslant \beta_1\left \| \cdot \right \|_2 \leqslant \left \| \cdot \right \|_3 \leqslant \beta_2 \left \| \cdot \right \|_2 \leqslant \alpha_2 \beta_2 \left \| \cdot \right \|_1 \Rightarrow \left \| \cdot \right \|_1 \sim \left \| \cdot \right \|_3$
		$\boxtimes$
	\end{enumerate}
	\par\bigskip
	\textbf{Теорема}
	
	\textit{В пространстве $P_n$ нормы эквивалентны}.
	\par\bigskip
	$\blacklozenge\ a(x_1, \cdots, x_n) \in P_n$, $h = (e_1, \cdots, e_n)$
	\par\bigskip
	$\quad e_1(1, 0, \cdots, 0)$, $e_2(0, 1, \cdots, 0)$, $\cdots$, $e_n(0, 0, \cdots, 1)$
	\par\bigskip
	$\quad a = x_1e_1 + \cdots + x_ne_n = \sum\limits_{i=1}^{n}{x_ie_i}$
	\par\bigskip
	$\quad \left \|a\right \|=\left \|\sum\limits_{i=1}^{n}{x_ie_i}\right \|=\sum\limits_{i=1}^{n}{\left \|x_ie_i\right \|}=\sum\limits_{i=1}^{n}{|x_i|\left \|e_i\right \|}\leqslant \underset{1 \leqslant i \leqslant n}{max|e_i|}\sum\limits_{i=1}^{n}{|x_i|}=\alpha\sum\limits_{i=1}^{n}{|x_i|}=\alpha\left \|a\right \|_0$
	\par\bigskip
	$\quad \left \|a\right \| \leqslant \alpha \left \|a\right \|_0$
	\par\bigskip
	$\quad \left \|a\right \| \leqslant \sum\limits_{i=1}^{n}{|x_i|\left \|e_i\right \|}= \underset{1 \leqslant i \leqslant n}{max|x_i|}\sum\limits_{i=1}^{n}{\left \|e_i\right \|}=\beta\underset{1 \leqslant i \leqslant n}{max|x_i|}=\beta\left \|a\right \|_1$
	\par\bigskip
	$\quad \left \|a\right \| \leqslant \beta\left \|a\right \|_k$, $\left \|a\right \|_0 \leqslant \beta\left \|a\right \|_k=\frac{1}{\beta}\left \|a\right \|_0 \leqslant \left \|a\right \|_k$, $\forall a \in P_n$
	\par\bigskip
	$\quad \frac{1}{\beta}\left \|a\right \|_0 \leqslant \left \|a\right \|_k \leqslant \alpha \left \|a\right \|_0 \rightarrow \left \|a\right \|_0 \sim \left \|a\right \|_k \rightarrow  \left \|\cdot\right \|_0 \sim \left \|\cdot\right \|_k$
	\par\bigskip
	$\quad \underset{1 \leqslant i \leqslant n}{max|x_i|}\leq\sqrt{\sum\limits_{i=1}^{n}{|x_i|^2}}\leq\sqrt{n\cdot\underset{1 \leqslant i \leqslant n}{max|x_i|^2}}=\sqrt{n}\cdot\underset{1 \leqslant i \leqslant n}{max|x_i|}$
	\par\bigskip
	$\quad \left \|a\right \|_k=\left \|a\right \|_E\leqslant \sqrt{n}\left \|a\right \|_k$, $\forall a \in V \rightarrow  \left \|\right \|_E \sim \left \|\right \|_k$
	\par\bigskip
	$\quad  \left \|\right \|_E \sim \left \|\right \|_k,  \left \|\right \|_k\sim \left \|\right \|_0 $
	$\quad \boxtimes$
	\par\bigskip
	\textbf{Теорема}
	
	\textit{В конечномерном пространстве все нормы эквивалентны}.
	
	
	
	
	
	
	
	\section{Нормы матриц}
	\quad\; Пусть $A\in P_{m,n}$, $P\in \begin{Bmatrix}\mathbb{R}, \mathbb{C}\end{Bmatrix}$, тогда $X\in P_n, AX \in P_m$
	\par\bigskip
	$\left \| AX \right \| \leqslant  \left \| A \right \|\cdot \left \| X \right \|, \forall X \in P_n, \forall A \in P_{m,n}$
	\par\bigskip
	$\left \| A \right \|= sup \frac{\left \| AX \right \|}{\left \| X \right \|}\qquad \frac{\left \| AX \right \|}{\left \| X \right \|}=\left \| A\left ( \frac{1}{\left \| X \right \|}X\right) \right \|$
	\par\bigskip
	$X_0=\frac{1}{\left \|  X\right \|}X$, $\left \| X_0 \right \|=\left \| \frac{1}{\left \|X\right \|}X \right \|=\frac{1}{\left \|X\right \|}\left \| X \right \|=1$
	\par\bigskip
	$(1)\left \| A \right \|=sup\frac{\left \| AX \right \|}{\left \| X \right \|}\quad(\left \| A \right \|=sup\left \| AX \right \|)$
	
	\par\bigskip
	\textbf{Теорема}
	
	\textit{Функция (1) определена и является согласованной матричной нормой для $\forall$ векторных норм.}
	\par\bigskip
	$\blacklozenge\ $
	$A=(\alpha_{ij})\in P_{n,n}, X=\begin{pmatrix}x_1\\ \vdots \\ x_n\end{pmatrix}$
	
	$\quad\left \| AX \right \|\leqslant \alpha \left \| AX \right \|_0=\sum\limits_{i=1}^{m}{|\sum\limits_{j=1}^{n}{\alpha_ix_j|}}\leqslant \sum\limits_{i=1}^{m}{\sum\limits_{j=1}^{n}{|\alpha_{ij}||x_j|}}\leqslant \beta\underset{1 \leqslant j \leqslant n}{max|x_j|}=\beta\left \| X \right \|_n=\gamma\left \| X \right \|$
	
	$\quad\frac{\left \| AX \right \|}{\left \| X \right \|}\leqslant \gamma \Rightarrow \exists$ $ sup\frac{\left \| AX \right \|}{\left \| X \right \|}$
	\par\bigskip
	\quadДоказательство, что это матричная норма
	\begin{enumerate}
		\item $\left \| A \right \|\geqslant 0$\\
		$\left \| A \right \| =0 \Leftrightarrow sup \left \| AX \right \|=0 \Leftrightarrow  AX=0, \forall X \in P_n \Leftrightarrow A=0 $
		\item $\left \| \alpha A \right \|= \underset{\left \| X \right \|=1}{sup \left \|\alpha A \cdot X\right \|}=\underset{\left \| X \right \|=1}{sup (|\alpha|\left \| AX \right \|)}=|\alpha|\underset{\left \| X \right \|=1}{sup (\left \| AX \right \|)}=|\alpha|\left \| A \right \| \forall \alpha \in P$
		
		\item  $\left \| A + B \right \| = \underset{\left \| X \right \|=1} {sup\left \| (A+B)X \right \|}=\underset{\left \| X \right \|=1} {sup\left \| AX + BX \right \|}\leqslant \underset{\left \| X \right \|=1} {sup(\left \| AX \right \|+\left \| BX \right \|)}=\underset{\left \| X \right \|=1} {sup(\left \| AX \right \|)} +\underset{\left \| X \right \|=1} {sup(\left \| BX \right \|)} = \left \| A \right \| + \left \| B \right \| $
		$\boxtimes\ $
	\end{enumerate}
	\par\bigskip 
	Согласованная форма
	\par\bigskip 
	$\frac{\left \| AX \right \|}{\left \| X \right \|}\leqslant sup\left ( \frac{\left \| AX \right \|}{\left \| X \right \|} \right )=\left \| A \right \|$
	\par\bigskip 
	$\frac{\left \| AX \right \|}{\left \| X \right \|}\leq\left \| A \right \|, \left \| AX \right \|\leqslant \left \| A \right \|\left \| X \right \|, \forall X \in P_n$
	\par\bigskip 
	$\left \| A \right \|_I=sup \left ( \frac{\left \| AX \right \|}{\left \| X \right \|} \right )\quad(\left \| A \right \|_I=\underset{\left \| X \right \|=1} {sup(\left \| AX \right \|)})$
	\par\bigskip 
	Индуцированная форма
	\par\bigskip
	\textbf{Теорема}
	\par\bigskip
	\textit{Любая согласованная форма мажорирует индуцированную}.
	\par\bigskip
	$\blacklozenge\ $
	$\left \| AX \right \|\leqslant \left \| A \right \|\cdot\left \| X \right \|, \forall X \in P_n$ --- из согласованности
	\par\bigskip
	$\frac{\left \| AX \right \|}{\left \| X \right \|}\leqslant \left \| A \right \|$
	\par\bigskip
	$\frac{\left \| AX \right \|}{\left \| X \right \|}\leqslant sup \left ( \frac{\left \| AX \right \|}{\left \| X \right \|} \right )\leqslant \left \| A \right \|$
	\par\bigskip
	$\left \| A \right \|_I\leqslant \left \| A \right \|, \forall A \in P_{m,n}$
	$\boxtimes\ $
	\par\bigskip
	
	$\bullet\ A\in P_{n,n}, \left \| E_n \right \|=1$ --- \textit{норма сохраняет единицу.}
	\par\bigskip
	$\bullet$ \textit{\textbf{Кольцевая норма} --- норма, у которой $\left \| AB \right \| \leqslant \left \| A \right \|\cdot \left \| B \right \|, \forall A,B \in P_{n,n}$ (матричная).}
	\par\bigskip
	\textbf{\textit{Свойства кольцевой нормы:}}
	\begin{enumerate}
		\item $\left \| A \right \|= \left \| AE_n \right \| \leqslant \left \| A \right \|\cdot \left \| E_n \right \|\Rightarrow \left \| E_n \right \| \geqslant 1$
		\item $\left \| E_n \right \|=\left \| AA^{-1} \right \|\leqslant \left \| A \right \|\cdot \left \| A^{-1} \right \|,\left \| A^{-1} \right\|\geqslant \frac{E_n}{\left \| A \right \|}\geqslant \frac{1}{\left \| A \right \|}\Rightarrow \left \| A^{-1} \right \|\geqslant (\left \| A \right \|)^{-1}$
	\end{enumerate}
	
	\textbf{Теорема}
	
	\textit{Любая индуцированная норма сохраняет единицу}.
	\par\bigskip
	$\blacklozenge\ \left \| A \right \|_I=sup \left ( \frac{\left \| AX \right \|}{\left \| X \right \|} \right )$
	\par\bigskip
	$\quad \left \| A \right \|_I=\underset{\left \| X \right \|\geqslant 1}{sup \left ( \left \| AX \right \|\right )}$
	\par\bigskip
	$\quad\left \| E_n \right \|_I=sup\left ( \frac{\left \| E_nX \right \|}{\left \| X \right \|} \right )=sup\left ( \frac{\left \| X \right \|}{\left \| X \right \|} \right )=1$
	$\boxtimes\ $
	\par\bigskip
	Кольцевая норма
	\par\bigskip
	$\left \| AB \right \|_I=\underset{\left \| X \right \|=1} {sup(\left \| (AB)X\right \|)})=\underset{\left \| X \right \|=1} {sup(\left \| (A(BX)\right \|)})\leqslant \underset{\left \| X \right \|=1} {sup(\left \| A \right \|_I \left \| BX \right \|)}=\left \| A \right \|_I \underset{\left \| X \right \|=1} {sup(\left \| BX \right \|)}=$
	
	$=\left \| A \right \|_I \left \| B \right \|_I $
	\par\bigskip
	$A \in P_{m,n}, B \in P_{n,k}, \quad AB \in P_{m,k}$
	\par\bigskip
	$\left \| AB \right \|_1 \leqslant \left \| A \right \|_1\left \| B \right \|_1,\quad\forall A \in P_{m,n}, \forall B \in P_{n,k}$
	\par\bigskip
	\textit{Матричные нормы, индуцированные векторными нормами:}
	\begin{enumerate}
		\item Евклидова норма индуцирует спектральную норму.\\
		$\left \| A \right \|_S = \underset{i} {max \sqrt{\lambda_i}}$, где $\lambda_i$ - собственное значение $A^*A$
		\item Октаэдрическая норма индуцирует\\
		$\left \| A \right \| = \underset{j} {max}\sum\limits_{i=1}^{n}|\alpha_{ij}|$ (столбцовая норма)
		\item Кубическая норма индуцирует\\
		$\left \| A \right \| = \underset{i} {max}\sum\limits_{j=1}^{n}(\alpha_{ij})$ (строковая норма)
	\end{enumerate}
	
	
	
	
	
	
	
	
	
	
	\section{Псевдообратная матрица.}
	
	\quad\;\textbf{ Теорема (о скелетном разложении матрицы)}
	
	\textit{Пусть $A \in P_{m,n},\ rank A = r>0$. Тогда $\exists\ B \in P_{m,n},\ \exists\ C \in P_{n, k}: A = B \cdot C,\ rank B = rank C = r.$}
	\par\bigskip
	$\blacklozenge\ (B_1, ..., B_n)$ --- ЛНЗ столбцы $B \in P_{m,n}$.
	
	$\quad rank B = r$ (т.к. столбцы независимые)
	
	$\quad (A_1, ..., A_n)$ --- столбцы A.
	
	$\quad A_i=C_{1i}B_1 + ... + C_{ni}B_{n}$, $i=\overline{1, n}$
	
	$\quad\Rightarrow A=B\cdot C$, $rank C = rank(A_1, ..., A_n) = rank A = r$
	$\boxtimes$
	\par\bigskip
	$\bigstar$\textbf{ Замечание 1}
	
	\textit{Скелетное разложение неоднозначно.}
	\par\bigskip
	$\bigstar$\textbf{ Замечание 2}
	
	\textit{$A \in P_{m,n}$, $rank A = n$, $B=A \Rightarrow C = E_n$  $\Rightarrow A = A \cdot E_n$
		$rank A = m, A = E_m \cdot A$}
	\par\bigskip
	$\bullet$ \textit{Пусть $A \in P_{m,n}.\ A^+ \in P_{n,m} $ --- \textbf{псевдообратная для матрицы A}, если: }
	\begin{enumerate}
		\item $AA^+A=A$
		\item $A^+AA^+=A^+$
		\item $(A^+A)^*=A^+A$
		\item $(AA^+)^*=AA^+$
	\end{enumerate}
	
	\textbf{Теорема}
	
	\textit{Для любой матрицы существует псевдообратная ( $\forall A \in P_{m,n}\ \exists\ A^+$)}.
	\par\bigskip
	$\blacklozenge $ 1) $A = 0_{m,n}$, 2) $A^+ = 0_{n,m}$ 
	
	$\quad rank (A) = r > 0$. Пусть $A = B \cdot C$ - скелетное разложение, где $B \in P_{m, r}, C\in P_{r,n}$
	
	$\quad rank (B) = rank (C) = r$
	
	$\quad B^*B \in P_{r,r}$, $rank (B^*B) = rank (B) = r \Rightarrow \exists (B^*B)^{-1}$
	
	$\quad CC^* \in P_{r,r}$, $rank (CC^*) = rank (C) = r \Rightarrow \exists (CC^*)^{-1}$
	
	$\quad A^+ = C^*(CC^*)^{-1}(B^*B)^{-1}\cdot B^* \in P_{n, m}$
	
	$\quad A = BC$
	$\boxtimes$
	\par\bigskip
	\textbf{\textit{Проверка свойств:}}
	\begin{enumerate}
		\item $AA^+A=BCC^*(CC^*)^{-1}(B^*B)^{-1}B^*BC=E_n \cdot E_m \cdot BC = BC = A$
		\item $A^+AA^+=C^*(CC^*)^{-1}(B^*B)^{-1}B^*BCC^*(CC^*)^{-1}(B^*B)^{-1}B^* = C^*(CC^*)^{-1}(B^*B)^{-1}B^*=A^+$
		\item $(A^+A)^*=(C^*(CC^*)^{-1}(B^*B)^{-1}B^*BC)^*= (C^*(CC^*)^{-1}C)^*=C^*((CC^*)^{-1})^*C=C^*(CC^*)^{-1}C=C^*(CC^*)^{-1}(B^*B)^{-1}B^*BC=A^+A$
		\item $(AA^+)^*=AA^+$
	\end{enumerate}
	
	\textit{\textbf{Следствие}}
	
	\textit{Пусть $A \in P_{m,n}$, тогда} $rank (A)=n$, $A=BC=A\cdot E_n \Rightarrow A^+ = C^*(CC^*)^{-1}(B^*B)^{-1}B^*$
	\par\bigskip
	$\blacklozenge\ B=A, C = E_n$
	
	$\quad A=AE_n$, $ A^+ = (A^*A)^{-1}A^*$
	
	$\quad rank(A)=m$, $A=BC \Rightarrow B = E_m, C=A$
	
	$\quad A^+=A^*(AA^*)^{-1} \quad\boxtimes$
	\par\bigskip
	\textbf{\textit{Скелетные разложения могут быть разными.}}
	\par\bigskip
	\textbf{Теорема}
	
	\textit{$\forall A \in P_{n,m}\ \exists\ A^+$ и только одна }(без доказательства).
	\par\bigskip
	\textit{\textbf{Следствие}}
	
	$\forall A \in P_{r, n}$ $det(A) \neq 0 \Rightarrow A^+=A^{-1}$
	\par\bigskip
	$\blacklozenge\ A \in P_{r,n}$, $det(A) \neq 0 \Rightarrow rank (A) = n$
	
	$\quad A^+ = (A^*(A))^{-1}A^*=(A^*A)^{-1}A^*=A^{-1}(A^*)^{-1}A^*=A^{-1}$
	$\boxtimes$
	
	
	
	
	
	
	
	
	
	
	\section{Нормальное псевдорешение линейной системы.}
	
	$\quad \; $Рассмотрим несовместную линейную систему с действительными коэффициентами 
	
	$AX = B\ (1)$, где $A$ $\in$ $\mathbb{R}_{m,n}$ , $B$ $\in$ $\mathbb{R}_{m,1}$, $X$ $=$ ($x_1$ $\dots$ $x_n$)
	
	$L_0$ – пространство решения приведённой системы $AX =  0$. В пространстве $\mathbb{R}^n$ введем скалярное произведение следующим образом:
	
	\par\bigskip
	
	\textit{$X = (x_1 \dots x_n), Y = (y_1 \dots y_n) \Rightarrow (x, y) = x_1y_1 + \dots + x_ny_n$}
	\par\bigskip
	
	$\bullet$\textit{ $Y \in P_n $ --- \textbf{ невязка $X$ }, если $Y = B - AX$}
	
	Если $AX = B$, то $Y$ --- нулевой вектор.
	
	$\bullet$\textit{ $X$ --- \textbf{ псевдорешение системы }, если у него невязка минимальной длины.}
	
	$\bullet$\textit{ \textbf{Нормальным псевдорешением системы} (1) называется её псевдорешение с наименьшей длиной.}
	
	\par\bigskip
	
	\textbf{Теорема}
	
	\textit{НПР определено однозначно и равно ортогональной составляющей
		произвольного псевдорешения системы $(1)$ относительно подпространства} $L_0$.
	\par\bigskip
	$\blacklozenge$ Покажем, что ортогональные составляющие псевдорешения системы равны: 
	
	$\quad$Пусть $L_n$ --- множество псевдорешений системы (1), тогда $L_n$ --- множество решений $AX = B_1\ (2)$, где $В_1$ --– проекция $B$ на $L = L(A_1, \dots , A_n) \Rightarrow L_n = X_c + L_0 , $ где $X_c $ – частное
	решение системы (2). 
	
	$\quad$
	Пусть $x_1 = $ ортогональная проекция последовательности $ X_c$  на $L_0$,$ x_2 $  --- ортогональная
	составляющая последовательности $X_C$ относительно $L_0$, тогда:
	
	$\quad$
	$x_c = x_1 + x_2 \Rightarrow L_n = x_1 + x_2 + L_0$, т.к. $x_1 \in  L_0, L_0$ --- подпоследовательность $\Rightarrow L_n = x_2 + L_0$,
	т.е. любое псевдорешение системы (1) $y \in L_n$ представимо в виде $y = x_2 + y_1 \Rightarrow$ т.к.
	такое представление последовательности $y$ --- единственно, то $x_2$ --- ортогональная
	составляющая последовательности $y$ относительно $L_0$, т.е. все псевдорешения имеют
	ортогональное состовляющее относительно $L_0.$
	
	$\quad$
	Покажем, что $x_2$ --- единственное НПР системы (1).
	
	$\quad$
	Множество псевдорешений $L_n = X_2 + L_0 $ (мы это показали выше), т.к. $L_0$ ---
	подпространство пространства $\mathbb{R}^n$, то $L_0$ содержит нулевую последовательность $0 =
	(0,\dots,0) \in L_0 \Rightarrow x_2 + 0 \in L_n \Rightarrow$ $x_2$  --- псевдорешение системы (1).
	
	$\quad$
	Примем $\forall y \in L_n ,\ y \neq x_2,\ \exists\ y_1 \in L_0\ (y_1 \neq 0) : y = y_1 + y_2 \Rightarrow |y|^2 = |x_2 + y_1|^2 = |x_2|^2 + |y_1|^2 > |x_2|^2
	\Rightarrow x_2$ --- единственное псевдорешение системы (1) с наименьшей длиной.$\quad\boxtimes$
	\par\bigskip
	$\bigstar$ \textbf{Замечание:} НПР системы (1) является единственным псевдорешением,
	принадлежащим $L_0$(1).
	
\end{document}